@inproceedings{10.1145/3458864.3467675,
author = {Xu, Jingao and Chi, Guoxuan and Yang, Zheng and Li, Danyang and Zhang, Qian and Ma, Qiang and Miao, Xin},
title = {FollowUpAR: Enabling Follow-up Effects in Mobile AR Applications},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467675},
doi = {10.1145/3458864.3467675},
abstract = {Existing smartphone-based Augmented Reality (AR) systems are able to render virtual effects on static anchors. However, today's solutions lack the ability to render follow-up effects attached to moving anchors since they fail to track the 6 degrees of freedom (6-DoF) poses of them. We find an opportunity to accomplish the task by leveraging sensors capable of generating sparse point clouds on smartphones and fusing them with vision-based technologies. However, realizing this vision is non-trivial due to challenges in modeling radar error distributions and fusing heterogeneous sensor data. This study proposes FollowUpAR, a framework that integrates vision and sparse measurements to track object 6-DoF pose on smartphones. We derive a physical-level theoretical radar error distribution model based on an in-depth understanding of its hardware-level working principles and design a novel factor graph competent in fusing heterogeneous data. By doing so, FollowUpAR enables mobile devices to track anchor's pose accurately. We implement FollowUpAR on commodity smartphones and validate its performance with 800,000 frames in a total duration of 15 hours. The results show that FollowUpAR achieves a remarkable rotation tracking accuracy of 2.3° with a translation accuracy of 2.9mm, outperforming most existing tracking systems and comparable to state-of-the-art learning-based solutions. FollowUpAR can be integrated into ARCore and enable smartphones to render follow-up AR effects to moving objects.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {1–13},
numpages = {13},
keywords = {6-DoF pose tracking, augmented reality, computer vision, mmWave radar},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467676,
author = {Hu, Jinhan and Iosifescu, Andrei and LiKamWa, Robert},
title = {LensCap: Split-Process Framework for Fine-Grained Visual Privacy Control for Augmented Reality Apps},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467676},
doi = {10.1145/3458864.3467676},
abstract = {Augmented Reality (AR) enables smartphone users to interact with virtual content spatially overlaid on a continuously captured physical world. Under the current permission enforcement model in popular operating systems, AR apps are given Internet permission at installation time, and request camera permission and external storage write permission at runtime through a user's approval. With these permissions granted, any Internet-enabled AR app could silently collect camera frames and derived visual information for malicious intent without a user's awareness. This raises serious concerns about the disclosure of private user data in their living environments.To give users more control over application usage of their camera frames and the information derived from them, we introduce LensCap, a split-process app design framework, in which the app is split into a camera-handling visual process and a connectivity-handling network process. At runtime, LensCap manages secured communications between split processes, enacting fine-grained data usage monitoring. LensCap also allows both processes to present interactive user interfaces. With LensCap, users can decide what forms of visual data can be transmitted to the network, while still allowing visual data to be used for AR purposes on device. We prototype LensCap as an Android library and demonstrate its usability as a plugin in Unreal Engine. Performance evaluation results on five AR apps confirm that visual privacy can be preserved with an insignificant latency penalty (&lt; 1.3 ms) at 60 FPS.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {14–27},
numpages = {14},
keywords = {unreal engine, visual privacy, augmented reality security, split-process control, AR application development},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467886,
author = {Zhao, Yiqin and Guo, Tian},
title = {Xihe: A 3D Vision-Based Lighting Estimation Framework for Mobile Augmented Reality},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467886},
doi = {10.1145/3458864.3467886},
abstract = {Omnidirectional lighting provides the foundation for achieving spatially-variant photorealistic 3D rendering, a desirable property for mobile augmented reality applications. However, in practice, estimating omnidirectional lighting can be challenging due to limitations such as partial panoramas of the rendering positions, and the inherent environment lighting and mobile user dynamics. A new opportunity arises recently with the advancements in mobile 3D vision, including built-in high-accuracy depth sensors and deep learning-powered algorithms, which provide the means to better sense and understand the physical surroundings. Centering the key idea of 3D vision, in this work, we design an edge-assisted framework called Xihe to provide mobile AR applications the ability to obtain accurate omnidirectional lighting estimation in real time.Specifically, we develop a novel sampling technique that efficiently compresses the raw point cloud input generated at the mobile device. This technique is derived based on our empirical analysis of a recent 3D indoor dataset and plays a key role in our 3D vision-based lighting estimator pipeline design. To achieve the realtime goal, we develop a tailored GPU pipeline for on-device point cloud processing and use an encoding technique that reduces network transmitted bytes. Finally, we present an adaptive triggering strategy that allows Xihe to skip unnecessary lighting estimations and a practical way to provide temporal coherent rendering integration with the mobile AR ecosystem. We evaluate both the lighting estimation accuracy and time of Xihe using a reference mobile application developed with Xihe's APIs. Our results show that Xihe takes as fast as 20.67ms per lighting estimation and achieves 9.4% better estimation accuracy than a state-of-the-art neural network.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {28–40},
numpages = {13},
keywords = {mobile augmented reality, lighting estimation, edge inference, 3D vision, deep learning},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3468161,
author = {Kim, Seyeon and Bin, Kyungmin and Ha, Sangtae and Lee, Kyunghan and Chong, Song},
title = {ZTT: Learning-Based DVFS with Zero Thermal Throttling for Mobile Devices},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3468161},
doi = {10.1145/3458864.3468161},
abstract = {DVFS (dynamic voltage and frequency scaling) is a system-level technique that adjusts voltage and frequency levels of CPU/GPU at runtime to balance energy efficiency and high performance. DVFS has been studied for many years, but it is considered still challenging to realize a DVFS that performs ideally for mobile devices for two main reasons: i) an optimal power budget distribution between CPU and GPU in a power-constrained platform can only be defined by the application performance, but conventional DVFS implementations are mostly application-agnostic; ii) mobile platforms experience dynamic thermal environments for many reasons such as mobility and holding methods, but conventional implementations are not adaptive enough to such environmental changes. In this work, we propose a deep reinforcement learning-based frequency scaling technique, zTT. zTT learns thermal environmental characteristics and jointly scales CPU and GPU frequencies to maximize the application performance in an energy-efficient manner while achieving zero thermal throttling. Our evaluations for zTT implemented on Google Pixel 3a and NVIDIA JETSON TX2 platform with various applications show that zTT can adapt quickly to changing thermal environments, consistently resulting in high application performance with energy efficiency. In a high-temperature environment where a rendering application with the default mobile DVFS fails to keep producing more than a target frame rate, zTT successfully manages to do so even with 23.9% less average power consumption.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {41–53},
numpages = {13},
keywords = {deep reinforcement learning, mobile devices, DVFS},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467681,
author = {Ouyang, Xiaomin and Xie, Zhiyuan and Zhou, Jiayu and Huang, Jianwei and Xing, Guoliang},
title = {ClusterFL: A Similarity-Aware Federated Learning System for Human Activity Recognition},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467681},
doi = {10.1145/3458864.3467681},
abstract = {Federated Learning (FL) has recently received significant interests thanks to its capability of protecting data privacy. However, existing FL paradigms yield unsatisfactory performance for a wide class of human activity recognition (HAR) applications since they are oblivious to the intrinsic relationship between data of different users. We propose ClusterFL, a similarity-aware federated learning system that can provide high model accuracy and low communication overhead for HAR applications. ClusterFL features a novel clustered multi-task federated learning framework that maximizes the training accuracy of multiple learned models while automatically capturing the intrinsic clustering relationship among the data of different nodes. Based on the learned cluster relationship, ClusterFL can efficiently drop out the nodes that converge slower or have little correlation with other nodes in each cluster, significantly speeding up the convergence while maintaining the accuracy performance. We evaluate the performance of ClusterFL on an NVIDIA edge testbed using four new HAR datasets collected from total 145 users. The results show that, ClusterFL outperforms several state-of-the-art FL paradigms in terms of overall accuracy, and save more than 50% communication overhead at the expense of negligible accuracy degradation.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {54–66},
numpages = {13},
keywords = {communication optimization, federated learning, multitask learning, human activity recognition, clustering},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467884,
author = {Li, Tianxing and Huang, Jin and Risinger, Erik and Ganesan, Deepak},
title = {Low-Latency Speculative Inference on Distributed Multi-Modal Data Streams},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467884},
doi = {10.1145/3458864.3467884},
abstract = {While multi-modal deep learning is useful in distributed sensing tasks like human tracking, activity recognition, and audio and video analysis, deploying state-of-the-art multi-modal models in a wirelessly networked sensor system poses unique challenges. The data sizes for different modalities can be highly asymmetric (e.g., video vs. audio), and these differences can lead to significant delays between streams in the presence of wireless dynamics. Therefore, a slow stream can significantly slow down a multi-modal inference system in the cloud, leading to either increased latency (when blocked by the slow stream) or degradation in inference accuracy (if inference proceeds without waiting). In this paper, we introduce speculative inference on multi-modal data streams to adapt to these asymmetries across modalities. Rather than blocking inference until all sensor streams have arrived and been temporally aligned, we impute any missing, corrupt, or partially-available sensor data, then generate a speculative inference using the learned models and imputed data. A rollback module looks at the class output of speculative inference and determines whether the class is sufficiently robust to incomplete data to accept the result; if not, we roll back the inference and update the model's output. We implement the system in three multi-modal application scenarios using public datasets. The experimental results show that our system achieves 7 -- 128\texttimes{} latency speedup with the same accuracy as six state-of-the-art methods.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {67–80},
numpages = {14},
keywords = {cloud computing, deep neural networks, edge computing, computation off-loading},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467882,
author = {Zhang, Li Lyna and Han, Shihao and Wei, Jianyu and Zheng, Ningxin and Cao, Ting and Yang, Yuqing and Liu, Yunxin},
title = {Nn-Meter: Towards Accurate Latency Prediction of Deep-Learning Model Inference on Diverse Edge Devices},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467882},
doi = {10.1145/3458864.3467882},
abstract = {With the recent trend of on-device deep learning, inference latency has become a crucial metric in running Deep Neural Network (DNN) models on various mobile and edge devices. To this end, latency prediction of DNN model inference is highly desirable for many tasks where measuring the latency on real devices is infeasible or too costly, such as searching for efficient DNN models with latency constraints from a huge model-design space. Yet it is very challenging and existing approaches fail to achieve a high accuracy of prediction, due to the varying model-inference latency caused by the runtime optimizations on diverse edge devices.In this paper, we propose and develop nn-Meter, a novel and efficient system to accurately predict the inference latency of DNN models on diverse edge devices. The key idea of nn-Meter is dividing a whole model inference into kernels, i.e., the execution units on a device, and conducting kernel-level prediction. nn-Meter builds atop two key techniques: (i) kernel detection to automatically detect the execution unit of model inference via a set of well-designed test cases; and (ii) adaptive sampling to efficiently sample the most beneficial configurations from a large space to build accurate kernel-level latency predictors. Implemented on three popular platforms of edge hardware (mobile CPU, mobile GPU, and Intel VPU) and evaluated using a large dataset of 26,000 models, nn-Meter significantly outperforms the prior state-of-the-art.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {81–93},
numpages = {13},
keywords = {deep neural network, edge AI, inference latency prediction},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466628,
author = {Mo, Fan and Haddadi, Hamed and Katevas, Kleomenis and Marin, Eduard and Perino, Diego and Kourtellis, Nicolas},
title = {PPFL: Privacy-Preserving Federated Learning with Trusted Execution Environments},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466628},
doi = {10.1145/3458864.3466628},
abstract = {We propose and implement a Privacy-preserving Federated Learning (PPFL) framework for mobile systems to limit privacy leakages in federated learning. Leveraging the widespread presence of Trusted Execution Environments (TEEs) in high-end and mobile devices, we utilize TEEs on clients for local training, and on servers for secure aggregation, so that model/gradient updates are hidden from adversaries. Challenged by the limited memory size of current TEEs, we leverage greedy layer-wise training to train each model's layer inside the trusted area until its convergence. The performance evaluation of our implementation shows that PPFL can significantly improve privacy while incurring small system overheads at the client-side. In particular, PPFL can successfully defend the trained model against data reconstruction, property inference, and membership inference attacks. Furthermore, it can achieve comparable model utility with fewer communication rounds (0.54\texttimes{}) and a similar amount of network traffic (1.002\texttimes{}) compared to the standard federated learning of a complete model. This is achieved while only introducing up to ~15% CPU time, ~18% memory usage, and ~21% energy consumption overhead in PPFL's client-side.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {94–108},
numpages = {15},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467962,
author = {Talebi, Seyed Mohammadjavad Seyed and Sani, Ardalan Amiri and Saroiu, Stefan and Wolman, Alec},
title = {MegaMind: A Platform for Security &amp; Privacy Extensions for Voice Assistants},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467962},
doi = {10.1145/3458864.3467962},
abstract = {Voice assistants raise serious security and privacy concerns because they use always-on microphones in sensitive locations (e.g., inside a home) and send audio recordings to the cloud for processing. The cloud transcribes these recordings and interprets them as user requests, and sometimes even shares these requests with third-party services. These steps may result in unintended or malicious voice data leaks and in unauthorized actions, such as a purchase. This paper presents MegaMind, a novel extensible platform that lets a user deploy security and privacy extensions locally on their voice assistant. MegaMind's extensions interpose on requests before sending them to the cloud and on responses before delivering them to the user. MegaMind's programming model enables writing powerful extensions with ease, such as one for secure conversations. Additionally, MegaMind protects against malicious extensions by providing two important guarantees, namely permission enforcement and non-interference. We implement MegaMind and integrate it with Amazon Alexa Service SDK. Our evaluation shows that MegaMind achieves a small conversation latency on platforms with adequate compute power, such as a Raspberry Pi 4 and an x86-based laptop.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {109–121},
numpages = {13},
keywords = {extensibility, security and privacy, smart speakers, voice assistants},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467887,
author = {Park, Chang Min and Kim, Donghwi and Sidhwani, Deepesh Veersen and Fuchs, Andrew and Paul, Arnob and Lee, Sung-Ju and Dantu, Karthik and Ko, Steven Y.},
title = {Rushmore: Securely Displaying Static and Animated Images Using TrustZone},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467887},
doi = {10.1145/3458864.3467887},
abstract = {We present Rushmore, a system that securely displays static or animated images using TrustZone. The core functionality of Rushmore is to securely decrypt and display encrypted images (sent by a trusted party) on a mobile device. Although previous approaches have shown that it is possible to securely display encrypted images using TrustZone, they exhibit a critical limitation that significantly hampers the applicability of using TrustZone for display security. The limitation is that, when the trusted domain of TrustZone (the secure world) takes control of the display, the untrusted domain (the normal world) cannot display anything simultaneously. This limitation comes from the fact that previous approaches give the secure world exclusive access to the display hardware to preserve security. With Rushmore, we overcome this limitation by leveraging a well-known, yet overlooked hardware feature called an IPU (Image Processing Unit) that provides multiple display channels. By partitioning these channels across the normal world and the secure world, we enable the two worlds to simultaneously display pixels on the screen without sacrificing security. Furthermore, we show that with the right type of cryptographic method, we can decrypt and display encrypted animated images at 30 FPS or higher for medium-to-small images and at around 30 FPS for large images. One notable cryptographic method we adapt for Rushmore is visual cryptography, and we demonstrate that it is a light-weight alternative to other cryptographic methods for certain use cases. Our evaluation shows that in addition to providing usable frame rates, Rushmore incurs less than 5% overhead to the applications running in the normal world.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {122–135},
numpages = {14},
keywords = {TrustZone, secure image display, visual cryptography},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3468220,
author = {Koh, John S. and Nieh, Jason and Bellovin, Steven M.},
title = {Encrypted Cloud Photo Storage Using Google Photos},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3468220},
doi = {10.1145/3458864.3468220},
abstract = {Cloud photo services are widely used for persistent, convenient, and often free photo storage, which is especially useful for mobile devices. As users store more and more photos in the cloud, significant privacy concerns arise because even a single compromise of a user's credentials give attackers unfettered access to all of the user's photos. We have created Easy Secure Photos (ESP) to enable users to protect their photos on cloud photo services such as Google Photos. ESP introduces a new client-side encryption architecture that includes a novel format-preserving image encryption algorithm, an encrypted thumbnail display mechanism, and a usable key management system. ESP encrypts image data such that the result is still a standard format image like JPEG that is compatible with cloud photo services. ESP efficiently generates and displays encrypted thumbnails for fast and easy browsing of photo galleries from trusted user devices. ESP's key management makes it simple to authorize multiple user devices to view encrypted image content via a process similar to device pairing, but using the cloud photo service as a QR code communication channel. We have implemented ESP in a popular Android photos app for use with Google Photos and demonstrate that it is easy to use and provides encryption functionality transparently to users, maintains good interactive performance and image quality while providing strong privacy guarantees, and retains the sharing and storage benefits of Google Photos without any changes to the cloud service.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {136–149},
numpages = {14},
keywords = {Google photos, key management, usable security, image encryption},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466627,
author = {Ibrahim, Muhammad and Imran, Abdullah and Bianchi, Antonio},
title = {SafetyNOT: On the Usage of the SafetyNet Attestation API in Android},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466627},
doi = {10.1145/3458864.3466627},
abstract = {Many apps performing security-sensitive tasks (e.g., online banking) attempt to verify the integrity of the device they are running in and the integrity of their own code. To ease this goal, Android provides an API, called the SafetyNet Attestation API, that can be used to detect if the device an app is running in is in a "safe" state (e.g., non-rooted) and if the app's code has not been modified (using, for instance, app repackaging). In this paper, we perform the first large-scale systematic analysis of the usage of the SafetyNet API. Our study identifies many common mistakes that app developers make when attempting to use this API. Specifically, we provide a systematic categorization of the possible misusages of this API, and we analyze how frequent each misuse is. Our results show that, for instance, more than half of the analyzed apps check SafetyNet results locally (as opposed to using a remote trusted server), rendering their checks trivially bypassable. Even more surprisingly, we found that none of the analyzed apps invoking the SafetyNet API uses it in a fully correct way.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {150–162},
numpages = {13},
keywords = {attestation, API misusage, reverse engineering, Android, tampering, SafetyNet},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467879,
author = {Chen, Xingyu and Liu, Jia and Xiao, Fu and Chen, Shigang and Chen, Lijun},
title = {Thermotag: Item-Level Temperature Sensing with a Passive RFID Tag},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467879},
doi = {10.1145/3458864.3467879},
abstract = {Temperature sensing plays a significant role in upholding quality assurance and meeting regulatory compliance in a wide variety of applications, such as fire safety and cold chain monitoring. However, existing temperature measurement devices are bulky, cost-prohibitive, or battery-powered, making item-level sensing and intelligence costly. In this paper, we present a novel tag-based thermometer called Thermotag, which uses a common passive RFID tag to sense the temperature with competitive advantages of being low-cost, battery-free, and robust to environmental conditions. The basic idea of Thermotag is that the resistance of a semiconductor diode in a tag's chip is temperature-sensitive. By measuring the discharging period through the reverse-polarized diode, we can estimate the temperature indirectly. We propose a standards-compliant measurement scheme of the discharging period by using a tag's volatile memory and build a mapping model between the discharging period and temperature for accurate and reliable temperature sensing. We implement Thermotag using a commercial off-the-shelf RFID system, with no need for any firmware or hardware modifications. Extensive experiments show that the temperature measurement has a large span ranging from 0 °C to 85 °C and a mean error of 2.7 °C.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {163–174},
numpages = {12},
keywords = {persistence time, passive RFID, temperature sensing},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467680,
author = {Ma, Dong and Ferlini, Andrea and Mascolo, Cecilia},
title = {OESense: Employing Occlusion Effect for in-Ear Human Sensing},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467680},
doi = {10.1145/3458864.3467680},
abstract = {Smart earbuds are recognized as a new wearable platform for personal-scale human motion sensing. However, due to the interference from head movement or background noise, commonly-used modalities (e.g. accelerometer and microphone) fail to reliably detect both intense and light motions. To obviate this, we propose OESense, an acoustic-based in-ear system for general human motion sensing. The core idea behind OESense is the joint use of the occlusion effect (i.e., the enhancement of low-frequency components of bone-conducted sounds in an occluded ear canal) and inward-facing microphone, which naturally boosts the sensing signal and suppresses external interference. We prototype OESense as an earbud and evaluate its performance on three representative applications, i.e., step counting, activity recognition, and hand-to-face gesture interaction. With data collected from 31 subjects, we show that OESense achieves 99.3% step counting recall, 98.3% recognition recall for 5 activities, and 97.0% recall for five tapping gestures on human face, respectively. We also demonstrate that OESense is compatible with earbuds' fundamental functionalities (e.g. music playback and phone calls). In terms of energy, OESense consumes 746 mW during data recording and recognition and it has a response latency of 40.85 ms for gesture recognition. Our analysis indicates such overhead is acceptable and OESense is potential to be integrated into future earbuds.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {175–187},
numpages = {13},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466870,
author = {Sun, Wei and Srinivasan, Kannan},
title = {Healthy Diapering with Passive RFIDs for Diaper Wetness Sensing and Urine PH Identification},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466870},
doi = {10.1145/3458864.3466870},
abstract = {In this paper, we present RFDiaper, a commodity passive RFID based healthy diapering system, which can sense the diaper wetness (i.e., wet/dry) and identify pH value of urine absorbed by the diaper. To do so, we leverage the coupling effect between the urine absorbed by the diaper and RFID tag, thereby the phase and amplitude variation can indicate urine pH and diaper wetness. However, rich scattering and dynamic environment exhibit a great challenge for accurate diaper wetness sensing and urine pH identification. Therefore, we propose a twin-tag based dynamic environment mitigation approach for robust and healthy diapering. Specifically, by extracting the differential amplitude and phase from the co-located sensing tag and reference tag (i.e., twin-tag) attached on the diaper, the multipath effect and the other dynamic factors (e.g., diaper wearer's body, tag's orientation and temperature, etc.) can be mitigated. Then, we detect the diaper wetness and estimate the urine pH based on differential amplitude and phase. We have implemented RFDiaper's design and evaluated its effectiveness with the experiments using commercial off-the-shelf (COTS) RFID tags attached on the diaper worn by the doll and the human subjects. RFDiaper can achieve the median accuracy of around 96% for diaper wetness sensing and urine pH estimation error of around 0.23 in dynamic environment.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {188–201},
numpages = {14},
keywords = {commodity passive RFIDs, diaper wetness sensing, healthy diapering, RFID sensing, urine pH identification},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3468012,
author = {Korany, Belal and Mostofi, Yasamin},
title = {Counting a Stationary Crowd Using Off-the-Shelf Wifi},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3468012},
doi = {10.1145/3458864.3468012},
abstract = {In this paper, we are interested in the problem of counting a crowd of stationary people (i.e., seated) using a pair of WiFi transceivers. While the people in the crowd are stationary, i.e. with no major body motion except breathing, people do not stay still for a long period of time and frequently engage in small in-place body motions called fidgets (e.g., adjusting their seating position, crossing their legs, checking their phones, etc). In this paper, we propose that the aggregate natural fidgeting and in-place motions of a stationary crowd carry crucial information on the crowd count. We then mathematically characterize the Probability Distribution Function (PDF) of the crowd fidgeting and silent periods (which we can extract from the received WiFi signal) and show their dependency on the total number of people in the area. In developing our mathematical models, we show how our problem of interest resembles a several-decade-old M/G/∞ queuing theory problem, which allows us to borrow mathematical tools from the literature on M/G/∞ queues. We extensively validate our proposed approach with a total of 47 experiments in four different environments (including through-wall settings), in which up to and including N = 10 people are seated. We further test our system in different scenarios, and with different activities, representing various engagement levels of the crowd, such as attending a lecture, watching a movie, and reading. Moreover, we test our proposed system with different number of people seated in several different configurations. Our evaluation results show that our proposed approach achieves a very high counting accuracy, with the estimated number of people being only 0 or 1 off from the true number 96.3% of the time in non-through-wall settings, and 90% of the time in through-wall settings. Our results show the potential of our proposed framework for crowd counting in real-world scenarios.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {202–214},
numpages = {13},
keywords = {occupancy estimation, crowd counting, wifi sensing},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467683,
author = {He, Yan and He, Qiuye and Fang, Song and Liu, Yao},
title = {MotionCompass: Pinpointing Wireless Camera via Motion-Activated Traffic},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467683},
doi = {10.1145/3458864.3467683},
abstract = {Wireless security cameras are integral components of security systems used by military installations, corporations, and, due to their increased affordability, many private homes. These cameras commonly employ motion sensors to identify that something is occurring in their fields of vision before starting to record and notifying the property owner of the activity. In this paper, we discover that the motion sensing action can disclose the location of the camera through a novel wireless camera localization technique we call MotionCompass. In short, a user who aims to avoid surveillance can find a hidden camera by creating motion stimuli and sniffing wireless traffic for a response to that stimuli. With the motion trajectories within the motion detection zone, the exact location of the camera can be then computed. We develop an Android app to implement MotionCompass. Our extensive experiments using the developed app and 18 popular wireless security cameras demonstrate that for cameras with one motion sensor, MotionCompass can attain a mean localization error of around 5 cm with less than 140 seconds. This localization technique builds upon existing work that detects the existence of hidden cameras, to pinpoint their exact location and area of surveillance.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {215–227},
numpages = {13},
keywords = {localization, wireless traffic analysis, hidden camera, motion sensor},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467677,
author = {Gu, Zhihao and He, Taiwei and Yin, Junwei and Xu, Yuedong and Wu, Jun},
title = {TyrLoc: A Low-Cost Multi-Technology MIMO Localization System with a Single RF Chain},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467677},
doi = {10.1145/3458864.3467677},
abstract = {This work presents the design and implementation of TyrLoc, an accurate multi-technology switching MIMO localization system that can be deployed on low-cost SDRs. TyrLoc only uses a single RF Chain to switch on each antenna in an antenna array within the coherence time asynchronously, thus mimicking a MIMO platform to pinpoint the positions of WIFI, Bluetooth Low Energy (BLE) and LoRa devices. TyrLoc makes three key technical contributions. First, TyrLoc modifies the firmware of inexpensive PlutoSDR that controls the antenna switching pattern and tags the signal associated with each antenna. Second, it develops a two-stage fine-grained carrier frequency offset (CFO) calibration algorithm that harnesses the agile antenna switching pattern and is 10\texttimes{} more accurate than the baseline method. Third, TyrLoc employs an interpolated transform approach to facilitate angle-of-arrival (AoA) estimation in the presence of missing antennas. The AoA-based localization experiments in a multipath-rich indoor environment show that TyrLoc with eight antennas achieves the median errors of 63cm for WIFI, 39cm for BLE and 32cm for LoRa, respectively.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {228–240},
numpages = {13},
keywords = {CFO calibration, switching MIMO, localization, SDR},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3468850,
author = {Pizarro, Alejandro Blanco and Beltr\'{a}n, Joan Palacios and Cominelli, Marco and Gringoli, Francesco and Widmer, Joerg},
title = {Accurate Ubiquitous Localization with Off-the-Shelf IEEE 802.11ac Devices},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3468850},
doi = {10.1145/3458864.3468850},
abstract = {WiFi location systems are remarkably accurate, with decimeter-level errors for recent CSI-based systems. However, such high accuracy is achieved under Line-of-Sight (LOS) conditions and with an access point (AP) density that is much higher than that typically found in current deployments that primarily target good coverage. In contrast, when many of the APs within range are in Non-Line-of-Sight (NLOS), the location accuracy degrades drastically.In this paper we present UbiLocate, a WiFi location system that copes well with common AP deployment densities and works ubiquitously, i.e., without excessive degradation under NLOS. UbiLocate demonstrates that meter-level median accuracy NLOS localization is possible through (i) an innovative angle estimator based on a Nelder-Mead search, (ii) a fine-grained time of flight ranging system with nanosecond resolution, and (iii) the accuracy improvements brought about by the increase in bandwidth and number of antennas of IEEE 802.11ac. In combination, they provide superior resolvability of multipath components, significantly improving location accuracy over prior work. We implement our location system on off-the-shelf 802.11ac devices and make the implementation, CSI-extraction tool and custom Fine Timing Measurement design publicly available to the research community. We carry out an extensive performance analysis of our system and show that it outperforms current state-of-the-art location systems by a factor of 2--3, both under LOS and NLOS.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {241–254},
numpages = {14},
keywords = {802.11ac, indoor localization, ToF, AoA, wireless networks, CSI},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467880,
author = {Garg, Nakul and Bai, Yang and Roy, Nirupam},
title = {Owlet: Enabling Spatial Information in Ubiquitous Acoustic Devices},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467880},
doi = {10.1145/3458864.3467880},
abstract = {This paper presents a low-power and miniaturized design for acoustic direction-of-arrival (DoA) estimation and source localization, called Owlet. The required aperture, power consumption, and hardware complexity of the traditional array-based spatial sensing techniques make them unsuitable for small and power-constrained IoT devices. Aiming to overcome these fundamental limitations, Owlet explores acoustic microstructures for extracting spatial information. It uses a carefully designed 3D-printed metamaterial structure that covers the microphone. The structure embeds a direction-specific signature in the recorded sounds. Owlet system learns the directional signatures through a one-time in-lab calibration. The system uses an additional microphone as a reference channel and develops techniques that eliminate environmental variation, making the design robust to noises and multipaths in arbitrary locations of operations. Owlet prototype shows 3.6° median error in DoA estimation and 10cm median error in source localization while using a 1.5cm \texttimes{} 1.3cm acoustic structure for sensing. The prototype consumes less than 100th of the energy required by a traditional microphone array to achieve similar DoA estimation accuracy. Owlet opens up possibilities of low-power sensing through 3D-printed passive structures.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {255–268},
numpages = {14},
keywords = {spatial sensing, low-power sensing, IoT, acoustic metamaterial},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467679,
author = {Xue, Hongfei and Ju, Yan and Miao, Chenglin and Wang, Yijiang and Wang, Shiyang and Zhang, Aidong and Su, Lu},
title = {MmMesh: Towards 3D Real-Time Dynamic Human Mesh Construction Using Millimeter-Wave},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467679},
doi = {10.1145/3458864.3467679},
abstract = {In this paper, we present mmMesh, the first real-time 3D human mesh estimation system using commercial portable millimeter-wave devices. mmMesh is built upon a novel deep learning framework that can dynamically locate the moving subject and capture his/her body shape and pose by analyzing the 3D point cloud generated from the mmWave signals that bounce off the human body. The proposed deep learning framework addresses a series of challenges. First, it encodes a 3D human body model, which enables mmMesh to estimate complex and realistic-looking 3D human meshes from sparse point clouds. Second, it can accurately align the 3D points with their corresponding body segments despite the influence of ambient points as well as the error-prone nature and the multi-path effect of the RF signals. Third, the proposed model can infer missing body parts from the information of the previous frames. Our evaluation results on a commercial mmWave sensing testbed show that our mmMesh system can accurately localize the vertices on the human mesh with an average error of 2.47 cm. The superior experimental results demonstrate the effectiveness of our proposed human mesh construction system.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {269–282},
numpages = {14},
keywords = {millimeter wave, human sensing, deep learning, point cloud, human mesh estimation},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466862,
author = {Narayana, Sujay and Prasad, R. Venkatesha and Prabhakar, T. V.},
title = {SOS: Isolated Health Monitoring System to <u>S</u>Ave <u>O</u>Ur <u>S</u>Atellites},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466862},
doi = {10.1145/3458864.3466862},
abstract = {With the advent of Space-IoTs, the rate of launch of satellites has grown significantly. Alongside, the failure rate of satellites has also surged increased tremendously. Satellites are non-repairable systems in orbit, and the financial loss incurred when the satellites fail before their expected mission time is substantial. If the source of a failure is known while the satellite is in orbit, then there is a possibility to revive it by sending appropriate commands from ground stations. In this work, we present a simple, independent satellite health monitoring system called Chirper. The Chirper is equipped with multiple modules such as IMU, isolated voltage and current measurement probes, and an onboard communication channel. We present a new approach to measure low DC voltages in an isolated way, providing a resolution and accuracy of around 1 V. We evaluated the design and performance of the Chirper through simulation, testing it in space systems test facility, and by mounting it on a helium balloon. With extensive experiments we show that 90% of the time the dc voltage measurement error is within 0.8 V, and the maximum error is 0.9 V. We expect to launch the Chirper soon on a space system.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {283–295},
numpages = {13},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466625,
author = {Hou, Kaiyu and Li, You and Yu, Yinbo and Chen, Yan and Zhou, Hai},
title = {Discovering Emergency Call Pitfalls for Cellular Networks with Formal Methods},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466625},
doi = {10.1145/3458864.3466625},
abstract = {Availability and security problems in cellular emergency call systems can cost people their lives, yet this topic has not been thoroughly researched. Based on our proposed Seed-Assisted Specification method, we start to investigate this topic by looking closely into one emergency call failure case in China. Using what we learned from the case as prior knowledge, we build a formal model of emergency call systems with proper granularity. By running model checking, four public-unaware scenarios where emergency calls cannot be correctly routed are discovered. Additionally, we extract configurations of two major U.S. carriers and incorporate them as model constraints into the model. Based on the augmented model, we find two new attacks leveraging the privileges of emergency calls. Finally, we present a solution with marginal overhead to resolve issues we can foresee.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {296–309},
numpages = {14},
keywords = {emergency call, formal methods, protocol formal verification, cellular network protocol, protocol specification},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466869,
author = {Tambe, Arjun and Nambi, Akshay and Marathe, Sumukh},
title = {Is Your Smoke Detector Working Properly? Robust Fault Tolerance Approaches for Smoke Detectors},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466869},
doi = {10.1145/3458864.3466869},
abstract = {Billions of smoke detectors are in use worldwide to provide early warning of fires. Despite this, they frequently fail to operate in an ongoing fire, risking death and property damage. A significant fraction of faults result from drift, or reduced sensitivity, and other faults in smoke detectors' phototransistors (PTs). Existing approaches attempt to detect drift from the PT output in normal conditions (without smoke). However, we find that drifted PTs mimic the output of working PTs in normal conditions, but diverge in the presence of smoke, making this approach ineffective.This paper presents two novel approaches to systematically detect faults and measure and compensate for drift in smoke detectors' PTs. Our first approach, called FallTime, measures a PT "fingerprint," a unique electrical characteristic with distinct behavior for working, drifted, and faulty components. FallTime can be added to many existing smoke detector models in software alone, with no/minimal hardware modifications. Our second approach, DriftTestButton, is a mechanical test button that simulates the behavior of smoke when pressed. It offers a robust, straightforward approach to detect faults, and can measure and compensate for drift across the entire smoke detector system. We empirically evaluate both approaches and present extensive experimental results from actual smoke detectors deployed in a commercial building, along with custom-built smoke detectors. By conducting tests with live smoke, we show that both FallTime and DriftTestButton perform more effectively than existing fault tolerance techniques and stand to substantially reduce the risk that a smoke detector fails to alarm in the presence of smoke.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {310–322},
numpages = {13},
keywords = {phototransistors, drift detection, smoke detectors, fault tolerance},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467682,
author = {Dash, Pranab and Hu, Y. Charlie},
title = {How Much Battery Does Dark Mode Save? An Accurate OLED Display Power Profiler for Modern Smartphones},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467682},
doi = {10.1145/3458864.3467682},
abstract = {By omitting external lighting, OLED display significantly reduces the power draw compared to its predecessor LCD and has gained wide adoption in modern smartphones. The real potential of OLED in saving phone battery drain lies in exploiting app UI color design, i.e., how to design app UI to use pixel colors that result in low OLED display power draw. In this paper, we design and implement an accurate per-frame OLED display power profiler, PFOP, that helps developers to gain insight into the impact of different app UI design on its OLED power draw, and an enhanced Android Battery that helps phone users to understand and manage phone display energy drain, for example, from different app and display configurations such as dark mode and screen brightness. A major challenge in designing both tools is to develop an accurate and robust OLED display power model. We experimentally show that linear-regression-based OLED power models developed in the past decade cannot capture the unique behavior of OLED display hardware in modern smartphones which have a large color space and propose a new piecewise power model that achieves much better modeling accuracy than the prior-art by applying linear regression in each small regions of the vast color space. Using the two tools, we performed to our knowledge the first power saving measurement of the emerging dark mode for a set of popular Google Android apps.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {323–335},
numpages = {13},
keywords = {display power profiler, power modeling, OLED display, dark mode},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467678,
author = {AlDuaij, Naser and Nieh, Jason},
title = {Tap: An App Framework for Dynamically Composable Mobile Systems},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467678},
doi = {10.1145/3458864.3467678},
abstract = {As smartphones and tablets have become ubiquitous, there is a growing demand for apps that can enable users to collaboratively use multiple mobile systems. We present Tap, a framework that makes it easy for users to dynamically compose collections of mobile systems and developers to write apps that make use of those impromptu collections. Tap users control the composition by simply tapping systems together for discovery and authentication. The physical interaction mimics and supports ephemeral user interactions without the need for tediously exchanging user contact information such as phone numbers or email addresses. Tapping triggers a simple NFC-based mechanism to exchange connectivity information and security credentials that works across heterogeneous networks and requires no user accounts or cloud infrastructure support. Tap makes it possible for apps to use existing mobile platform APIs across multiple mobile systems by virtualizing data sources so that local and remote data sources can be combined together upon tapping. Virtualized data sources can be hardware or software features, including media, clipboard, calendar events, and devices such as cameras and microphones. Leveraging existing mobile platform APIs makes it easy for developers to write apps that use hardware and software features across dynamically composed collections of mobile systems. We have implemented a Tap prototype that allows apps to make use of both unmodified Android and iOS systems. We have modified and implemented various apps using Tap to demonstrate that it is easy to use and can enable apps to provide powerful new functionality by leveraging multiple mobile systems. Our results show that Tap has good performance, even for high-bandwidth features, and is user and developer friendly.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {336–349},
numpages = {14},
keywords = {iOS, distributed computing, mobile devices, mobile computing, Android, remote display, operating systems},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466866,
author = {Ramanujam, Murali and Madhyastha, Harsha V. and Netravali, Ravi},
title = {Marauder: Synergized Caching and Prefetching for Low-Risk Mobile App Acceleration},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466866},
doi = {10.1145/3458864.3466866},
abstract = {Low interaction response times are crucial to the experience that mobile apps provide for their users. Unfortunately, existing strategies to alleviate the network latencies that hinder app responsiveness fall short in practice. In particular, caching is plagued by challenges in setting expiration times that match when a resource's content changes, while prefetching hinges on accurate predictions of user behavior that have proven elusive. We present Marauder, a system that synergizes caching and prefetching to improve the speedups achieved by each technique while avoiding their inherent limitations. Key to Marauder is our observation that, like web pages, apps handle interactions by downloading and parsing structured text resources that entirely list (i.e., without needing to consult app binaries) the set of other resources to load. Building on this, Marauder introduces two low-risk optimizations directly from the app's cache. First, guided by cached text files, Marauder prefetches referenced resources during an already-triggered interaction. Second, to improve the efficacy of cached content, Marauder judiciously prefetches about-to-expire resources, extending cache lives for unchanged resources, and downloading updates for lightweight (but crucial) text files. Across a wide range of apps, live networks, interaction traces, and phones, Marauder reduces median and 90th percentile interaction response times by 27.4% and 43.5%, while increasing data usage by only 18%.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {350–362},
numpages = {13},
keywords = {prefetching, mobile apps, performance, smartphones, caching},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467881,
author = {Balasingam, Arjun and Gopalakrishnan, Karthik and Mittal, Radhika and Arun, Venkat and Saeed, Ahmed and Alizadeh, Mohammad and Balakrishnan, Hamsa and Balakrishnan, Hari},
title = {Throughput-Fairness Tradeoffs in Mobility Platforms},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467881},
doi = {10.1145/3458864.3467881},
abstract = {This paper studies the problem of allocating tasks from different customers to vehicles in mobility platforms, which are used for applications like food and package delivery, ridesharing, and mobile sensing. A mobility platform should allocate tasks to vehicles and schedule them in order to optimize both throughput and fairness across customers. However, existing approaches to scheduling tasks in mobility platforms ignore fairness.We introduce Mobius, a system that uses guided optimization to achieve both high throughput and fairness across customers. Mobius supports spatiotemporally diverse and dynamic customer demands. It provides a principled method to navigate inherent tradeoffs between fairness and throughput caused by shared mobility. Our evaluation demonstrates these properties, along with the versatility and scalability of Mobius, using traces gathered from ridesharing and aerial sensing applications. Our ridesharing case study shows that Mobius can schedule more than 16,000 tasks across 40 customers and 200 vehicles in an online manner.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {363–375},
numpages = {13},
keywords = {mobility platforms, resource allocation, ridesharing, aerial sensing, vehicle routing, optimization},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466867,
author = {Shen, Wen-Hsuan and Tsai, Hsin-Mu},
title = {RayTrack: Enabling Interference-Free Outdoor Mobile VLC with Dynamic Field-of-View},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466867},
doi = {10.1145/3458864.3466867},
abstract = {Connected autonomous vehicles have boosted a high demand on communication throughput in order to timely share the information collected by in-car sensors (e.g., LiDAR). While visible light communication (VLC) has shown its capability to offer Gigabit-level throughput for applications with high demand for data rate, most are performed indoors and the throughput of outdoor VLC drops to a few Mbps. To fill this performance gap, this paper presents RayTrack, an interference-free outdoor mobile VLC system. The key idea of RayTrack is to use a small but real-time adjustable FOV according to the transmitter location, which can effectively repel interference from the environment and from other transmitters and boost the system throughput. The idea also realizes virtual point-to-point links, and eliminates the need of link access control. To be able to minimize the transmitter detection time to only 20 ms, RayTrack leverages a high-compression-ratio compressive sensing scheme, incorporating a dual-photodiode architecture, optimized measurement matrix and Gaussian-based basis to increase sparsity. Real-world driving experiments show that RayTrack is able to achieve a data rate of 607.9 kbps with over 90% detection accuracy and lower than 15% bit error rate at 35 m, with 70 - 100 km/hr driving speed. To the best of our knowledge, this is the first working outdoor VLC system which can offer such range, throughput and error performance while accommodating freeway mobility.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {376–388},
numpages = {13},
keywords = {visible light communication, vehicular communication, compressive sensing},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466864,
author = {Woodford, Timothy and Zhang, Xinyu and Chai, Eugene and Sundaresan, Karthikeyan and Khojastepour, Amir},
title = {SpaceBeam: LiDAR-Driven One-Shot MmWave Beam Management},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466864},
doi = {10.1145/3458864.3466864},
abstract = {mmWave 5G networks promise to enable a new generation of networked applications requiring a combination of high throughput and ultra-low latency. However, in practice, mmWave performance scales poorly for large numbers of users due to the significant overhead required to manage the highly-directional beams. We find that we can substantially reduce or eliminate this overhead by using out-of-band infrared measurements of the surrounding environment generated by a LiDAR sensor. To accomplish this, we develop a ray-tracing system that is robust to noise and other artifacts from the infrared sensor, create a method to estimate the reflection strength from sensor data, and finally apply this information to the multiuser beam selection process. We demonstrate that this approach reduces beam-selection overhead by over 95% in indoor multi-user scenarios, reducing network latency by over 80% and increasing throughput by over 2\texttimes{} in mobile scenarios.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {389–401},
numpages = {13},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466865,
author = {Zhang, Maolin and Chen, Si and Zhao, Jia and Gong, Wei},
title = {Commodity-Level BLE Backscatter},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466865},
doi = {10.1145/3458864.3466865},
abstract = {The communication reliability of state-of-the-art Bluetooth Low Energy (BLE) backscatter systems is fundamentally limited by their modulation schemes because the Binary Frequency Shift Keying (BFSK) modulation of the tag does not exactly match commodity BLE receivers designed for Gauss Frequency Shift Keying (GFSK) modulated signals with high bandwidth efficiency. Gaussian pulse shaping is a missing piece in state-of-the-art BLE backscatter systems. Inspired by active BLE and applying calculus, we present IBLE, a BLE backscatter communication system that achieves full compatibility with commodity BLE devices. IBLE leverages the fact that phase shift is the integral of frequency over time to build a reliable physical layer for BLE backscatter. IBLE uses instantaneous phase shift (IPS) modulation, GFSK modulation, and optional FEC coding to improve the reliability of BLE backscatter communication to the commodity level. We prototype IBLE using various commodity BLE devices and a customized tag with FPGA. Empirical results demonstrate that IBLE achieves PERs of 0.04% and 0.68% when the uplink distances are 2 m and 14 m respectively, which are 280x and 70x lower than the PERs of the state-of-the-art system RBLE. On the premise of meeting the BER requirements of the BLE specification, the uplink range of IBLE is 20 m. Since BLE devices are everywhere, IBLE is readily deployable in our everyday IoT applications.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {402–414},
numpages = {13},
keywords = {backscatter, bluetooth, internet of things},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466863,
author = {Bonati, Leonardo and D'Oro, Salvatore and Basagni, Stefano and Melodia, Tommaso},
title = {SCOPE: An Open and Softwarized Prototyping Platform for NextG Systems},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466863},
doi = {10.1145/3458864.3466863},
abstract = {The cellular networking ecosystem is being radically transformed by openness, softwarization, and virtualization principles, which will steer NextG networks toward solutions running on "white box" infrastructures. Telco operators will be able to truly bring intelligence to the network, dynamically deploying and adapting its elements at run time according to current conditions and traffic demands. Deploying intelligent solutions for softwarized NextG networks, however, requires extensive prototyping and testing procedures, currently largely unavailable. To this aim, this paper introduces SCOPE, an open and softwarized prototyping platform for NextG systems. SCOPE is made up of: (i) A ready-to-use, portable open-source container for instantiating softwarized and programmable cellular network elements (e.g., base stations and users); (ii) an emulation module for diverse real-world deployments, channels and traffic conditions for testing new solutions; (iii) a data collection module for artificial intelligence and machine learning-based applications, and (iv) a set of open APIs for users to control network element functionalities in real time. Researchers can use SCOPE to test and validate NextG solutions over a variety of large-scale scenarios before implementing them on commercial infrastructures. We demonstrate the capabilities of SCOPE and its platform independence by prototyping exemplary cellular solutions in the controlled environment of Colosseum, the world's largest wireless network emulator. We then port these solutions to indoor and outdoor testbeds, namely, to Arena and POWDER, a PAWR platform.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {415–426},
numpages = {12},
keywords = {data-driven control, network slicing, NextG, data collection, 5G},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466868,
author = {Lacruz, Jesus O. and Ortiz, Rafael Ruiz and Widmer, Joerg},
title = {A Real-Time Experimentation Platform for Sub-6 GHz and Millimeter-Wave MIMO Systems},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466868},
doi = {10.1145/3458864.3466868},
abstract = {The performance of wireless communication systems is evolving rapidly, making it difficult to build experimentation platforms that meet the hardware requirements of new standards. The bandwidth of current systems ranges from 160 MHz for IEEE 802.11ac/ax to 2 GHz for Millimeter-Wave (mm-wave) IEEE 802.11ad/ay, and they support up to 8 spatial MIMO streams. Mobile 5G and beyond systems have a similarly diverse set of requirements.To address this, we propose a highly configurable wireless platform that meets such requirements and is both affordable and scalable. It is implemented on a single state-of-the-art FPGA board that can be configured from 4x4 mm-wave MIMO with 2 GHz channels to 8x8 MIMO with 160 MHz channels in sub-6 GHz bands. In addition, multi-band operation will play an important role in future wireless networks and our platform supports mixed configurations with simultaneous use of mm-wave and sub-6 GHz. Finally, the platform supports real-time operation, e.g., for closed-loop MIMO beam training with low-latency, by implementing suitable hardware/software accelerators. We demonstrate the platform's performance in a wide range of experiments. The platform is provided as open-source to build a community to use and extend it.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {427–439},
numpages = {13},
keywords = {FPGA, phased antenna array, multi-band, millimeter wave, MIMO, testbed},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467883,
author = {Fomichev, Mikhail and Hesse, Julia and Almon, Lars and Lippert, Timm and Han, Jun and Hollick, Matthias},
title = {FastZIP: Faster and More Secure Zero-Interaction Pairing},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467883},
doi = {10.1145/3458864.3467883},
abstract = {With the advent of the Internet of Things (IoT), establishing a secure channel between smart devices becomes crucial. Recent research proposes zero-interaction pairing (ZIP), which enables pairing without user assistance by utilizing devices' physical context (e.g., ambient audio) to obtain a shared secret key. The state-of-the-art ZIP schemes suffer from three limitations: (1) prolonged pairing time (i.e., minutes or hours), (2) vulnerability to brute-force offline attacks on a shared key, and (3) susceptibility to attacks caused by predictable context (e.g., replay attack) because they rely on limited entropy of physical context to protect a shared key. We address these limitations, proposing FastZIP, a novel ZIP scheme that significantly reduces pairing time while preventing offline and predictable context attacks. In particular, we adapt a recently introduced Fuzzy Password-Authenticated Key Exchange (fPAKE) protocol and utilize sensor fusion, maximizing their advantages. We instantiate FastZIP for intra-car device pairing to demonstrate its feasibility and show how the design of FastZIP can be adapted to other ZIP use cases. We implement FastZIP and evaluate it by driving four cars for a total of 800 km. We achieve up to three times shorter pairing time compared to the state-of-the-art ZIP schemes while assuring robust security with adversarial error rates below 0.5%.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {440–452},
numpages = {13},
keywords = {fPAKE, pairing, internet of things, zero-interaction, sensor fusion},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3467885,
author = {Cao, Yifeng and Dhekne, Ashutosh and Ammar, Mostafa},
title = {ITrackU: Tracking a Pen-like Instrument via UWB-IMU Fusion},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3467885},
doi = {10.1145/3458864.3467885},
abstract = {High-precision tracking of a pen-like instrument's movements is desirable in a wide range of fields spanning education, robotics, and art, to name a few. The key challenge in doing so stems from the impracticality of embedding electronics in the tip of such instruments (a pen, marker, scalpel, etc.) as well as the difficulties in instrumenting the surface that it works on. In this paper, we present ITrackU, a movement digitization system that does not require modifications to the surface or the tracked instrument's tip. ITrackU fuses locations obtained using ultra-wideband radios (UWB), with an inertial and magnetic unit (IMU) and a pressure sensor, yielding multidimensional improvements in accuracy, range, cost, and robustness, over existing works. ITrackU embeds a micro-transmitter at the base of a pen which creates a trackable beacon, that is localized from the corners of a writing surface. Fused with inertial motion sensor and a pressure sensor, ITrackU enables accurate tracking. Our prototype of ITrackU covers a large 2.5m \texttimes{} 2m area, while obtaining around 2.9mm median error. We demonstrate the accuracy of our system by drawing numerous shapes and characters on a whiteboard, and compare them against a touchscreen and a camera-based ground-truthing system. Finally, the produced stream of digitized data is minuscule in volume, when compared with a video of the whiteboard, which saves both network bandwidth and storage space.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {453–466},
numpages = {14},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466626,
author = {Kim, Wonjung and Lee, Seungchul and Chang, Youngjae and Lee, Taegyeong and Hwang, Inseok and Song, Junehwa},
title = {Hivemind: Social Control-and-Use of IoT towards Democratization of Public Spaces},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466626},
doi = {10.1145/3458864.3466626},
abstract = {Public spaces are equipped with 'public actuators', e.g., HVAC, lighting fixtures, speakers, or streaming TV channels to ensure their visitors' comfort. However, many public actuators rarely allow the visitors to adjust their operation, limiting their utility and fairness across the visitors. Also, the social bar is often too high to speak up one's preference and attempt to change an actuator's operation. Social control and use of IoT devices is an underexplored new direction of research even with its huge potential and implication, but comes with high complexity and scale. This paper proposes a novel architecture, namely, Social Control-and-Use Architecture for IoT Devices, which provides a systematic view and an effective tool to handle the complication and intricacy in system design. It also proposes Hivemind, a first-of-a-kind system developed, upon the architecture, for sharing IoT-enabled actuators in a public space. It transforms an exclusively-controlled actuator in a public space into a true public actuator, supporting visitors to instantly participate in the democratic collective control. Also, a myriad of off-the-shelf actuators are easily incorporated without modification to their implementation. The field deployment of Hivemind shows its comprehensive service coverage as well as the users' approval on the democratic collective control of public actuators.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {467–482},
numpages = {16},
keywords = {IoT, urban computing, public space, public actuator, group decision-making, social control-and-use, influence-aware authorization},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466907,
author = {Ramprasad, Brian and Chen, Hongkai and Veith, Alexandre and Truong, Khai and de Lara, Eyal},
title = {Pain-o-Vision, Effortless Pain Management},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466907},
doi = {10.1145/3458864.3466907},
abstract = {Chronic pain is often an ongoing challenge for patients to track and collect data. Pain-O-Vision is a smartwatch enabled pain management system that uses computer vision to capture the details of painful events from the user. A natural reaction to pain is to clench ones fist. The embedded camera is used to capture different types of fist clenching, to represent different levels of pain. An initial prototype was built on an Android smartwatch that uses a cloud-based classification service to detect the fist clench gestures. Our results show that it is possible to map a fist clench to different levels of pain which allows the patient to record the intensity of a painful event without carrying a specialized pain management device.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {483–484},
numpages = {2},
keywords = {mobile computing, pain management, smartwatches},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466908,
author = {Aldeer, Murtadha and Yu, Justin and Chowdhury, Tahiya and Florentine, Joseph and Kolodziejski, Jakub and Howard, Richard E. and Martin, Richard P. and Ortiz, Jorge},
title = {A Smart Agent Guided Contactless Data Collection System amid a Pandemic},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466908},
doi = {10.1145/3458864.3466908},
abstract = {The COVID-19 pandemic has impacted academic life in different ways. In the mobile and pervasive computing community, there was a struggle on data collection for the evaluation of human-sensing systems. An automated and contactless solution to collect data from users at home is one way that can help in the continuation of user-centric studies. In this poster, we present a portable system for remote, in-home data collection. The system is powered by a Raspberry Pi© and input peripherals (a camera, a microphone, and a wireless receiver). Our system uses a speech interface for text-to-speech and speech-to-text conversions. The system acts as a voice-based "smart agent" that guides the user during an experiment session. We aim to use our system to collect data from a set of smart pill bottles that we previously designed for medication adherence monitoring [1] and user identification [3].},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {485–486},
numpages = {2},
keywords = {data collection, smart agent, portable system, smart pillbox},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466910,
author = {Li, Borui and Fan, Hongchang and Gao, Yi and Dong, Wei},
title = {ThingSpire OS: A WebAssembly-Based IoT Operating System for Cloud-Edge Integration},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466910},
doi = {10.1145/3458864.3466910},
abstract = {We advocate ThingSpire OS, a new IoT operating system based on WebAssembly for cloud-edge integration. By design, WebAssembly is considered as the first-class citizen in ThingSpire OS to achieve coherent execution among IoT device, edge and cloud. Furthermore, ThingSpire OS enables efficient execution of WebAssembly on resource-constrained devices by implementing a WebAssembly runtime based on Ahead-of-Time (AoT) compilation with a small footprint, achieves seamless inter-module communication wherever the modules locate, and leverages several optimizations such as lightweight preemptible invocation for memory isolation and control-flow integrity. We implement a prototype of ThingSpire OS and conduct preliminary evaluations on its inter-module communication performance.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {487–488},
numpages = {2},
keywords = {operating system, WebAssembly, internet of things},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466911,
author = {Mohzary, Muhammad and Almalki, Khalid J and Choi, Baek-Young and Song, Sejun},
title = {Apple in My Eyes (AIME): Liveness Detection for Mobile Security Using Corneal Specular Reflections},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466911},
doi = {10.1145/3458864.3466911},
abstract = {In this paper, we present a novel software-based face Presentation Attack Detection (PAD) method named "Apple in My Eyes (AIME)" using screen display as a challenge and corneal specular reflections as a response for authenticating the liveness against presentation. To detect face liveness, AIME creates multiple image patterns on the authentication screen as a challenge, then captures meaningful corneal specular reflection responses from user's eyes using the front camera, and analyzes the reflective pattern images using various lightweight Machine Learning (ML) techniques under a subsecond level delay (200 ms). We demonstrate that AIME can detect various attacks, including digital images displayed on the phone or tablet, printed paper images, 2D paper masks, videos, 3D silicon masks, and 3D facial models using VR. AIME liveness detection can be applied for various contactless biometric authentication accurately and efficiently without any costly extra sensors.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {489–490},
numpages = {2},
keywords = {presentation attack detection, anti-spoofing, liveness detection},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466913,
author = {Pasandi, Hannaneh Barahouei and Nadeem, Tamer},
title = {LATTE: Online MU-MIMO Grouping for Video Streaming over Commodity Wifi},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466913},
doi = {10.1145/3458864.3466913},
abstract = {In this paper, we present LATTE, a novel framework that proposes MU-MIMO group selection optimization for multi-user video streaming over IEEE 802.11ac. Taking a cross-layer approach, LATTE first optimizes the MU-MIMO user group selection for the users with the same characteristics in the PHY/MAC layer. It then optimizes the video bitrate for each group accordingly. We present our design and its evaluation on smartphones over 802.11ac WiFi.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {491–492},
numpages = {2},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466914,
author = {Chen, Hsin-Yuan and Hsu, Ruey-Tzer and Chen, Ying-Chiao and Hsu, Wei-Chen and Huang, Polly},
title = {AR Game Traffic Characterization: A Case of Pok\'{e}Mon Go in a Flash Crowd Event},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466914},
doi = {10.1145/3458864.3466914},
abstract = {Latency is a major issue towards practical use of augmented reality (AR) in mobile apps such as navigation and gaming. A string of work has appeared recently, proposing to offload a part of the AR-related processing pipeline to the edge [8]. One pitfall in these studies is the (simplified) assumption about the network delay. As a reality check and to gather insights to realize AR in real time, we seek in this work a better understanding of how a popular AR game, Pok\'{e}mon Go, delivers its data in situ.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {493–494},
numpages = {2},
keywords = {traffic characterization, AR game, edge offloading},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466916,
author = {Holcomb, Amelia and Tong, Bill and Penny, Megan and Keshav, Srinivasan},
title = {Measuring Forest Carbon with Mobile Phones},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466916},
doi = {10.1145/3458864.3466916},
abstract = {Tree trunk diameter, currently measured during manual forest inventories, is a key input to tree carbon storage calculations. We designan app running on a smartphone equipped with a time-of-flight sensor that allows efficient, low-cost, and accurate measurement of trunk diameter, even in the face of natural leaf and branch occlusion. The algorithm runs in near real-time on the phone, allowing user interaction to improve the quality of the results. We evaluate the app in realistic settings and find that in a corpus of 55 sample tree images, it estimates trunk diameter with mean error of 7.8%.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {495–496},
numpages = {2},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3468444,
author = {Kim, Wonjung and Lee, Seungchul and Chang, Youngjae and Lee, Taegyeong and Hwang, Inseok and Song, Junehwa},
title = {Facilitating In-Situ Shared Use of IoT Actuators in Public Spaces},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3468444},
doi = {10.1145/3458864.3468444},
abstract = {Public spaces, where we gather, commune, and take a rest, are the essential parts of a modern urban landscape, enriching citizen's everyday life [3]. How we share these spaces are considered an indicator of the quality of life. Public spaces thus have a responsibility to provide comfort and satisfaction to any visitors. However, in most times, the operations of the spaces are managed in rather an exclusive manner.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {497–498},
numpages = {2},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466904,
author = {Liu, Hansi and Alali, Abrar and Ibrahim, Mohamed and Li, Hongyu and Gruteser, Marco and Jain, Shubham and Dana, Kristin and Ashok, Ashwin and Cheng, Bin and Lu, Hongsheng},
title = {Lost and Found! Associating Target Persons in Camera Surveillance Footage with Smartphone Identifiers},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466904},
doi = {10.1145/3458864.3466904},
abstract = {We demonstrate an application of finding target persons on a surveillance video. Each visually detected participant is tagged with a smartphone ID and the target person with the query ID is highlighted. This work is motivated by the fact that establishing associations between subjects observed in camera images and messages transmitted from their wireless devices can enable fast and reliable tagging. This is particularly helpful when target pedestrians need to be found on public surveillance footage, without the reliance on facial recognition. The underlying system uses a multi-modal approach that leverages WiFi Fine Timing Measurements (FTM) and inertial sensor (IMU) data to associate each visually detected individual with a corresponding smartphone identifier. These smartphone measurements are combined strategically with RGB-D information from the camera, to learn affinity matrices using a multi-modal deep learning network.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {499–500},
numpages = {2},
keywords = {multimodal learning, machine learning, wifi FTM ranging, person identification},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466905,
author = {Liu, Ruofeng and Jiang, Wenjun and Chen, Xun},
title = {Acoustic Ruler Using Wireless Earbud},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466905},
doi = {10.1145/3458864.3466905},
abstract = {In the paper, we demonstrate an application of the wireless earbud - an acoustic ruler. Approaches are proposed to improve the robustness of the design in the low signal-to-noise ratio environment. We also share our solution to several engineering challenges, which aims at facilitating the transformation of earbuds to into acoustic sensing research platforms without any hardware modification.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {501–502},
numpages = {2},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466906,
author = {Garg, Nakul and Bai, Yang and Roy, Nirupam},
title = {Microstructure-Guided Spatial Sensing for Low-Power IoT},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466906},
doi = {10.1145/3458864.3466906},
abstract = {This demonstration presents a working prototype of Owlet, an alternative design for spatial sensing of acoustic signals. To overcome the fundamental limitations in form-factor, power consumption, and hardware requirements with array-based techniques, Owlet explores wave's interaction with acoustic structures for sensing. By combining passive acoustic microstructures with microphones, we envision achieving the same functionalities as microphone and speaker arrays with less power consumption and in a smaller form factor. Our design uses a 3D-printed metamaterial structure over a microphone to introduce a carefully designed spatial signature to the recorded signal. Owlet prototype shows 3.6° median error in Direction-of-Arrival (DoA) estimation and 10 cm median error in source localization while using a 1.5cm \texttimes{} 1.3cm acoustic structure for sensing.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {503–504},
numpages = {2},
keywords = {IoT, low-power sensing, acoustic metamaterial, spatial sensing},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466909,
author = {Tharpe, Bronson and Bourgeois, Anu G. and Ashok, Ashwin},
title = {A Do-It-Yourself Computer Vision Based Robotic Ball Throw Trainer},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466909},
doi = {10.1145/3458864.3466909},
abstract = {We demonstrate a self-training system for sports involving throwing a ball. We design a do-it-yourself (DIY) machinery that can be assembled using off-the-shelf items and integrates computer vision to visually track the ball throw accuracy. In this work, we demonstrate a system that can identify if the ball went through the hoop and approximately in which of the hoop's inner region. We envision that this preliminary design sets the foundation for a complete DIY sports IoT system that involves a hoola hoop, RaspberryPi, PiCamera and a LED strip, along with advanced ball placement and dynamics tracking.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {505–506},
numpages = {2},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466912,
author = {Johnson, David and Maas, Dustin and Van Der Merwe, Jacobus},
title = {Open Source RAN Slicing on POWDER: A Top-to-Bottom O-RAN Use Case},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466912},
doi = {10.1145/3458864.3466912},
abstract = {This demonstration will showcase our efforts to develop a radio access network (RAN) slicing mechanism that is controllable via management software in an Open RAN framework. To our knowledge, our work represents the first effort that combines an open source Open RAN framework with an open source mobility stack, provides a top-to-bottom RAN application via the RAN intelligent control (RIC) provided by that framework and illustrates its functionality in a realistic wireless environment. Our software is publicly available and we provide a profile in the POWDER platform to enable others to replicate and build on our work.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {507–508},
numpages = {2},
keywords = {RAN slicing, open RAN, programmability},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3458864.3466915,
author = {Breen, Joe and Duerig, Jonathon and Eide, Eric and Hibler, Mike and Johnson, David and Kasera, Sneha and Maas, Dustin and Orange, Alex and Patwari, Neal and Ricci, Robert and Schurig, David and Stoller, Leigh and Van der Merwe, Jacobus and Webb, Kirk and Wong, Gary},
title = {Mobile and Wireless Research on the POWDER Platform},
year = {2021},
isbn = {9781450384438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458864.3466915},
doi = {10.1145/3458864.3466915},
abstract = {POWDER is a highly flexible, deeply programmable, and city-scale scientific instrument that enables cutting-edge research in wireless technologies. Researchers interact with the POWDER platform via the Internet to conduct their experiments, with zero penalty for remote access. In this two-part demonstration, the POWDER implementers show how to use the platform. First, they present the workflow that researchers follow to conduct experiments. Second, they highlight some of the hardware and software building blocks available through POWDER, including components related to over-the-air wireless and mobile networking, 5G, and massive MIMO.},
booktitle = {Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {509–510},
numpages = {2},
location = {Virtual Event, Wisconsin},
series = {MobiSys '21}
}

@inproceedings{10.1145/3386901.3389034,
author = {Lacruz, Jesus Omar and Garcia, Dolores and Mateo, Pablo Jim\'{e}nez and Palacios, Joan and Widmer, Joerg},
title = {Mm-FLEX: An Open Platform for Millimeter-Wave Mobile Full-Bandwidth Experimentation},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389034},
doi = {10.1145/3386901.3389034},
abstract = {Millimeter-Wave (mm-wave) technology is increasingly being considered for mobile devices and use cases such as vehicular communication. This requires suitable experimentation platforms to support systems-oriented research to tackle the multitude of problems and challenges of mm-wave communications in such environments. To this end, we introduce mm-FLEX, a flexible and modular open platform with real-time signal processing capabilities that supports a bandwidth of 2 GHz and is compatible with mm-wave standard requirements. mm-FLEX integrates an FPGA-based baseband processor with full-duplex capabilities together with mm-wave RF front-ends and phased antenna arrays that are fully configurable from the processor in real-time. To demonstrate the capabilities of mm-FLEX, we implement a scalable, ultra-fast beam alignment mechanism for IEEE 802.11ad systems. It is based on compressive estimation of the signal's angle-of-arrival by means of switching through multiple receive beam patterns on a nano-second time-scale while receiving a packet preamble. Our implementation is open source and is made publicly available to the research community.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {1–13},
numpages = {13},
keywords = {FPGA, millimeter wave, beam training, testbed, phased antenna array},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388945,
author = {Lu, Chris Xiaoxuan and Rosa, Stefano and Zhao, Peijun and Wang, Bing and Chen, Changhao and Stankovic, John A. and Trigoni, Niki and Markham, Andrew},
title = {See through Smoke: Robust Indoor Mapping with Low-Cost MmWave Radar},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388945},
doi = {10.1145/3386901.3388945},
abstract = {This paper presents the design, implementation and evaluation of milliMap, a single-chip millimetre wave (mmWave) radar based indoor mapping system targetted towards low-visibility environments to assist in emergency response. A unique feature of milliMap is that it only leverages a low-cost, off-the-shelf mmWave radar, but can reconstruct a dense grid map with accuracy comparable to lidar, as well as providing semantic annotations of objects on the map. milliMap makes two key technical contributions. First, it autonomously overcomes the sparsity and multi-path noise of mmWave signals by combining cross-modal supervision from a co-located lidar during training and the strong geometric priors of indoor spaces. Second, it takes the spectral response of mmWave reflections as features to robustly identify different types of objects e.g. doors, walls etc. Extensive experiments in different indoor environments show that milliMap can achieve a map reconstruction error less than 0.2m and classify key semantics with an accuracy of ~ 90%, whilst operating through dense smoke.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {14–27},
numpages = {14},
keywords = {millimeter wave radar, emergency response, indoor mapping, mobile robotics},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389031,
author = {Prabhakara, Akarsh and Singh, Vaibhav and Kumar, Swarun and Rowe, Anthony},
title = {Osprey: A MmWave Approach to Tire Wear Sensing},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389031},
doi = {10.1145/3386901.3389031},
abstract = {Tire wear is a leading cause of automobile accidents globally. Beyond safety, tire wear affects performance and is an important metric that decides tire replacement, one of the biggest maintenance expense of the global trucking industry. We believe that it is important to measure and monitor tire wear in all automobiles. Current approach to measure tire wear is manual and extremely tedious. Embedding sensor electronics in tires to measure tire wear is challenging, given the inhospitable temperature, pressure and dynamics of the tire. Further, off-tire sensors placed in the well such as laser range-finders are vulnerable to road debris that may settle in tire grooves.This paper presents Osprey, the first on-automobile, mmWave sensing system that can measure accurate tire wear continuously and is robust to road debris. Osprey's key innovation is to leverage existing, high volume, automobile mmWave RADAR, place it in the tire well of automobiles and observe reflections of the RADAR's signal from the tire surface and grooves to measure tire wear, even in the presence of debris. We achieve this through a super-resolution Inverse Synthetic Aperture RADAR algorithm that exploits the natural rotation of the tire and improves range resolution to sub-mm. We show how our system can eliminate debris by attaching specialized metallic structures in the grooves that behave as spatial codes and offer a unique signature, when coupled with the rotation of the tire. In addition to tire wear sensing, we demonstrate the ability to detect and locate unsafe, metallic foreign objects such as nails lodged in the tire.We evaluate Osprey on commercial tires mounted on mechanical, tire-rotation rig and passenger car. We test Osprey at different speeds, in the presence of different types of debris, different levels of debris, on different terrains, and different levels of automobile vibration. We achieve a median absolute tire wear error of 0.68 mm across all our experiments. Osprey also locates foreign objects lodged in the tire with an error of 1.7 cm and detects metallic foreign objects with an accuracy of 92%.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {28–41},
numpages = {14},
keywords = {RADAR, orthogonal codes, free of electronics, automotive, millimeter wave, FMCW, wireless sensing, tire wear, spatial coding, foreign object, 77 GHz, super resolution, debris, tread depth, inverse synthetic aperture RADAR imaging},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388914,
author = {Zhu, Fengyuan and Feng, Yuda and Li, Qianru and Tian, Xiaohua and Wang, Xinbing},
title = {DigiScatter: Efficiently Prototyping Large-Scale OFDMA Backscatter Networks},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388914},
doi = {10.1145/3386901.3388914},
abstract = {Recently proposed OFDMA backscatter could improve both concurrency and spectrum allocation flexibility for backscatter systems based on OFDM. However, we find that it is remarkably inefficient for the existing design to scale up in prototyping: it requires one-by-one offline computation to obtain tags' operating parameters, in order to ensure orthogonality among subcarriers in the system; moreover, the tag hardware has to be dedicatedly modified offline before being assigned multiple subcarriers. The inefficiency is caused by the current analog frequency synthesis design for the tag. This paper proposes DigiScatter, an OFDMA backscatter system realizing digital frequency synthesis, which provides an efficient prototyping approach for large-scale OFDMA backscatter networks. In DigiScatter, we for the first time integrate IDFT into the tag design; such a simple but effective improvement enables the system to support high concurrency and flexible spectrum resource allocation through pure software configurations in an online manner. We build a prototype and conduct comprehensive experiments to validate our design. DigiScatter physically realizes 100 and 300 concurrent OFDMA backscatter transmissions in 2.4GHz and 900MHz respectively, and provides frequency synthesis capability for supporting 1019 concurrent transmissions.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {42–53},
numpages = {12},
keywords = {backscatter communication, OFDMA},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388949,
author = {Jung, Jinhwan and Ryoo, Jihoon and Yi, Yung and Kim, Song Min},
title = {Gateway over the Air: Towards Pervasive Internet Connectivity for Commodity IoT},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388949},
doi = {10.1145/3386901.3388949},
abstract = {This paper presents GateScatter, the first backscatter-based gateway connecting commodity IoT to WiFi. The backscatter design of GateScatter is an economic option towards pervasive Internet connectivity for ever-growing IoT. The carefully designed tag optimally reshapes ZigBee IoT packets with an arbitrary payload into an 802.11b WiFi packet over the air, such that the payload can be reliably retrieved at the WiFi receiver (hence a gateway). Gate-Scatter is highly compatible - it works with a wide range of IEEE 802.15.4-compliant systems, is agnostic to upper layer proprietary protocols, and does not require any modification to the commodity IoT platforms. GateScatter is extended to BLE IoT for generality. We prototype GateScatter hardware on FPGA where the wide applicability is demonstrated through evaluations on five popular IoT devices including Samsung SmartThings sensor, Philips smart bulb, and Amazon Echo Plus. Further extensive evaluations show that GateScatter consistently achieves throughput above 200 kbps and range of over 27 m under diverse practical scenarios including a corridor, dormitory room, and under user mobility.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {54–66},
numpages = {13},
keywords = {backscatter, ZigBee, internet-of-things (IoT), wifi, BLE},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388942,
author = {Zhao, Jia and Gong, Wei and Liu, Jiangchuan},
title = {Towards Scalable Backscatter Sensor Mesh with Decodable Relay and Distributed Excitation},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388942},
doi = {10.1145/3386901.3388942},
abstract = {Backscatter communication, in which data is conveyed through reflecting excitation signals, has been advocated as a promising green technology for Internet of Things (IoT). Existing backscatter solutions however are mostly centralized, relying on a single excitation source, typically within one hop. Though recent works have demonstrated the viability of multi-hop backscatter, the excitation signal remains centralized, which attenuates quickly and fundamentally limits the communication scope. For long-range and high-quality communication, distributed excitations are expected and also naturally available as ambient signals (WiFi, BLE, cellular, FM, light, sound, etc.), albeit not being explored for boosting nearby tags for relaying.Given the existence of distributed excitation, a relay tag has to be decodable, i.e., be able to first decode its previous hop's information and then backscatter to the next hop with a boost from a nearby excitation whenever possible. In this paper, we present DecRel, a decodable tag relay solution towards a backscatter sensor mesh for universal and scalable deployment with distributed excitation. DecRel is also an innovative wireless sensor architecture for simultaneous sensing and relay. It incorporates a relay path that uses envelope detection for decoding, and a sensing path that converts its own sensor data into a baseband for amplitude-demodulation by the next hop tag's relay path. The two paths then backscatter their respective data to different frequencies to avoid interference. We have built a working DecRel tag prototype using FPGA, discrete components, and off-the-shelf analog devices. Our experiments show superior performance of DecRel as compared with the state-of-the-art non-decodable tag relay: specifically, a digital baseband's multi-hop throughput of up to 40Kbps (200x improvement), an analog baseband's equivalent multi-hop throughput of up to 768Kbps (3000x improvement), and a tag-to-tag distance of up to 4.8m (10x improvement) with a hop count of up to 6. DecRel tag consumes 337.9μW of power using IC design.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {67–79},
numpages = {13},
keywords = {decodable relay, backscatter, mesh networks, internet of things},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388918,
author = {Galisteo, Ander and Varshney, Ambuj and Giustiniano, Domenico},
title = {Two to Tango: Hybrid Light and Backscatter Networks for next Billion Devices},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388918},
doi = {10.1145/3386901.3388918},
abstract = {The growth rate of Internet-of-Things (IoT) devices sold globally is constantly lower than the forecast. This deceleration is caused in part by the need for batteries and the scalability cost for their replacement. Backscatter has attracted significant interest over the past couple of years to enable sustainable sensing devices by eliminating batteries. IoT devices have been designed for transmitting sensed data with backscatter, but the question of efficient reception of data with battery-free devices is still open. As shown in this paper, classical low-power Radio Frequency (RF) envelope detectors are affected by low sensitivity, false detection alarms, and low energy efficiency. We argue that Light Fidelity (LiFi) can provide downlink and harvesting medium as LED lights are becoming pervasively deployed for illumination. We show, for the first time, that the advantages of LiFi and RF backscatter can be combined for battery-free communication. We design a low-power platform that leverages the complementary nature of these two mediums. We demonstrate that our platform removes energy-inefficiency in the downlink reception typical of RF backscatter, and significantly expands the deployment scenarios for battery-free tags when compared to conventional single-technology designs.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {80–93},
numpages = {14},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389029,
author = {An, Zhenlin and Lin, Qiongzheng and Li, Ping and Yang, Lei},
title = {General-Purpose Deep Tracking Platform across Protocols for the Internet of Things},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389029},
doi = {10.1145/3386901.3389029},
abstract = {In recent years, considerable effort has been recently exerted to explore the high-precision RF-tracking systems indoors to satisfy various real-world demands. However, such systems are tailored for a particular type of device (e.g., RFID, WSN or Wi-Fi). With the rapid development of the Internet of Things (IoT), various new wireless protocols (e.g., LoRa, Sigfox, and NB-IoT) have been proposed to accommodate different demands. The coexistence of multiple types of IoT devices forces users to deploy multiple tracking systems in a warehouse or a smart home where various IoT devices are running, which causes huge additional costs in installation and maintenance. To address this issue, this work presents iArk, which is a general-purpose tracking platform for all types of IoT devices working at the ultra high frequency band. Our innovation lies in the design of the "K+1"-model hardware, the protocol free middleware, and the multipath resistant learnware. By the virtue of decoupling from wireless protocols, iArk also allows researchers to concentrate on developing a new tracking algorithm without considering the protocol diversity. To date, the platform can support five mainstream types of IoT devices (i.e., NB-IoT, LoRa, RFID, Sigfox and Zigbee) and is scalable to other types with minimal effort.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {94–106},
numpages = {13},
keywords = {deep learning, localization, internet of things},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388888,
author = {Cho, Haehyun and Park, Jinbum and Kim, Donguk and Zhao, Ziming and Shoshitaishvili, Yan and Doup\'{e}, Adam and Ahn, Gail-Joon},
title = {SmokeBomb: Effective Mitigation against Cache Side-Channel Attacks on the ARM Architecture},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388888},
doi = {10.1145/3386901.3388888},
abstract = {Cache side-channel attacks abuse microarchitectural designs meant to optimize memory access to infer information about victim processes, threatening data privacy and security. Recently, the ARM architecture has come into the spotlight of cache side-channel attacks with its unprecedented growth in the market.We propose SmokeBomb, a novel cache side-channel mitigation that functions by explicitly ensuring a private space for each process to safely access sensitive data. The heart of the idea is to use the L1 cache of the CPU core as a private space by which SmokeBomb can give consistent results against cache attacks on the sensitive data, and thus, an attacker cannot distinguish specific data used by the victim. Our experimental results show that SmokeBomb can effectively prevent currently formalized cache attack methods.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {107–120},
numpages = {14},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388939,
author = {Rathore, Aditya Singh and Zhu, Weijin and Daiyan, Afee and Xu, Chenhan and Wang, Kun and Lin, Feng and Ren, Kui and Xu, Wenyao},
title = {SonicPrint: A Generally Adoptable and Secure Fingerprint Biometrics in Smart Devices},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388939},
doi = {10.1145/3386901.3388939},
abstract = {The advent of smart devices has caused unprecedented security and privacy concerns to its users. Although the fingerprint technology is a go-to biometric solution in high-impact applications (e.g., smart-phone security, monetary transactions and international-border verification), the existing fingerprint scanners are vulnerable to spoofing attacks via fake-finger and cannot be employed across smart devices (e.g., wearables) due to hardware constraints. We propose SonicPrint that extends fingerprint identification beyond smartphones to any smart device without the need for traditional fingerprint scanners. SonicPrint builds on the fingerprint-induced sonic effect (FiSe) caused by a user swiping his fingertip on smart devices and the resulting property, i.e., different users' fingerprint would result in distinct FiSe. As the first exploratory study, extensive experiments verify the above property with 31 participants over four different swipe actions on five different types of smart devices with even partial fingerprints. SonicPrint achieves up to a 98% identification accuracy on smartphone and an equal-error-rate (EER) less than 3% for smartwatch and headphones. We also examine and demonstrate the resilience of SonicPrint against fingerprint phantoms and replay attacks. A key advantage of SonicPrint is that it leverages the already existing microphones in smart devices, requiring no hardware modifications. Compared with other biometrics including physiological patterns and passive sensing, SonicPrint is a low-cost, privacy-oriented and secure approach to identify users across smart devices of unique form-factors.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {121–134},
numpages = {14},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389023,
author = {Jang, Jinsoo and Kang, Brent Byunghoon},
title = {SelMon: Reinforcing Mobile Device Security with Self-Protected Trust Anchor},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389023},
doi = {10.1145/3386901.3389023},
abstract = {Higher privileged trust anchors such as thin hypervisors and Trust-Zone have been adopted to protect mobile OSs. For instance, the Samsung Knox security platform implements a kernel integrity monitor based on a hardware-assisted virtualization technique for 64-bit devices. Although it protects the OS kernel integrity, the monitoring platform itself can be a target of attackers if it encompasses exploitable bugs. In this paper, we propose SelMon, a portable way of self-protecting kernel integrity monitors without introducing another higher privileged trust anchor. To this end, we first logically separate the regions of the integrity monitor into two parts: privileged and non-privileged regions. Then, we ensure that only the privileged region code can access the critical data objects that can be exploited to compromise the monitor integrity (e.g., the hypervisor page table). The non-critical operations in terms of preserving the monitor integrity are conducted in the non-privileged region. In addition to the privilege separation, we also illustrate how to utilize the general hardware features, watchpoint and data execution prevention (DEP), to ensure the robustness of the separation. In the evaluation, it was found that our approach imposes a negligible overhead of 2% in the worst case with SPEC CPU2006.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {135–147},
numpages = {13},
keywords = {debug facility, mobile device security, privilege separation},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389030,
author = {Liu, Yihao and Huang, Kai and Song, Xingzhe and Yang, Boyuan and Gao, Wei},
title = {MagHacker: Eavesdropping on Stylus Pen Writing via Magnetic Sensing from Commodity Mobile Devices},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389030},
doi = {10.1145/3386901.3389030},
abstract = {Stylus pens have been widely used with today's mobile devices to provide a convenient handwriting input method, but also bring a unique security vulnerability that may unveil the user's handwriting contents to a nearby eavesdropper. In this paper, we present MagHacker, a new sensing system that realizes such eavesdropping attack over commodity mobile devices, which monitor and analyze the magnetic field being produced by the stylus pen's internal magnet. MagHacker divides the continuous magnetometer readings into small segments that represent individual letters, and then translates these readings into writing trajectories for letter recognition. Experiment results over realistic handwritings from multiple human beings demonstrate that MagHacker can accurately eavesdrop more than 80% of handwriting with stylus pens, from a distance of 10cm. Only slight degradation in such accuracy is produced when the eavesdropping distance or the handwriting speed increases. MagHacker is highly energy efficient, and can well adapt to different stylus pen models and environmental contexts.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {148–160},
numpages = {13},
keywords = {magnetic sensing, smartphones, eavesdropping, coordinate transformation, stylus pen},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388946,
author = {Mo, Fan and Shamsabadi, Ali Shahin and Katevas, Kleomenis and Demetriou, Soteris and Leontiadis, Ilias and Cavallaro, Andrea and Haddadi, Hamed},
title = {DarkneTZ: Towards Model Privacy at the Edge Using Trusted Execution Environments},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388946},
doi = {10.1145/3386901.3388946},
abstract = {We present DarkneTZ, a framework that uses an edge device's Trusted Execution Environment (TEE) in conjunction with model partitioning to limit the attack surface against Deep Neural Networks (DNNs). Increasingly, edge devices (smartphones and consumer IoT devices) are equipped with pre-trained DNNs for a variety of applications. This trend comes with privacy risks as models can leak information about their training data through effective membership inference attacks (MIAs).We evaluate the performance of DarkneTZ, including CPU execution time, memory usage, and accurate power consumption, using two small and six large image classification models. Due to the limited memory of the edge device's TEE, we partition model layers into more sensitive layers (to be executed inside the device TEE), and a set of layers to be executed in the untrusted part of the operating system. Our results show that even if a single layer is hidden, we can provide reliable model privacy and defend against state of the art MIAs, with only 3% performance overhead. When fully utilizing the TEE, DarkneTZ provides model protections with up to 10% overhead.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {161–174},
numpages = {14},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388947,
author = {Lee, Seulki and Nirjon, Shahriar},
title = {Fast and Scalable In-Memory Deep Multitask Learning via Neural Weight Virtualization},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388947},
doi = {10.1145/3386901.3388947},
abstract = {This paper introduces the concept of Neural Weight Virtualization - which enables fast and scalable in-memory multitask deep learning on memory-constrained embedded systems. The goal of neural weight virtualization is two-fold: (1) packing multiple DNNs into a fixed-sized main memory whose combined memory requirement is larger than the main memory, and (2) enabling fast in-memory execution of the DNNs. To this end, we propose a two-phase approach: (1) virtualization of weight parameters for fine-grained parameter sharing at the level of weights that scales up to multiple heterogeneous DNNs of arbitrary network architectures, and (2) in-memory data structure and run-time execution framework for in-memory execution and context-switching of DNN tasks. We implement two multitask learning systems: (1) an embedded GPU-based mobile robot, and (2) a microcontroller-based IoT device. We thoroughly evaluate the proposed algorithms as well as the two systems that involve ten state-of-the-art DNNs. Our evaluation shows that weight virtualization improves memory efficiency, execution time, and energy efficiency of the multitask learning systems by 4.1x, 36.9x, and 4.2x, respectively.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {175–190},
numpages = {16},
keywords = {multitask learning, deep neural network, virtualization, in-memory},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388948,
author = {Xu, Mengwei and Zhang, Xiwen and Liu, Yunxin and Huang, Gang and Liu, Xuanzhe and Lin, Felix Xiaozhu},
title = {Approximate Query Service on Autonomous IoT Cameras},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388948},
doi = {10.1145/3386901.3388948},
abstract = {Elf is a runtime for an energy-constrained camera to continuously summarize video scenes as approximate object counts. Elf's novelty centers on planning the camera's count actions under energy constraint. (1) Elf explores the rich action space spanned by the number of sample image frames and the choice of per-frame object counters; it unifies errors from both sources into one single bounded error. (2) To decide count actions at run time, Elf employs a learning-based planner, jointly optimizing for past and future videos without delaying result materialization. Tested with more than 1,000 hours of videos and under realistic energy constraints, Elf continuously generates object counts within only 11% of the true counts on average. Alongside the counts, Elf presents narrow errors shown to be bounded and up to 3.4X smaller than competitive baselines. At a higher level, Elf makes a case for advancing the geographic frontier of video analytics.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {191–205},
numpages = {15},
keywords = {approximate query, IoT cameras, video analytics},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389024,
author = {Lee, Youngmoon and He, Liang and Shin, Kang G.},
title = {Causes and Fixes of Unexpected Phone Shutoffs},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389024},
doi = {10.1145/3386901.3389024},
abstract = {Many users have reported that their smartphones shut off unexpectedly, even when they show &gt;30% remaining battery capacity. After examining the problem from both the user and phone sides, we discovered the cause of these unexpected shutoffs to be a large and dynamic internal voltage drop of the phone battery, which is, in turn, caused by the dynamics of both battery's internal resistance and the phone's discharge current. To fix these unexpected shutoffs, we design a novel Battery-aware Power Management (BPM) middleware that accounts for these dual-dynamics in phone operation. Specifically, BPM profiles the battery's internal resistance --- which varies with battery state-of-charge (SoC), temperature, and aging --- using a novel duty-cycled charging method. BPM then regulates, at run-time, the phone's discharge current based on the constructed battery profile. We have implemented and evaluated BPM on 4 commodity smartphones from different OEMs with the latest battery firmware, demonstrating that BPM prevents unexpected phone shutoffs and extends their operation time by 1.16--2.03X. Our user study, which includes 121 mobile phone users, also corroborates BPM's usefulness/attractiveness.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {206–219},
numpages = {14},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389027,
author = {Mirzamohammadi, Saeed and Liu, Yuxin (Myles) and Huang, Tianmei Ann and Sani, Ardalan Amiri and Agarwal, Sharad and Kim, Sung Eun (Summer)},
title = {Tabellion: Secure Legal Contracts on Mobile Devices},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389027},
doi = {10.1145/3386901.3389027},
abstract = {A legal contract is an agreement between two or more parties as to something that is to be done in the future. Forming contracts electronically is desirable since it is convenient. However, existing electronic contract platforms have a critical shortcoming. They do not provide strong evidence that a contract has been legally and validly created. More specifically, they do not provide strong evidence that an electronic signature is authentic, that there was mutual assent, and that the parties had an opportunity to read the contract. We present Tabellion, a system for forming legal contracts on mobile devices, such as smartphones and tablets, that addresses the above shortcoming. We define four secure primitives and use them in Tabellion to introduce self-evident contracts, the validity of which can be verified by independent inspectors. We show how these primitives can be implemented securely in the Trusted Execution Environment (TEE) of mobile devices as well as a secure enclave in a centralized server, all with a small Trusted Computing Base (TCB). Moreover, we demonstrate that it is feasible to build a fully functional contract platform on top of these primitives. We develop ~15,000 lines of code (LoC) for our prototype, only ~1,000 of which need to be trusted. Through analysis, prototype measurements, and a 30-person user study, we show that Tabellion is secure, achieves acceptable performance, and provides slightly better usability than the state-of-the-art electronic contract platform, DocuSign, for viewing and signing contracts.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {220–233},
numpages = {14},
keywords = {legal contract, trusted computing, mobile device, trusted execution environment (TEE), electronic signature, electronic contract},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388913,
author = {Tong, Shuai and Wang, Jiliang and Liu, Yunhao},
title = {Combating Packet Collisions Using Non-Stationary Signal Scaling in LPWANs},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388913},
doi = {10.1145/3386901.3388913},
abstract = {LoRa, a representative Low-Power Wide Area Network (LPWAN) technology, has been shown as a promising platform to connect Internet of Things. Practical LoRa deployments, however, suffer from collisions, especially in dense networks and wide coverage areas expected by LoRa applications. Existing collision resolution approaches do not exploit the coding properties of LoRa and thus cannot work well for low SNR LoRa signals. We propose NScale to decompose concurrent transmissions by leveraging subtle inter-packet time offsets for low SNR LoRa collisions. NScale (1) translates subtle time offsets, which are vulnerable to noise, to robust frequency features, and (2) further amplifies the time offsets by non-stationary signal scaling, i.e., scaling the amplitude of a symbol differently at different positions. In practical implementation, we propose a noise resistant iterative symbol recovery method to combat symbol distortion in low SNR, and address frequency shifts incurred by CFO and packet time offsets in decoding. We theoretically show that NScale introduces &lt; 1.7 dB SNR loss compared with the original LoRa. We implement NScale on USRP N210 and evaluate its performance in both indoor and outdoor networks. NScale is implemented in software at the gateway and can work for COTS LoRa nodes without any modification. The evaluation results show that NScale improves the network throughput by 3.3x for low SNR collided signals compared with other state-of-the-art methods.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {234–246},
numpages = {13},
keywords = {LPWAN, internet of things, collision resolution, LoRa},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388915,
author = {Balanuta, Artur and Pereira, Nuno and Kumar, Swarun and Rowe, Anthony},
title = {A Cloud-Optimized Link Layer for Low-Power Wide-Area Networks},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388915},
doi = {10.1145/3386901.3388915},
abstract = {Conventional wireless communication systems are typically designed assuming a single transmitter-receiver pair for each link. In Low-Power Wide-Area Networks (LP-WANs), this one-to-one design paradigm is often overly pessimistic in terms of link budget because client packets are frequently detected by multiple gateways (i.e. one-to-many). Prior work has shown massive improvement in performance when specialized hardware is used to coherently combine signals at the physical layer.In this paper, we explore the potential of using multiple receivers at the MAC and link layer where these performance gains are often neglected. We present an approach called Opportunistic Packet Recovery (OPR) that targets the most likely corrupt bits across a set of packets that suffered failed CRCs at multiple LoRa LP-WAN base-stations. We see that bit errors are often disjoint across receivers, which aids in collaborative error detection. OPR leverages this to provide increasing gain in error recovery as a function of the number of receiving gateways. Since LP-WAN networks can easily offload packet processing to the cloud, there is ample compute time per packet (order of seconds) to search for bit permutations that would restore packet integrity. Link layer corrections have the advantage of being immediately applicable to the millions of already deployed LP-WAN systems without additional hardware or expensive RF front-ends. We experimentally demonstrate that OPR can correct up to 72% of packets that would normally have failed, when they are captured by multiple gateways.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {247–259},
numpages = {13},
keywords = {cloud computing, interference mitigation, co-existence, low-power wide-area network (LPWAN)},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388941,
author = {Lei, Xinyu and Tu, Guan-Hua and Li, Chi-Yu and Xie, Tian and Zhang, Mi},
title = {SecWIR: Securing Smart Home IoT Communications via Wi-Fi Routers with Embedded Intelligence},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388941},
doi = {10.1145/3386901.3388941},
abstract = {Smart home Wi-Fi IoT devices are prevalent nowadays and potentially bring significant improvements to daily life. However, they pose an attractive target for adversaries seeking to launch attacks. Since the secure IoT communications are the foundation of secure IoT devices, this study commences by examining the extent to which mainstream security protocols are supported by 40 of the best selling Wi-Fi smart home IoT devices on the Amazon platform. It is shown that 29 of these devices have either no security protocols deployed, or have problematic security protocol implementations. Seemingly, these vulnerabilities can be easily fixed by installing security patches. However, many IoT devices lack the requisite software/hardware resources to do so. To address this problem, the present study proposes a SecWIR (Secure Wi-Fi IoT communication Router) framework designed for implementation on top of the users' existing home Wi-Fi routers to provide IoT devices with a secure IoT communication capability. However, it is way challenging for SecWIR to function effectively on all home Wi-Fi routers since some routers are resource-constrained. Thus, several novel techniques for resolving this implementation issue are additionally proposed. The experimental results show that SecWIR performs well on a variety of commercial off-the-shelf (COTS) Wi-Fi routers at the expense of only a small reduction in the non-IoT data service throughput (less than 8%), and small increases in the CPU usage (4.5%~7%), RAM usage (1.9 MB~2.2 MB), and the IoT device access delay (24 ms~154 ms) while securing 250 IoT devices.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {260–272},
numpages = {13},
keywords = {smart home, security, wi-fi, IoT},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388940,
author = {Wang, Ju and Chang, Liqiong and Aggarwal, Shourya and Abari, Omid and Keshav, Srinivasan},
title = {Soil Moisture Sensing with Commodity RFID Systems},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388940},
doi = {10.1145/3386901.3388940},
abstract = {Intelligent irrigation based on measurements of soil moisture levels in every pot in a greenhouse can not only improve plant productivity and quality but also save water. However, existing soil moisture sensors are too expensive to deploy in every pot. We therefore introduce GreenTag, a low-cost RFID-based soil moisture sensing system whose accuracy is comparable to that of an expensive soil moisture sensor. Our key idea is to attach two RFID tags to a plant's container so that changes in soil moisture content are reflected in their Differential Minimum Response Threshold (DMRT) metric at the reader. We show that a low-pass filtered DMRT metric is robust to changes both in the RF environment (e.g., from human movement) and in pot locations. In a realistic setting, GreenTag achieves a 90-percentile moisture estimation errors of 5%, which is comparable to the 4% errors using expensive soil moisture sensors. Moreover, this accuracy is maintained despite changes in the RF environment and container locations. We also show the effectiveness of GreenTag in a real greenhouse.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {273–285},
numpages = {13},
keywords = {greenhouse, soil moisture, RFID},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389025,
author = {Wang, Jiliang and Hu, Feng and Zhou, Ye and Liu, Yunhao and Zhang, Hanyi and Liu, Zhe},
title = {BlueDoor: Breaking the Secure Information Flow via BLE Vulnerability},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389025},
doi = {10.1145/3386901.3389025},
abstract = {Today's smart devices like fitness tracker, smartwatch, etc., often employ Bluetooth Low Energy (BLE) for data transmission. Such devices thus become our information portal, e.g., SMS message and notifications are delivered to those devices through BLE. In this study, we present BlueDoor, which can obtain unauthorized information from smart devices via BLE vulnerability. We thoroughly examine the BLE protocol, and leverage its intrinsic properties designed for low-cost embedded and wearable devices to bypass the encryption and authentication in BLE. By mimicking a low capacity device to downgrade the process of encryption key negotiation and authentication, BlueDoor can enforce a new key with the peripheral BLE device and pass the authentication without user participation. As a result, BlueDoor can extract BLE packets as well as read/write stored data on BLE devices. We show that BlueDoor works well on the fundamental design tradeoff of using BLE on diverse embedded and wearable devices, and thus can be generalized to various BLE devices. We implement the BlueDoor design and examine its performance on 15 COTS BLE enabled smart devices, including fitness trackers, smartwatch, smart bulb, etc. The results show that BlueDoor can break the information flow and obtain different types of information (e.g., SMS message, notifications) delivered to BLE devices. In addition to privacy threats, this further means traditional operations such as using SMS for verification in widely adopted authentication, are insecure.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {286–298},
numpages = {13},
keywords = {bluetooth low energy, security, BLE},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388912,
author = {He, Songtao and Bastani, Favyen and Balasingam, Arjun and Gopalakrishna, Karthik and Jiang, Ziwen and Alizadeh, Mohammad and Balakrishnan, Hari and Cafarella, Michael and Kraska, Tim and Madden, Sam},
title = {BeeCluster: Drone Orchestration via Predictive Optimization},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388912},
doi = {10.1145/3386901.3388912},
abstract = {The rapid development of small aerial drones has enabled numerous drone-based applications, e.g., geographic mapping, air pollution sensing, and search and rescue. To assist the development of these applications, we propose BeeCluster, a drone orchestration system that manages a fleet of drones. BeeCluster provides a virtual drone abstraction that enables developers to express a sequence of geographical sensing tasks, and determines how to map these tasks to the fleet efficiently. BeeCluster's core contribution is predictive optimization, in which an inferred model of the future tasks of the application is used to generate an optimized flight and sensing schedule for the drones that aims to minimize the total expected execution time.We built a prototype of BeeCluster and evaluated it on five real-world case studies with drones in outdoor environments, measuring speedups from 11.6% to 23.9%.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {299–311},
numpages = {13},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388944,
author = {Ibrahim, Mohamed and Rostami, Ali and Yu, Bo and Liu, Hansi and Jawahar, Minitha and Nguyen, Viet and Gruteser, Marco and Bai, Fan and Howard, Richard},
title = {Wi-Go: Accurate and Scalable Vehicle Positioning Using WiFi Fine Timing Measurement},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388944},
doi = {10.1145/3386901.3388944},
abstract = {Driver assistance and vehicular automation would greatly benefit from uninterrupted lane-level vehicle positioning, especially in challenging environments like metropolitan cities. In this paper, we explore whether the WiFi Fine Time Measurement (FTM) protocol, with its robust, accurate ranging capability, can complement current GPS and odometry systems to achieve lane-level positioning in urban canyons. We introduce Wi-Go, a system that simultaneously tracks vehicles and maps WiFi access point positions by coherently fusing WiFi FTMs, GPS, and vehicle odometry information together. Wi-Go also adaptively controls the FTM messaging rate from clients to prevent high bandwidth usage and congestion, while maximizing the tracking accuracy. Wi-Go achieves lane-level vehicle positioning (1.3 m median and 2.9 m 90-percentile error), an order of magnitude improvement over vehicle built-in GPS, through vehicle experiments in the urban canyons of Manhattan, New York City, as well as in suburban areas (0.8 m median and 3.2 m 90-percentile error).},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {312–324},
numpages = {13},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389033,
author = {Ben Ali, Ali J. and Hashemifar, Zakieh Sadat and Dantu, Karthik},
title = {Edge-SLAM: Edge-Assisted Visual Simultaneous Localization and Mapping},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389033},
doi = {10.1145/3386901.3389033},
abstract = {Localization in urban environments is becoming increasingly important and used in tools such as ARCore [11], ARKit [27] and others. One popular mechanism to achieve accurate indoor localization as well as a map of the space is using Visual Simultaneous Localization and Mapping (Visual-SLAM). However, Visual-SLAM is known to be resource-intensive in memory and processing time. Further, some of the operations grow in complexity over time, making it challenging to run on mobile devices continuously. Edge computing provides additional compute and memory resources to mobile devices to allow offloading of some tasks without the large latencies seen when offloading to the cloud. In this paper, we present Edge-SLAM, a system that uses edge computing resources to offload parts of Visual-SLAM. We use ORB-SLAM2 as a prototypical Visual-SLAM system and modify it to a split architecture between the edge and the mobile device. We keep the tracking computation on the mobile device and move the rest of the computation, i.e., local mapping and loop closure, to the edge. We describe the design choices in this effort and implement them in our prototype. Our results show that our split architecture can allow the functioning of the Visual-SLAM system long-term with limited resources without affecting the accuracy of operation. It also keeps the computation and memory cost on the mobile device constant which would allow for deployment of other end applications that use Visual-SLAM.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {325–337},
numpages = {13},
keywords = {mapping, edge computing, visual simultaneous localization and mapping, mobile systems, split architecture, localization},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388950,
author = {Kassem, Mohamed M. and Kheirkhah, Morteza and Marina, Mahesh K. and Buneman, Peter},
title = {WhiteHaul: An Efficient Spectrum Aggregation System for Low-Cost and High Capacity Backhaul over White Spaces},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388950},
doi = {10.1145/3386901.3388950},
abstract = {We address the challenge of backhaul connectivity for rural and developing regions, which is essential for universal fixed/mobile Internet access. To this end, we propose to exploit the TV white space (TVWS) spectrum for its attractive properties: low cost, abundance in under-served regions and favorable propagation characteristics. Specifically, we propose a system called WhiteHaul for the efficient aggregation of the TVWS spectrum tailored for the backhaul use case. At the core of WhiteHaul are two key innovations: (i) a TVWS conversion substrate that can efficiently handle multiple non-contiguous chunks of TVWS spectrum using multiple low cost 802.11n/ac cards but with a single antenna; (ii) novel use of MPTCP as a link-level tunnel abstraction and its use for efficiently aggregating multiple chunks of the TVWS spectrum via a novel uncoupled, cross-layer congestion control algorithm. Through extensive evaluations using a prototype implementation of WhiteHaul, we show that: (a) WhiteHaul can aggregate almost the whole of TV band with 3 interfaces and achieve nearly 600Mbps TCP throughput; (b) the WhiteHaul MPTCP congestion control algorithm provides an order of magnitude improvement over state of the art algorithms for typical TVWS backhaul links. We also present additional measurement and simulation based results to evaluate other aspects of the WhiteHaul design.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {338–351},
numpages = {14},
keywords = {multipath TCP, universal internet access, TV white space spectrum, rural connectivity, backhaul, spectrum aggregation},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389026,
author = {Reynders, Brecht and Minucci, Franco and Perenda, Erma and Sallouha, Hazem and Calvo-Palomino, Roberto and Lizarribar, Yago and Fuchs, Markus and Sch\"{a}fer, Matthias and Engel, Markus and Van den Bergh, Bertold and Pollin, Sofie and Giustiniano, Domenico and Bovet, G\'{e}r\^{o}me and Lenders, Vincent},
title = {SkySense: Terrestrial and Aerial Spectrum Use Analysed Using Lightweight Sensing Technology with Weather Balloons},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389026},
doi = {10.1145/3386901.3389026},
abstract = {Given the availability of lightweight radio and processing technology, it becomes feasible to imagine spectrum sensing systems using weather balloons. Such balloons navigate the airspace up to 40 km, and can provide a bird's eye and clear view of terrestrial, as well as aerial spectrum use. In this paper, we present SkySense, which is an extension of the Electrosense sensing framework with mobile GPS-located sensors and local data logging. In addition, we present 6 different sensing campaigns, targeting multiple terrestrial or aerial technologies such as ADS-B, AIS or LTE. For instance, for ADS-B, we can clearly conclude that the number of airplanes that are detected is the same for each balloon altitude, but the message reception rate decreases strongly with altitude because of collisions. For each sensing campaign, the dataset is described, and some example spectrum analysis results are presented. In addition, we analyse and quantify important trends visible when sensing from the sky, such as temperature and hardware variations, increased ambient interference levels, as well as hardware limitations of the lightweight system. A key challenge is the automatic gain control and dynamic range of the system, as a radio navigating over 30km, sees a very wide range of possible signal levels. All data is publicly available through the Electrosense framework, to encourage the spectrum sensing community to further analyse the data or motivate further measurement campaigns using weather balloons.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {352–363},
numpages = {12},
keywords = {skysense, balloon, HAB, spectrum sensing},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388943,
author = {Zhu, Xiao and Sun, Jiachen and Zhang, Xumiao and Guo, Y. Ethan and Qian, Feng and Mao, Z. Morley},
title = {MPBond: Efficient Network-Level Collaboration among Personal Mobile Devices},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388943},
doi = {10.1145/3386901.3388943},
abstract = {MPBond is an efficient system allowing multiple personal mobile devices to collaboratively fetch content from the Internet. For example, a smartwatch can assist its paired smartphone with downloading data. Inspired by the success of MPTCP, MPBond applies the concept of distributed multipath transport where multiple subflows can traverse different devices. We develop a cross-device connection management scheme, a buffering strategy, a packet scheduling algorithm, and a policy framework tailored to MPBond's architecture. We implement MPBond on commodity mobile devices such as Android smartphones and smartwatches. Our real-world evaluations using different workloads under various network conditions demonstrate the efficiency of MPBond. Compared to state-of-the-art collaboration frameworks, MPBond reduces file download time by 5% to 46%, and improves the video streaming bitrate by 2% to 118%. Meanwhile, it improves the energy efficiency by 10% to 57%.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {364–376},
numpages = {13},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388911,
author = {Lee, Jinsung and Lee, Sungyong and Lee, Jongyun and Sathyanarayana, Sandesh Dhawaskar and Lim, Hyoyoung and Lee, Jihoon and Zhu, Xiaoqing and Ramakrishnan, Sangeeta and Grunwald, Dirk and Lee, Kyunghan and Ha, Sangtae},
title = {PERCEIVE: Deep Learning-Based Cellular Uplink Prediction Using Real-Time Scheduling Patterns},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388911},
doi = {10.1145/3386901.3388911},
abstract = {As video calls and personal broadcasting become popular, the demand for mobile live streaming over cellular uplink channels is growing fast. However, current live streaming solutions are known to suffer from frequent uplink throughput fluctuations causing unnecessary video stalls and quality drops. As a remedy to this problem, we propose PERCEIVE, a deep learning-based uplink throughput prediction framework. PERCEIVE exploits a 2-stage LSTM (Long Short Term Memory) design and makes throughput predictions for the next 100ms. Our extensive evaluations show that PERCEIVE, trained with LTE network traces from three major operators in the U.S., achieves high accuracy in the uplink throughput prediction with only 7.67% mean absolute error and outperforms existing prediction techniques. We integrate PERCEIVE with WebRTC, a popular video streaming platform from Google, as a rate adaptation module. Our implementation on the Android phone demonstrates that it can improve PSNR by up to 6dB (4x) over the default WebRTC while providing less streaming latency.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {377–390},
numpages = {14},
keywords = {deep learning, LTE, cellular uplink, live video},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388916,
author = {Yi, Edgardo Barsallo and Zhang, Heng and Maji, Amiya K. and Xu, Kefan and Bagchi, Saurabh},
title = {Vulcan: Lessons on Reliability of Wearables through State-Aware Fuzzing},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388916},
doi = {10.1145/3386901.3388916},
abstract = {As we look to use Wear OS (formerly known as Android Wear) devices for fitness and health monitoring, it is important to evaluate the reliability of its ecosystem. The goal of this paper is to understand the reliability weak spots in Wear OS ecosystem. We develop a state-aware fuzzing tool, Vulcan, without any elevated privileges, to uncover these weak spots by fuzzing Wear OS apps. We evaluate the outcomes due to these weak spots by fuzzing 100 popular apps downloaded from Google Play Store. The outcomes include causing specific apps to crash, causing the running app to become unresponsive, and causing the device to reboot. We finally propose a proof-of-concept mitigation solution to address the system reboot issue.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {391–403},
numpages = {13},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389032,
author = {Pham, Nhat and Dinh, Tuan and Raghebi, Zohreh and Kim, Taeho and Bui, Nam and Nguyen, Phuc and Truong, Hoang and Banaei-Kashani, Farnoush and Halbower, Ann and Dinh, Thang and Vu, Tam},
title = {WAKE: A behind-the-Ear Wearable System for Microsleep Detection},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389032},
doi = {10.1145/3386901.3389032},
abstract = {Microsleep, caused by sleep deprivation, sleep apnea, and narcolepsy, costs the U.S.'s economy more than $411 billion/year because of work performance reduction, injuries, and traffic accidents. Mitigating microsleep's consequences require an unobtrusive, reliable, and socially acceptable microsleep detection solution throughout the day, every day. Unfortunately, existing solutions do not meet these requirements.In this paper, we propose a novel behind-the-ear wearable device for microsleep detection, called WAKE. WAKE detects microsleep by monitoring biosignals from the brain, eye movements, facial muscle contractions, and sweat gland activities from behind the user's ears. In particular, we introduce a Three-fold Cascaded Amplifying (3CA) technique to tame the motion artifacts and environmental noises for capturing high fidelity signals. The behind-the-ear form factor is motivated by the fact that bone-conductance headphones, which are worn around the ear, are becoming widely used. This technology trend gives us an opportunity to enable a wide range of cognitive monitoring and improvement applications by integrating more sensing and actuating functionality into the ear-phone, making it a smarter one.Through our prototyping, we show that WAKE can suppress motion and environmental noise in real-time by 9.74-19.47 dB while walking, driving, or staying in different environments ensuring that the biosignals are captured reliably. We evaluated WAKE against gold-standard devices on 19 sleep-deprived and narcoleptic subjects. The Leave-One-Subject-Out Cross-Validation results show the feasibility of WAKE in microsleep detection on an unseen subject with average precision and recall of 76% and 85%, respectively.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {404–418},
numpages = {15},
keywords = {microsleep detection, fatigue supervising, cyber-physical systems, wearable devices, behind-the-ear sensing, drowsiness monitoring},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389022,
author = {Truong, Hoang and Bui, Nam and Raghebi, Zohreh and Ceko, Marta and Pham, Nhat and Nguyen, Phuc and Nguyen, Anh and Kim, Taeho and Siegfried, Katrina and Stene, Evan and Tvrdy, Taylor and Weinman, Logan and Payne, Thomas and Burke, Devin and Dinh, Thang and D'Mello, Sidney and Banaei-Kashani, Farnoush and Wager, Tor and Goldstein, Pavel and Vu, Tam},
title = {Painometry: Wearable and Objective Quantification System for Acute Postoperative Pain},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389022},
doi = {10.1145/3386901.3389022},
abstract = {Over 50 million people undergo surgeries each year in the United States, with over 70% of them filling opioid prescriptions within one week of the surgery. Due to the highly addictive nature of these opiates, a post-surgical window is a crucial time for pain management to ensure accurate prescription of opioids. Drug prescription nowadays relies primarily on self-reported pain levels to determine the frequency and dosage of pain drug. Patient pain self-reports are, however, influenced by subjective pain tolerance, memories of past painful episodes, current context, and the patient's integrity in reporting their pain level. Therefore, objective measures of pain are needed to better inform pain management.This paper explores a wearable system, named Painometry, which objectively quantifies users' pain perception based-on multiple physiological signals and facial expressions of pain. We propose a sensing technique, called sweep impedance profiling (SIP), to capture the movement of the facial muscle corrugator supercilii, one of the important physiological expressions of pain. We deploy SIP together with other biosignals, including electroencephalography (EEG), photoplethysmogram (PPG), and galvanic skin response (GSR) for pain quantification.From the anatomical and physiological correlations of pain with these signals, we designed Painometry, a multimodality sensing system, which can accurately quantify different levels of pain safely. We prototyped Painometry by building a custom hardware, firmware, and associated software. Our evaluations use the prototype on 23 subjects, which corresponds to 8832 data points from 276 minutes of an IRB-approved experimental pain-inducing protocol. Using leave-one-out cross-validation to estimate performance on unseen data shows 89.5% and 76.7% accuracy of quantification under 3 and 4 pain states, respectively.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {419–433},
numpages = {15},
keywords = {opioid overdose, impedance sensing, pain quantification},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3389028,
author = {Zhang, Hanbin and Guo, Gabriel and Comstock, Emery and Chen, Baicheng and Chen, Xingyu and Song, Chen and Ajay, Jerry and Langan, Jeanne and Bhattacharjya, Sutanuka and Cavuoto, Lora A and Xu, Wenyao},
title = {RehabPhone: A Software-Defined Tool Using 3D Printing and Smartphones for Personalized Home-Based Rehabilitation},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389028},
doi = {10.1145/3386901.3389028},
abstract = {Approximately 7 million survivors of stroke reside in the United States. Over half of these individuals will have residual deficits, making stroke one of the leading causes of disability. Long-term rehabilitation opportunities are critical for millions of individuals with chronic upper limb motor deicits due to stroke. Traditional in-home rehabilitation is reported to be dull, boring, and un-engaging. Moreover, existing rehabilitation technologies are not user-friendly and cannot be adaptable to different and ever-changing demands from individual stroke survivors. In this work, we present RehabPhone, a highly-usable software-defined stroke rehabilitation paradigm using the smartphone and 3D printing technologies. This software-definition has twofold. First, RehabPhone leverages the cost-effective 3D printing technology to augment ordinal smartphones into customized rehabilitation tools. The size, weight, and shape of rehabilitation tools are software-defined according to individual rehabilitation needs and goals. Second, RehabPhone integrates 13 functional rehabilitation activities co-designed with stroke professionals into a smartphone APP. The software utilizes built-in smartphone sensors to analyzes rehabilitation activities and provides real-time feedback to coach and engage stroke users. We perform the in-lab usability optimization with the RehabPhone prototype with involving 16 healthy adults and 4 stroke survivors. After that, we conduct a 6-week unattended intervention study in 12 homes of stroke residence. In the course of the clinical study, over 32,000 samples of physical rehabilitation activities are collected and evaluated. Results indicate that stroke users with RehabPhone demonstrate a high adherence and clinical efficacy in a self-managed home-based rehabilitation course. To the best of our knowledge, this is the first exploratory clinical study using mobile health technologies in real-world stroke rehabilitation.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {434–447},
numpages = {14},
keywords = {stroke rehabilitation, smartphone, mobile health, 3D printing},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3388917,
author = {Wu, Hao and Feng, Jinghao and Tian, Xuejin and Sun, Edward and Liu, Yunxin and Dong, Bo and Xu, Fengyuan and Zhong, Sheng},
title = {EMO: Real-Time Emotion Recognition from Single-Eye Images for Resource-Constrained Eyewear Devices},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3388917},
doi = {10.1145/3386901.3388917},
abstract = {Real-time user emotion recognition is highly desirable for many applications on eyewear devices like smart glasses. However, it is very challenging to enable this capability on such devices due to tightly constrained image contents (only eye-area images available from the on-device eye-tracking camera) and computing resources of the embedded system. In this paper, we propose and develop a novel system called EMO that can recognize, on top of a resource-limited eyewear device, real-time emotions of the user who wears it. Unlike most existing solutions that require whole-face images to recognize emotions, EMO only utilizes the single-eye-area images captured by the eye-tracking camera of the eyewear. To achieve this, we design a customized deep-learning network to effectively extract emotional features from input single-eye images and a personalized feature classifier to accurately identify a user's emotions. EMO also exploits the temporal locality and feature similarity among consecutive video frames of the eye-tracking camera to further reduce the recognition latency and system resource usage. We implement EMO on two hardware platforms and conduct comprehensive experimental evaluations. Our results demonstrate that EMO can continuously recognize seven-type emotions at 12.8 frames per second with a mean accuracy of 72.2%, significantly outperforming the state-of-the-art approach, and consume much fewer system resources.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {448–461},
numpages = {14},
keywords = {deep learning, eyewear devices, emotion recognition, single-eye images, visual sensing},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3396598,
author = {Zhang, Anlan and Wang, Chendong and Liu, Xing and Han, Bo and Qian, Feng},
title = {Mobile Volumetric Video Streaming Enhanced by Super Resolution},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3396598},
doi = {10.1145/3386901.3396598},
abstract = {Volumetric videos allow viewers to exercise 6-DoF (degrees of freedom) movement when watching them. Due to their true 3D nature, streaming volumetric videos is highly bandwidth demanding. In this work, we present to our knowledge a first volumetric video streaming system that leverages deep super resolution (SR) to boost the video quality on commodity mobile devices. We propose a series of judicious optimizations to make SR efficient on mobile devices.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {462–463},
numpages = {2},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3396599,
author = {Nishiyama, Taiga and Yoshikawa, Daichi and Nishio, Nobuhiko and Tsubouchi, Kota},
title = {AirPlanes: A DIY Modeling System Using Mobile VSLAM for Indoor Space},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3396599},
doi = {10.1145/3386901.3396599},
abstract = {There is growing interest in using augmented reality technology for gaming, navigation, and remote communication. Although 3D space models can be made manually or digitalized using specialized and expensive sensing devices like LiDAR (Light Detection and Ranging), which are costly and time-consuming, the recently developed ARCore for Android and ARkit for iOS are convenient and quick means of developing AR applications. Their recognition performance is poor for flat and monotone walls. This drawback is significant because most walls in indoor environments are flat and only a small portion of them are colorful enough to detect feature points.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {464–465},
numpages = {2},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3396602,
author = {Salehnamadi, Navid and Alshayban, Abdulaziz and Ahmed, Iftekhar and Malek, Sam},
title = {A Benchmark for Event-Race Analysis in Android Apps},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3396602},
doi = {10.1145/3386901.3396602},
abstract = {Over the past few years, researchers have proposed various program analysis tools for automated detection of event-race conditions in Android. However, to this date, it is not clear how these tools compare to one another, as they have been evaluated on arbitrary, disjointed set of Android apps, for which there is no ground truth, i.e., verified set of event races. To fill this gap and support future research in this area, we introduce BenchERoid, a set of 34 Android apps with injected event-race bugs. The current version of benchmark contains 36 types of event-race bugs that were identified by analyzing Android concurrency literature and publicly available issue repositories. We believe that our framework is a valuable resource for both developers and researchers interested in concurrency bug analysis in Android. BenchERoid is publicly available at: https://github.com/seal-hub/bencheroid.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {466–467},
numpages = {2},
keywords = {benchmark, concurrency, event-race, android},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3396603,
author = {Zhang, Junbo and Kumar, Swarun},
title = {NoFaceContact: Stop Touching Your Face with NFC},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3396603},
doi = {10.1145/3386901.3396603},
abstract = {Coronavirus disease 2019, known as COVID-19, has spread rapidly and infected millions of people around the world. In addition to respiratory droplet spreading, a common mode of contraction of this virus is when individuals touch their face after coming into contact with a contaminated surface. In this poster, we leverage near-field communication (NFC) and propose a system design, NoFaceContact, which can promptly warn users when they attempt to touch their face with the aim of helping to reduce the spread of COVID-19 and improve overall hygiene. A proof-of-concept experiment shows that NoFaceContact can achieve an average communication distance of 8.07 cm and can potentially detect a wide range of face touching poses.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {468–469},
numpages = {2},
keywords = {near-field communication, RSSI},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3396604,
author = {Bansal, Atul and Kumar, Swarun and Iannucci, Bob},
title = {Does Ambient RF Energy Suffice to Power Battery-Free IoT?},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3396604},
doi = {10.1145/3386901.3396604},
abstract = {Recent years have witnessed novel designs of battery-free IoT tags using RF backscatter. Traditionally, they require a dedicated transmitter to excite the tag. However, such a deployment is infeasible at large scale. To counter this problem, researchers have proposed using ambient RF energy to power up the battery-free tag. In this poster, we evaluate if this ambient RF energy is sufficient to meet the power requirements of a battery-free tag in today's urban and rural areas. We also compare available ambient RF energy across different frequencies. Finally, we discuss open challenges in realising ambient backscatter systems in real-world.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {470–471},
numpages = {2},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3396605,
author = {Nasirifar, Mohammad and Brown, Angela Demke},
title = {Deduplicating Future Data Transfer Using Data Exchanged in the Past to Decrease Mobile Bandwidth Usage},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3396605},
doi = {10.1145/3386901.3396605},
abstract = {In client-server architectures, there are cases where there is a need to transfer large amounts of data from the server to the client (or less frequently, in the opposite direction). Mobile application markets are a notable example where the clients need to download large chunks of data in the order of megabytes at a time, compared to a typical RPC request which is in the order of kilobytes.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {472–473},
numpages = {2},
keywords = {deduplication, compression},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3396606,
author = {Huang, Tzu-Heng and Tsai, Cheng-Hsien and Shan, Man-Kwan},
title = {Key Sensor Discovery for Quality Audit of Air Sensor Networks},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3396606},
doi = {10.1145/3386901.3396606},
abstract = {Air quality has impacts on our health and environment extremely. To monitor air pollutants, with the maturity of wireless sensor network, low-cost air sensors are deployed to trace pollution sources and detect personal exposure. Regular quality audit of deployed sensors is essential to ensure data quality of large-scale air monitoring networks. However, inspecting tremendous sensors by professional technicians regularly will take much human resources. This paper proposed the key sensor discovery for efficient and effective quality audit of large-scale air sensor network.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {474–475},
numpages = {2},
keywords = {air monitoring sensor network, quality audit, correlation model, key sensor},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3396600,
author = {Zhu, Xiao and Sun, Jiachen and Zhang, Xumiao and Guo, Yihua Ethan and Qian, Feng and Mao, Z. Morley},
title = {MPBond: Efficient Network-Level Collaboration among Personal Mobile Devices},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3396600},
doi = {10.1145/3386901.3396600},
abstract = {We demo MPBond, a novel multipath transport system allowing multiple personal mobile devices to collaboratively fetch content from the Internet. Inspired by the success of MPTCP, MPBond applies the concept of distributed multipath transport where multiple subflows can traverse different devices. Other key design aspects of MPBond include a device/connection management scheme, a buffering strategy, a packet scheduling algorithm, and a policy framework tailored to MPBond's architecture. We install MPBond on commodity mobile devices and show how easy it is to configure the usage of MPBond for unmodified apps. We visualize the runtime behavior of MPBond to further illustrate its design. We also demonstrate the download time and energy reduction of file download, as well as the video streaming QoE improvement with MPBond.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {476–477},
numpages = {2},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3396601,
author = {Prabhakara, Akarsh and Singh, Vaibhav and Kumar, Swarun and Rowe, Anthony},
title = {Osprey Demo: A Mmwave Approach to Tire Wear Sensing},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3396601},
doi = {10.1145/3386901.3396601},
abstract = {In this paper, we demonstrate Osprey, a tire wear sensor presented in [4]. Osprey makes use of commodity automotive, mmWave RADAR, places it in the tire well of automobiles to image the tire and then measures the tire wear. Osprey measures accurate tire wear continuously while being resilient to road debris and without embedding any electronics in tires. Osprey achieves this by building a super resolution algorithm based on Inverse Synthetic Aperture RADAR imaging and by embedding thin metallic strips along coded patterns in the grooves to combat debris. Here, we implement Osprey on a tire rotation rig and demonstrate the ability to measure tire wear (with and without debris) accurately and detect potentially harmful foreign objects.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {478–479},
numpages = {2},
keywords = {RADAR, wireless sensing, free of electronics, inverse synthetic aperture RADAR imaging, super resolution, spatial coding, automotive, millimeter wave, orthogonal codes, tread depth, 77 GHz, FMCW, tire wear, foreign object, debris},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3386901.3397492,
author = {Yi, Edgardo Barsallo and Zhang, Heng and Maji, Amiya K. and Bagchi, Saurabh},
title = {Vulcan: A State-Aware Fuzzing Tool for Wear OS Ecosystem},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3397492},
doi = {10.1145/3386901.3397492},
abstract = {This demo abstract introduces Vulcan, a fuzz testing tool for evaluating the robustness of wearable device by injecting intra-device and inter-device communication messages. Vulcan first builds a state-model of a wearable app by offline training then steers the app to a target state for injecting mutated messages. The target state of the app typically runs a high number of concurrent processes. By testing a set of 100 popular Wear OS apps, Vulcan was able to trigger 45 unique crashes and 18 system reboots. These system reboots are triggered by a fuzzing user-level app and we present a mitigation strategy to prevent it.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {480–481},
numpages = {2},
keywords = {Wear OS, reliability, wearable, android, fuzzer},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inproceedings{10.1145/3340948,
author = {Lv, Qin (Christine)},
title = {Session Details: Session 1: On the Horizon},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340948},
doi = {10.1145/3340948},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326077,
author = {Zhang, Chi and Kumar, Sidharth and Bharadia, Dinesh},
title = {Capttery: Scalable Battery-like Room-Level Wireless Power},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326077},
doi = {10.1145/3307334.3326077},
abstract = {Internet-of-things (IoT) devices are becoming widely adopted, but they increasingly suffer from limited power, as power cords cannot reach the billions and batteries do not last forever. Existing systems address the issue with ultra-low-power designs and energy scavenging, which inevitably limit functionality. To unlock the full potential of ubiquitous computing and connectivity, our solution uses capacitive power transfer (CPT) to provide battery-like wireless power delivery, henceforth referred to as "Capttery". Capttery presents the first room-level (~5 m) CPT system, which delivers continuous milliwatt-level wireless power to multiple IoT devices concurrently. Unlike conventional one-to-one CPT systems that target kilowatt power in a controlled and potentially hazardous setup, Capttery is designed to be human-safe and invariant in a practical and dynamic environment. Our evaluation shows that Capttery can power end-to-end IoT applications across a typical room, where new receivers can be easily added in a plug-and-play manner.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {1–13},
numpages = {13},
keywords = {internet-of-things, energy harvesting, capacitive power transfer (cpt), wireless power transfer (wpt)},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326073,
author = {Xu, Chenhan and Li, Zhengxiong and Zhang, Hanbin and Rathore, Aditya Singh and Li, Huining and Song, Chen and Wang, Kun and Xu, Wenyao},
title = {WaveEar: Exploring a MmWave-Based Noise-Resistant Speech Sensing for Voice-User Interface},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326073},
doi = {10.1145/3307334.3326073},
abstract = {Voice-user interface (VUI) has become an integral component in modern personal devices (textite.g., smartphones, voice assistant) by fundamentally evolving the information sharing between the user and device. Acoustic sensing for VUI is designed to sense all acoustic objects; however, the existing VUI mechanism can only offer low-quality speech sensing. This is due to the audible and inaudible interference from complex ambient noise that limits the performance of VUI by causing denial-of-service (DoS) of user requests. Therefore, it is of paramount importance to enable noise-resistant speech sensing in VUI for executing critical tasks with superior efficiency and precision in robust environments. To this end, we investigate the feasibility of employing radio-frequency signals, such as millimeter wave (mmWave) for sensing the noise-resistant voice of an individual. We first perform an in-depth study behind the rationale of voice generation and resulting vocal vibrations. From the obtained insights, we presentWaveEar, an end-to-end noise-resistant speech sensing system.WaveEar comprises a low-cost mmWave probe to localize the position of the speaker among multiple people and direct the mmWave signals towards the near-throat region of the speaker for sensing his/her vocal vibrations. The received signal, containing the speech information, is fed to our novel deep neural network for recovering the voice through exhaustive extraction. Our experimental evaluation under real-world scenarios with 21 participants shows the effectiveness ofWaveEar to precisely infer the noise-resistant voice and enable a pervasive VUI in modern electronic devices.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {14–26},
numpages = {13},
keywords = {voice-user interface, speech recognition, mmwave, neural network},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326071,
author = {Cao, Qingqing and Weber, Noah and Balasubramanian, Niranjan and Balasubramanian, Aruna},
title = {DeQA: On-Device Question Answering},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326071},
doi = {10.1145/3307334.3326071},
abstract = {Today there is no effective support for device-wide question answering on mobile devices. State-of-the-art QA models are deep learning behemoths designed for the cloud which run extremely slow and require more memory than available on phones. We present DeQA, a suite of latency- and memory- optimizations that adapts existing QA systems to run completely locally on mobile phones. Specifically, we design two latency optimizations that (1) stops processing documents if further processing cannot improve answer quality, and (2) identifies computation that does not depend on the question and moves it offline. These optimizations do not depend on the QA model internals and can be applied to several existing QA models. DeQA also implements a set of memory optimizations by (i) loading partial indexes in memory, (ii) working with smaller units of data, and (iii) replacing in-memory lookups with a key-value database. We use DeQA to port three state-of-the-art QA systems to the mobile device and evaluate over three datasets. The first is a large scale SQuAD dataset defined over Wikipedia collection. We also create two on-device QA datasets, one over a publicly available email data collection and the other using a cross-app data collection we obtain from two users. Our evaluations show that DeQA can run QA models with only a few hundred MBs of memory and provides at least 13x speedup on average on the mobile phone across all three datasets.% with less than a 1% drop in accuracy.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {27–40},
numpages = {14},
keywords = {mobile systems, question answering, mobile devices},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326091,
author = {Meegahapola, Lakmal and Kandappu, Thivya and Jayarajah, Kasthuri and Akoglu, Leman and Xiang, Shili and Misra, Archan},
title = {BuScope: Fusing Individual &amp; Aggregated Mobility Behavior for "Live" Smart City Services},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326091},
doi = {10.1145/3307334.3326091},
abstract = {While analysis of urban commuting data has a long and demonstrated history of providing useful insights into human mobility behavior, such analysis has been performed largely in offline fashion and to aid medium-to-long term urban planning. In this work, we demonstrate the power of applying predictive analytics on real-time mobility data, specifically the smart-card generated trip data of millions of public bus commuters in Singapore, to create two novel and "live" smart city services. The key analytical novelty in our work lies in combining two aspects of urban mobility: (a) conformity: which reflects the predictability in the aggregated flow of commuters along bus routes, and (b) regularity: which captures the repeated trip patterns of each individual commuter. We demonstrate that the fusion of these two measures of behavior can be performed at city-scale using our BuScope platform, and can be used to create two innovative smart city applications. The Last-Mile Demand Generator provides O(mins) lookahead into the number of disembarking passengers at neighborhood bus stops; it achieves over 85% accuracy in predicting such disembarkations by an ingenious combination of individual-level regularity with aggregate-level conformity. By moving driverless vehicles proactively to match this predicted demand, we can reduce wait times for disembarking passengers by over 75%. Independently, the Neighborhood Event Detector uses outlier measures of currently operating buses to detect and spatiotemporally localize dynamic urban events, as much as 1.5 hours in advance, with a localization error of ~450 meters.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {41–53},
numpages = {13},
keywords = {live smart city services, conformity, regularity, mobility behavior},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326074,
author = {Xu, Xiangyu and Yu, Jiadi and Chen, Yingying and Zhu, Yanmin and Kong, Linghe and Li, Minglu},
title = {BreathListener: Fine-Grained Breathing Monitoring in Driving Environments Utilizing Acoustic Signals},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326074},
doi = {10.1145/3307334.3326074},
abstract = {Given the increasing amount of time people spent on driving, the physical and mental health of drivers is essential to road safety. Breathing patterns are critical indicators of the well-being of drivers on the road. Existing studies on breathing monitoring require active user participation of wearing special sensors or relatively quiet environments during sleep, which are hardly applicable to noisy driving environments. In this work, we propose a fine-grained breathing monitoring system, BreathListener, which leverages audio devices on smartphones to estimate the fine-grained breathing waveform in driving environments. By investigating the data collected from real driving environments, we find that Energy Spectrum Density (ESD) of acoustic signals can be utilized to capture breathing procedures in driving environments. To extract breathing pattern in ESD signals, BreathListener eliminates interference from driving environments in ESD signals utilizing background subtraction and Ensemble Empirical Mode Decomposition (EEMD). After that, the extracted breathing pattern is transformed into Hilbert spectrum, and we further design a deep learning architecture based on Generative Adversarial Network (GAN) to generate fine-grained breathing waveform from the Hilbert spectrum of extracted breathing patterns in ESD signals. Experiments with 10 drivers in real driving environments show that BreathListener can accurately capture breathing patterns of drivers in driving environments.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {54–66},
numpages = {13},
keywords = {driving safety, acoustic sensing, breathing monitoring},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3340949,
author = {Agarwal, Sharad},
title = {Session Details: Session 2: Adding to the Toolkit},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340949},
doi = {10.1145/3340949},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326106,
author = {Afanasov, Mikhail and Djordjevic, Alessandro and Lui, Feng and Mottola, Luca},
title = {FlyZone: A Testbed for Experimenting with Aerial Drone Applications},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326106},
doi = {10.1145/3307334.3326106},
abstract = {FlyZone is a testbed architecture to experiment with aerial drone applications. Unlike most existing drone testbeds that focus on low-level mechanical control, FlyZone offers a high-level API and features geared towards experimenting with application-level functionality. These include the emulation of environment influences, such as wind, and the automatic monitoring of developer-provided safety constraints, for example, to mimic obstacles. We conceive novel solutions to achieve this functionality, including a hardware/software architecture that maximizes decoupling from the main application and a custom visual localization technique expressly designed for testbed operation. We deploy two instances of FlyZone and study performance and effectiveness. We demonstrate that we realistically emulate the environment influence with a positioning error bound by the size of the smallest drone we test, that our localization technique provides a root mean square error of 9.2cm, and that detection of violations to safety constraints happens with a 50ms worst-case latency. We also report on how FlyZone supported developing three real-world drone applications, and discuss a user study demonstrating the benefits of FlyZone compared to drone simulators.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {67–78},
numpages = {12},
keywords = {dependability, localization, testbeds, drones},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326089,
author = {Mantz, Dennis and Classen, Jiska and Schulz, Matthias and Hollick, Matthias},
title = {InternalBlue - Bluetooth Binary Patching and Experimentation Framework},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326089},
doi = {10.1145/3307334.3326089},
abstract = {Bluetooth is one of the most established technologies for short range digital wireless data transmission. With the advent of wearables and the Internet of Things (IoT), Bluetooth has again gained importance, which makes security research and protocol optimizations imperative. Surprisingly, there is a lack of openly available tools and experimental platforms to scrutinize Bluetooth. In particular, system aspects and close to hardware protocol layers are mostly uncovered. We reverse engineer multiple Broadcom Bluetooth chipsets that are widespread in off-the-shelf devices. Thus, we offer deep insights into the internal architecture of a popular commercial family of Bluetooth controllers used in smartphones, wearables, and IoT platforms. Reverse engineered functions can then be altered with our InternalBlue Python framework---outperforming evaluation kits, which are limited to documented and vendor-defined functions. The modified Bluetooth stack remains fully functional and high-performance. Hence, it provides a portable low-cost research platform. InternalBlue is a versatile framework and we demonstrate its abilities by implementing tests and demos for known Bluetooth vulnerabilities. Moreover, we discover a novel critical security issue affecting a large selection of Broadcom chipsets that allows executing code within the attacked Bluetooth firmware. We further show how to use our framework to fix bugs in chipsets out of vendor support and how to add new security features to Bluetooth firmware.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {79–90},
numpages = {12},
keywords = {firmware, fuzzing, binary patching, bluetooth, security, iot, link layer},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326080,
author = {Kalm\'{a}r, Gy\"{o}rgy and Wittemyer, George and V\"{o}lgyesi, P\'{e}ter and Rasmussen, Henrik Barner and Mar\'{o}ti, Mikl\'{o}s and L\'{e}deczi, \'{A}kos},
title = {Animal-Borne Anti-Poaching System},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326080},
doi = {10.1145/3307334.3326080},
abstract = {Wildlife poaching is a critical driver of biodiversity loss and population decline. Poaching is a particular threat to high value, large-bodied species, such as elephants, that are slow to reproduce. Increasingly, GPS tracking collars serve as a key tool for studying the behavior and monitoring wildlife globally, including application to anti-poaching efforts. However, collars provide indirect information on poaching, such as immobility, that is often not available in real time. In parallel to collar development, acoustic gunshot detection systems have proliferated in the military and law enforcement. Static systems in wildlife areas have been deployed for detecting poaching, but such systems do not scale geographically. This paper explores the idea of fusing GPS tracking collars with acoustic shockwave detectors to create an animal-borne anti-poaching sensor. A real-time alert of gunshots near elephant groups would enable rangers to respond immediately to such events. The two main technical challenges to such a system are battery life and detection accuracy. The paper presents a prototype designed for elephants that has great promise in addressing these significant technical challenges.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {91–102},
numpages = {12},
keywords = {wearable, animal conservation, poaching, low-power, shockwave, acoustics},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326076,
author = {Li, Zhengxiong and Rathore, Aditya Singh and Chen, Baicheng and Song, Chen and Yang, Zhuolin and Xu, Wenyao},
title = {SpecEye: Towards Pervasive and Privacy-Preserving Screen Exposure Detection in Daily Life},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326076},
doi = {10.1145/3307334.3326076},
abstract = {Digital devices have become a necessity in our daily life, with digital screens acting as a gateway to access a plethora of information present in the underlying device. However, these devices emit visible light through screens where long-term use can lead to significant screen exposure, further influencing users' health. Conventional methods on screen exposure detection (textite.g., photo logger) are usually privacy-invasive and expensive, further, require ideal light conditions, which are unattainable in real practice. Considering the light intensity and spectrum vary among different light sources, an effective screen spectrum estimation can provide vital information about screen exposure. To this end, we first investigate the characteristics of the junction between p-type and n-type semiconductor (i.e., PN junction) to sense the spectrum under various conditions. Empirically, we design and implement, textsfSpecEye, an end-to-end, low cost, wearable, and privacy-preserving screen exposure detection system with a mobile application. For validating the performance of our system, we conduct comprehensive experiments with $54$ commodity digital screens, at $43$ distinct locations, with results showing a base accuracy of $99$%, and an equal error rate (EER) approaching $0.80$% under the controlled lab setup. Moreover, we assess the reliability, robustness, and performance variation of textsfSpecEye under various real-world circumstances to observe a stable accuracy of $95$%. Our real-world study indicates textsfSpecEye is a promising system for screen exposure detection in everyday life.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {103–116},
numpages = {14},
keywords = {privacy, health, screen exposure},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3340950,
author = {Lin, Kate Ching-Ju},
title = {Session Details: Session 3: What is Real},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340950},
doi = {10.1145/3340950},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326079,
author = {Park, Yongtae and Yun, Sangki and Kim, Kyu-Han},
title = {When IoT Met Augmented Reality: Visualizing the Source of the Wireless Signal in AR View},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326079},
doi = {10.1145/3307334.3326079},
abstract = {This paper presents VisIoT, a system that tracks the location of a wireless transmitter in IoT devices and displays it in the screen of an AR device such as smart glasses and tablet. The proposed system benefits existing IoT systems by enabling intuitive interaction between a user and IoT devices and further enhancing visualization of the data collected from IoT sensors. VisIoT achieves them through a combination of wireless sensing and camera motion tracking. By using the azimuth and elevation angles between the wireless transmitter and the camera-equipped mobile device, VisIoT can instantly identify the location of the IoT device from the camera image. This paper introduces novel azimuth and elevation estimation algorithms that leverage the phase difference of the signals from two antennas together with the tracked camera rotation. We prototype VisIoT using a tablet PC and a USRP software radio, and develop a software that tracks and visualizes the location of ZigBee nodes in real time. The evaluation results show that VisIoT can accurately track the nodes with the median position error of 6%.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {117–129},
numpages = {13},
keywords = {wireless device tracking, augmented reality, internet of things},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326087,
author = {Shi, Shu and Gupta, Varun and Jana, Rittwik},
title = {Freedom: Fast Recovery Enhanced VR Delivery Over Mobile Networks},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326087},
doi = {10.1145/3307334.3326087},
abstract = {In this paper we design and implement Freedom, a mobile VR system that deliver high quality VR content on today's mobile devices using 4G/LTE cellular networks. Compared to existing state-of-the-art, Freedom does not rely on any video frame pre- rendering or viewpoint prediction. We send a latency-adaptive VAM frame that contains pixels around the FoV. This allows the clients to render locally at a high refresh rate of 60 Hz to accommodate and compensate for the user's head movements before the next server update arrives. We demonstrate that Freedom is the first system in the world that can support dynamic and live 8K resolution VR content, while adapting to the real-world latency variations experienced in cellular networks. Compared to streaming the whole 360° panoramic VR content, we show that Freedom achieves up to 80% bandwidth savings. Finally, we provide detailed end to end latency measurements of actual VR systems by running extensive experiments in a private LTE testbed using a Mobile Edge Cloud (MEC).},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {130–141},
numpages = {12},
keywords = {360 video, motion-to-update latency, mobile edge cloud, mobile vr, remote rendering},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326098,
author = {Prakash, Siddhant and Bahremand, Alireza and Nguyen, Linda D. and LiKamWa, Robert},
title = {GLEAM: An Illumination Estimation Framework for Real-Time Photorealistic Augmented Reality on Mobile Devices},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326098},
doi = {10.1145/3307334.3326098},
abstract = {Mixed reality mobile platforms attempt to co-locate virtual scenes with physical environments, towards creating immersive user experiences. However, to create visual harmony between virtual and physical spaces, the virtual scene must be accurately illuminated with realistic lighting that matches the physical environment. To this end, we design GLEAM, a framework that provides robust illumination estimation in real-time by integrating physical light-probe estimation with current mobile AR systems. GLEAM visually observes reflective objects to compose a realistic estimation of physical lighting. Optionally, GLEAM can network multiple devices to sense illumination from different viewpoints and compose a richer estimation to enhance realism and fidelity. Using GLEAM, AR developers gain the freedom to use a wide range of materials, which is currently limited by the unrealistic appearance of materials that need accurate illumination, such as liquids, glass, and smooth metals. Our controlled environment user studies across 30 participants reveal the effectiveness of GLEAM in providing robust and adaptive illumination estimation over commercial status quo solutions, such as pre-baked directional lighting and ARKit 2.0 illumination estimation. Our benchmarks reveal the need for situation driven tradeoffs to optimize for quality factors in situations requiring freshness over quality and vice-versa. Optimizing for different quality factors in different situations, GLEAM can update scene illumination as fast as 30ms by sacrificing richness and fidelity in highly dynamic scenes, or prioritize quality by allowing an update interval as high as 400ms in scenes that require high-fidelity estimation.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {142–154},
numpages = {13},
keywords = {image processing, image-based lighting, light estimation, light probe, augmented reality, geometry, lighting models},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326097,
author = {Choi, Jaewon and Park, HyeonJung and Paek, Jeongyeup and Balan, Rajesh Krishna and Ko, JeongGil},
title = {LpGL: Low-Power Graphics Library for Mobile AR Headsets},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326097},
doi = {10.1145/3307334.3326097},
abstract = {We present LpGL, an OpenGL API compatible Low-power Graphics Library for energy efficient AR headset applications. We first characterize the power consumption patterns of a state of the art AR headset, Magic Leap One, and empirically show that its internal GPU is the most impactful and controllable energy consumer. Based on the preliminary studies, we design LpGL so that it uses the device's gaze/head orientation information and geometry data to infer user perception information, intercepts application-level graphics API calls, and employs frame rate control, mesh simplification, and culling techniques to enhance energy efficiency of AR headsets without detriment of user experience. Results from a comprehen- sive set of controlled in-lab experiments and an IRB-approved user study with 25 participants show that LpGL reduces up to 22% of total energy usage while adding only 46 sec of latency per object with close to no loss in subjective user experience.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {155–167},
numpages = {13},
keywords = {energy efficiency, augmented reality, mobile headsets},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3340951,
author = {Sani, Ardalan Amiri},
title = {Session Details: Session 4: Taming Your Apps},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340951},
doi = {10.1145/3340951},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326094,
author = {Yan, Yuxuan and Li, Zhenhua and Chen, Qi Alfred and Wilson, Christo and Xu, Tianyin and Zhai, Ennan and Li, Yong and Liu, Yunhao},
title = {Understanding and Detecting Overlay-Based Android Malware at Market Scales},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326094},
doi = {10.1145/3307334.3326094},
abstract = {As a key UI feature of Android, overlay enables one app to draw over other apps by creating an extra View layer on top of the host View. While greatly facilitating user interactions with multiple apps at the same time, it is often exploited by malicious apps (malware) to attack users. To combat this threat, prior countermeasures concentrate on restricting the capabilities of overlays at the OS level, while barely seeing adoption by Android due to the concern of sacrificing overlays' usability. To address this dilemma, a more pragmatic approach is to enable the early detection of overlay-based malware at the app market level during the app review process, so that all the capabilities of overlays can stay unchanged. Unfortunately, little has been known about the feasibility and effectiveness of this approach for lack of understanding of malicious overlays in the wild. To fill this gap, in this paper we perform the first large-scale comparative study of overlay characteristics in benign and malicious apps using static and dynamic analyses. Our results reveal a set of suspicious overlay properties strongly correlated with the malice of apps, including several novel features. Guided by the study insights, we build OverlayChecker, a system that is able to automatically detect overlay-based malware at market scales. OverlayChecker has been adopted by one of the world's largest Android app stores to check around 10K newly submitted apps per day. It can efficiently (within 2 minutes per app) detect nearly all (96%) overlay-based malware using a single commodity server.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {168–179},
numpages = {12},
keywords = {malware detection, android overlay, app market},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326095,
author = {Raval, Nisarg and Razeen, Ali and Machanavajjhala, Ashwin and Cox, Landon P. and Warfield, Andrew},
title = {Permissions Plugins as Android Apps},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326095},
doi = {10.1145/3307334.3326095},
abstract = {The permissions framework for Android is frustratingly inflexible. Once granted a permission, Android will always allow an app to access the resource until the user manually revokes the app's permission. Prior work has proposed extensible plugin frameworks, but they have struggled to support flexible authorization and isolate apps and plugins from each other. In this paper, we propose DALF, a framework for extensible permissions plugins that provides both flexibility and isolation. The insight underlying DALF is that permissions plugins should be treated as apps themselves. This approach allows plugins to maintain state and access system resources such as a device's location while being restricted by Android's process-isolation mechanisms. Experiments with microbenchmarks and case studies with real third-party apps show promising results: plugins are easy to develop and impose acceptable overhead for most resources.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {180–192},
numpages = {13},
keywords = {android, plugins, flexible permissions},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326102,
author = {Hu, Yongjian and Riva, Oriana and Nath, Suman and Neamtiu, Iulian},
title = {Elix: Path-Selective Taint Analysis for Extracting Mobile App Links},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326102},
doi = {10.1145/3307334.3326102},
abstract = {App links, also known as mobile deep links, are URIs that point to specific pages in an app. App links are essential to many mobile experiences: Google and Bing use them to link search results directly to relevant pages in an app and apps use them for cross-app navigation. However, app links are hard to discover and, since they must be explicitly built into apps by developers, only exist for a small fraction of apps. To address these two problems, we propose Elix, an automated app link extractor. We define link extraction as a static information flow problem where a link, with its scheme and parameters, is synthesized by analyzing the data flow between subsequent pages in an app. As static analysis is prone to false positives, Elix adopts a novel, path-selective taint analysis that leverages symbolic execution to reason about path constraints and abandon infeasible paths. Elix can automatically and correctly discover links that are exposed by an app, and many others that are not explicitly exposed, thus increasing coverage of both link-enabled apps and link-enabled pages in an app. Elix also simplifies the scheme of extracted links by reducing complex types to a minimal set of primitive types. We have implemented Elix on Android and applied it to 1007 popular Android apps. Elix can extract 80-90% of an app's links, and above 80% of the extracted links are stable.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {193–206},
numpages = {14},
keywords = {symbolic execution, static analysis, mobile app links},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326108,
author = {Zhang, Tao and Zuck, Aviad and Porter, Donald E. and Tsafrir, Dan},
title = {Apps Can Quickly Destroy Your Mobile's Flash: Why They Don't, and How to Keep It That Way},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326108},
doi = {10.1145/3307334.3326108},
abstract = {Although flash cells wear out, a typical SSD has enough cells and sufficiently sophisticated firmware that its lifetime generally exceeds the expected lifetime of its host system. Even under heavy use, SSDs last for years and can be replaced upon failure. On a smartphone, in contrast, the hardware is more limited and we show that, under heavy use, one can easily, and more quickly, wear out smartphone flash storage. Consequently, a simple, unprivileged, malicious application can render a smartphone unbootable ("bricked") in a few weeks with no warning signs to the user. This bleak result becomes more worrisome when considering the fact that smartphone users generally believe it is safe to try out new applications. To combat this problem, we study the I/O behavior of a wide range of Android applications. We find that high-volume write bursts exist, yet none of the applications we checked sustains an average write rate that is high enough to damage the device (under reasonable usage assumptions backed by the literature). We therefore propose a rate-limiting algorithm for write activity that (1) prevents such attacks, (2) accommodates "normal" bursts, and (3) ensures that the smartphone drive lifetime is longer than a preconfigured lower bound (i.e., its warranty). In terms of user experience, our design only requires that, in the worst case of an app that issues continuous, unsustainable, and unusual writes, the user decides whether to shorten the phone's life or rate limit the problematic app.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {207–221},
numpages = {15},
keywords = {device lifespan, app characterization, android, flash storage},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326072,
author = {Shi, Luman and Fu, Jianming and Guo, Zhengwei and Ming, Jiang},
title = {"Jekyll and Hyde" is Risky: Shared-Everything Threat Mitigation in Dual-Instance Apps},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326072},
doi = {10.1145/3307334.3326072},
abstract = {Recent developed application-level virtualization brings a groundbreaking innovation to Android ecosystem: a host app is able to load and launch arbitrary guest APK files without the hassle of installation. Powered by this technology, the so-called "dual-instance apps" are becoming increasingly popular as they can run dual copies of the same app on a single device (e.g., login Facebook simultaneously with two different accounts). Given the large demand from smartphone users, it is imperative to understand how secure dual-instance apps are. However, little work investigates their potential security risks. Even worse, new Android malware variants have been accused of skimming the cream off application-level virtualization. They abuse legitimate virtualization engines to launch phishing attacks or even thwart static detection. We first demonstrate that, current dual-instance apps design introduces serious "shared-everything" threats to users, and severe attacks such as permission escalation and privacy leak have become tremendously easier. Unfortunately, we find that most critical apps cannot discriminate between host app and Android system. In addition, traditional fingerprinting features targeting Android sandboxes are futile as well. To inform users that an app is running in an untrusted environment, we study the inherent features of dual-instance app environment and propose six robust fingerprinting features to detect whether an app is being launched by the host app. We test our approach, called DiPrint, with a set of dual-instance apps collected from popular app stores, Android systems, and virtualization-based malware. Our evaluation shows that DiPrint is able to accurately identify dual-instance apps with negligible overhead.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {222–235},
numpages = {14},
keywords = {shared-everything threat, dynamic detection, android application-layer virtualization},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3340952,
author = {Balasubramanian, Aruna},
title = {Session Details: Session 5: Sense and See},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340952},
doi = {10.1145/3340952},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326092,
author = {Hu, Jinhan and Shearer, Alexander and Rajagopalan, Saranya and LiKamWa, Robert},
title = {Banner: An Image Sensor Reconfiguration Framework for Seamless Resolution-Based Tradeoffs},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326092},
doi = {10.1145/3307334.3326092},
abstract = {Mobile vision systems would benefit from the ability to situationally sacrifice image resolution to save system energy when imaging detail is unnecessary. Unfortunately, any change in sensor resolution leads to a substantial pause in frame delivery -- as much as 280 ms. Frame delivery is bottlenecked by a sequence of reconfiguration procedures and memory management in current operating systems before it resumes at the new resolution. This latency from reconfiguration impedes the adoption of otherwise beneficial resolution-energy tradeoff mechanisms. We propose Banner as a media framework that provides a rapid sensor resolution reconfiguration service as a modification to common media frameworks, e.g., V4L2. Banner completely eliminates the frame-to-frame reconfiguration latency (226 ms to 33 ms), i.e., removing the frame drop during sensor resolution reconfiguration. Banner also halves the end-to-end resolution reconfiguration latency (226 ms to 105 ms). This enables a more than 49% reduction of system power consumption by allowing continuous vision applications to reconfigure the sensor resolution to 480p compared with downsampling from 1080p to 480p, as measured in a cloud-based offloading workload running on a Jetson TX2 board. As a result, Banner unlocks unprecedented capabilities for mobile vision applications to dynamically reconfigure sensor resolutions to balance the energy efficiency and task accuracy tradeoff.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {236–248},
numpages = {13},
keywords = {operating systems, energy efficiency, efficient visual computing, resolution-based tradeoff, device drivers, reconfiguration},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326093,
author = {Liu, Jian and Shi, Cong and Chen, Yingying and Liu, Hongbo and Gruteser, Marco},
title = {CardioCam: Leveraging Camera on Mobile Devices to Verify Users While Their Heart is Pumping},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326093},
doi = {10.1145/3307334.3326093},
abstract = {With the increasing prevalence of mobile and IoT devices (e.g., smartphones, tablets, smart-home appliances), massive private and sensitive information are stored on these devices. To prevent unauthorized access on these devices, existing user verification solutions either rely on the complexity of user-defined secrets (e.g., password) or resort to specialized biometric sensors (e.g., fingerprint reader), but the users may still suffer from various attacks, such as password theft, shoulder surfing, smudge, and forged biometrics attacks. In this paper, we propose, CardioCam, a low-cost, general, hard-to-forge user verification system leveraging the unique cardiac biometrics extracted from the readily available built-in cameras in mobile and IoT devices. We demonstrate that the unique cardiac features can be extracted from the cardiac motion patterns in fingertips, by pressing on the built-in camera. To mitigate the impacts of various ambient lighting conditions and human movements under practical scenarios, CardioCam develops a gradient-based technique to optimize the camera configuration, and dynamically selects the most sensitive pixels in a camera frame to extract reliable cardiac motion patterns. Furthermore, the morphological characteristic analysis is deployed to derive user-specific cardiac features, and a feature transformation scheme grounded on Principle Component Analysis (PCA) is developed to enhance the robustness of cardiac biometrics for effective user verification. With the prototyped system, extensive experiments involving $25$ subjects are conducted to demonstrate that CardioCam can achieve effective and reliable user verification with over $99%$ average true positive rate (TPR) while maintaining the false positive rate (FPR) as low as $4%$.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {249–261},
numpages = {13},
keywords = {camera, authentication, mobile devices, cardiac biometric},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326105,
author = {Balaji, Ananta Narayanan and Yuan, Chen and Wang, Bo and Peh, Li-Shiuan and Shao, Huilin},
title = {PH Watch - Leveraging Pulse Oximeters in Existing Wearables for Reusable, Real-Time Monitoring of PH in Sweat},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326105},
doi = {10.1145/3307334.3326105},
abstract = {Sweat is a readily accessible bodily fluid for detecting biomarkers such as pH, glucose etc., enabling continuous and non-invasive assessment of the well-being of individuals. Our proposed work aims at leveraging pulse oximeter chips in current-day fitness trackers for real-time continuous monitoring of pH in sweat. We achieve that by fabricating a highly responsive and long-term reusable pH sweat sensor on a flexible material to achieve skin conformity, targeting the sensor to work at the reflected infrared (880nm) and red (660nm) photoplethysmograph (PPG) signal intensities recorded by pulse oximeters. The sensor can be readily mounted atop any wearable with a pulse oximeter. We have successfully demonstrated a low-cost, low-power, highly-responsive and long-term reusable wrist-worn wearable prototype, pH Watch, for real-time continuous monitoring of pH value of sweat. We conducted on-body trials with 10 participants and pH Watch achieves an accuracy of $approx$91%. We also showed that the integration of our sweat sensor does not hinder the pulse oximeter from measuring heart rate and SpOtextsubscript2, and users can continue with their daily activities with motion artifacts removed efficiently from PPG signals using the TROIKA framework, resulting in heart rate and SpOtextsubscript2 measurements with an accuracy of $approx$95% and $approx$96% respectively when validated against commercial finger pulse oximeter measurements. To the best of our knowledge, pH Watch is the first demonstration of a reusable sweat sensor that can be readily integrated into today's smart watches with pulse oximeters, paving the way for ubiquitous sensing of biomarkers.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {262–274},
numpages = {13},
keywords = {sweat sensor, ph sensing, iot, wearables},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326078,
author = {Yue, Shichao and Katabi, Dina},
title = {Liquid Testing with Your Smartphone},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326078},
doi = {10.1145/3307334.3326078},
abstract = {Surface tension is an important property of liquids. It has diverse uses such as testing water contamination, measuring alcohol concentration in drinks, and identifying the presence of protein in urine to detect the onset of kidney failure. Today, measurements of surface tension are done in a lab environment using costly instruments, making it hard to leverage this property in ubiquitous applications. In contrast, we show how to measure surface tension using only a smartphone. We introduce a new algorithm that uses the small waves on the liquid surface as a series of lenses that focus light and generate a characteristic pattern. We then use the phone camera to capture this pattern and measure the surface tension. Our approach is simple, accurate and available to anyone with a smartphone. Empirical evaluations show that our mobile app can detect water contamination and measure alcohol concentration. Furthermore, it can track protein concentration in the urine, providing an initial at-home test for proteinuria, a dangerous complication that can lead to kidney failure.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {275–286},
numpages = {12},
keywords = {ubiquitous computing, liquid identification, surface tension, mobile sensing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3340953,
author = {Min, Chulhong},
title = {Session Details: Session 6: Simon Says},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340953},
doi = {10.1145/3340953},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326109,
author = {Liu, Yang and Li, Zhenjiang and Liu, Zhidan and Wu, Kaishun},
title = {Real-Time Arm Skeleton Tracking and Gesture Inference Tolerant to Missing Wearable Sensors},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326109},
doi = {10.1145/3307334.3326109},
abstract = {This paper presents ArmTroi, a wearable system for understanding and analyzing the detailed arm motions of people primarily by using the motion sensors from wrist-worn wearable devices. ArmTroi can achieve real-time 3D arm skeleton tracking and reliable gesture inference tolerant to missing wearable sensors for enabling numerous useful application designs. We have coped with two major challenges through ArmTroi. First, the skeleton of each arm is determined from the locations of the elbow and wrist, whereas a wearable device only senses a single point from the wrist. We find that the potential solution space is huge. This underconstrained nature fundamentally challenges the achievement of accurate and real-time arm skeleton tracking. Second, wearable sensors may not reliably provide sensory data. For example, devices are not worn by the user, yet the learning tools for gesture inference, such as deep learning, typically have static network structures, which require nontrivial network adaptation to match the input's varying availability and ensure reliable gesture inference. We propose effective techniques to address above challenges, and all computations can be conducted on the user's smartphone. ArmTroi is thus a fully lightweight and portable system. We develop a prototype and extensive evaluation shows the efficacy of the ArmTroi design.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {287–299},
numpages = {13},
keywords = {arm tracking, deep learning, gesture inference, mobile sensing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326090,
author = {Whitmire, Eric and Salemi Parizi, Farshid and Patel, Shwetak},
title = {Aura: Inside-out Electromagnetic Controller Tracking},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326090},
doi = {10.1145/3307334.3326090},
abstract = {The ability to track handheld controllers in 3D space is critical for interaction with head-mounted displays, such as those used in virtual and augmented reality systems. Today's systems commonly rely on dedicated infrastructure to track the controller or only provide inertial-based rotational tracking, which severely limits the user experience. Optical inside-out systems offer mobility but require line-of-sight and bulky tracking rings, which limit the ubiquity of these devices. In this work, we present Aura, an inside-out electromagnetic 6-DoF tracking system for handheld controllers. The tracking system consists of three coils embedded in a head-mounted display and a set of orthogonal receiver coils embedded in a handheld controller. We propose a novel closed-form and computationally simple tracking approach to reconstruct position and orientation in real time. Our handheld controller is small enough to fit in a pocket and consumes 45 mW of power, allowing it to operate for multiple days on a typical battery. An evaluation study demonstrates that Aura achieves a median tracking error of 5.5 mm and 0.8 degrees in 3D space within arm's reach.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {300–312},
numpages = {13},
keywords = {electromagnetic tracking, mixed reality, head-mounted display, controller, virtual reality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326081,
author = {Zheng, Yue and Zhang, Yi and Qian, Kun and Zhang, Guidong and Liu, Yunhao and Wu, Chenshu and Yang, Zheng},
title = {Zero-Effort Cross-Domain Gesture Recognition with Wi-Fi},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326081},
doi = {10.1145/3307334.3326081},
abstract = {Wi-Fi based sensing systems, although sound as being deployed almost everywhere there is Wi-Fi, are still practically difficult to be used without explicit adaptation efforts to new data domains. Various pioneering approaches have been proposed to resolve this contradiction by either translating features between domains or generating domain-independent features at a higher learning level. Still, extra training efforts are necessary in either data collection or model re-training when new data domains appear, limiting their practical usability. To advance cross-domain sensing and achieve fully zero-effort sensing, a domain-independent feature at the lower signal level acts as a key enabler. In this paper, we propose Widar3.0, a Wi-Fi based zero-effort cross-domain gesture recognition system. The key insight of Widar3.0 is to derive and estimate velocity profiles of gestures at the lower signal level, which represent unique kinetic characteristics of gestures and are irrespective of domains. On this basis, we develop a one-fits-all model that requires only one-time training but can adapt to different data domains. We implement this design and conduct comprehensive experiments. The evaluation results show that without re-training and across various domain factors (i.e. environments, locations and orientations of persons), Widar3.0 achieves 92.7% in-domain recognition accuracy and 82.6%-92.4% cross-domain recognition accuracy, outperforming the state-of-the-art solutions. To the best of our knowledge, Widar3.0 is the first zero-effort cross-domain gesture recognition work via Wi-Fi, a fundamental step towards ubiquitous sensing.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {313–325},
numpages = {13},
keywords = {channel state information, cots wi-fi, gesture recognition},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326107,
author = {Huang, Hua and Chen, Hongkai and Lin, Shan},
title = {MagTrack: Enabling Safe Driving Monitoring with Wearable Magnetics},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326107},
doi = {10.1145/3307334.3326107},
abstract = {"Hands on the wheel, eyes on the road" is the central guideline of safe vehicle driving practices. Many advanced driver assistance systems can effectively detect abnormal vehicle motions. However, these systems often leave insufficient time for drivers to respond to complex road situations, especially when the drivers are distracted. To reduce accidents, it is essential to detect whether a driver complies with safe driving guidelines in real time and provide warnings early before any dangerous maneuvers occur. There are vision-based driver distraction monitoring systems which rely on cameras in high-end vehicles, but their performances are heavily constrained by visibility requirements. In this paper, we present MagTrack, a driver monitoring system that is based on tracking magnetic tags worn by the user. With a single smartwatch and two low-cost magnetic accessories: a hand magnetic ring and a head magnetic eyeglasses clip, our system tracks and classifies a driver's bimanual and head movements simultaneously using both analytical and approximation sensing models. Our approach is robust to driver's postures, vehicles, and environmental changes. We demonstrate that a wide range of activities can be detected by our system, including bimanual steering, visual and manual distractions, and lane changes and turns. In extensive road tests with 500+ instances of driving activities and 500+ minutes of road driving with 10 subjects, MagTrack achieves 87% of precision and 90% of recall rate on the detection of unsafe driving activities.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {326–339},
numpages = {14},
keywords = {wearable magnetics, smartwatch sensing, driver assistance system},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3340954,
author = {Kravets, Robin},
title = {Session Details: Session 7: Too Close for Comfort},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340954},
doi = {10.1145/3340954},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326100,
author = {Pierson, Timothy J. and Peters, Travis and Peterson, Ronald and Kotz, David},
title = {CloseTalker: Secure, Short-Range Ad Hoc Wireless Communication},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326100},
doi = {10.1145/3307334.3326100},
abstract = {Secure communication is difficult to arrange between devices that have not previously shared a secret. Previous solutions to the problem are susceptible to man-in-the-middle attacks, require additional hardware for out-of-band communication, or require an extensive public-key infrastructure. Furthermore, as the number of wireless devices explodes with the advent of the Internet of Things, it will be impractical to manually configure each device to communicate with its neighbors. Our system, CloseTalker, allows simple, secure, ad hoc communication between devices in close physical proximity, while jamming the signal so it is unintelligible to any receivers more than a few centimeters away. CloseTalker does not require any specialized hardware or sensors in the devices, does not require complex algorithms or cryptography libraries, occurs only when intended by the user, and can transmit a short burst of data or an address and key that can be used to establish long-term or long-range communications at full bandwidth. In this paper we present a theoretical and practical evaluation of CloseTalker, which exploits Wi-Fi MIMO antennas and the fundamental physics of radio to establish secure communication between devices that have never previously met. We demonstrate that CloseTalker is able to facilitate secure in-band communication between devices in close physical proximity (about 5~cm), even though they have never met nor shared a key.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {340–352},
numpages = {13},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326101,
author = {Tsai, Lillian and De Viti, Roberta and Lentz, Matthew and Saroiu, Stefan and Bhattacharjee, Bobby and Druschel, Peter},
title = {EnClosure: Group Communication via Encounter Closures},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326101},
doi = {10.1145/3307334.3326101},
abstract = {New applications enabled by personal smart devices and the Internet-of-Things (IoT) require communication in the context of periods of spatial co-location. Examples of this encounter-based communication (EbC) include social exchange among individuals who shared an experience, and interaction among personal and IoT devices that provide location-based services. Existing EbC systems are limited to communication among participants that share a direct encounter. This paper is inspired by two insights: (1) encounters also enable group communication among devices connected by paths in the encounter graph that is contextual, spontaneous, secure, and does not require users to reveal identifying or linkable information; and (2) addressing communication partners using encounter closures subject to causal, spatial, and temporal constraints enables powerful new forms of group communication. We present the design of enClosure, a service providing group communication based on encounter closures for mobile and IoT applications, and a prototype implementation for Android and the Microsoft Embedded Social Cloud platform. Using real-world traces, we show that enClosure provides a privacy-preserving, secure platform for a wide range of group communication applications ranging from connecting attendees of a large event and virtual guest books to disseminating health risk warnings, lost-and-found, and tracing missing persons.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {353–365},
numpages = {13},
keywords = {internet-of-things (iot), group communication, mobile computing, privacy, encounter-based communication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326084,
author = {Wang, Ju and Chang, Liqiong and Abari, Omid and Keshav, Srinivasan},
title = {Are RFID Sensing Systems Ready for the Real World?},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326084},
doi = {10.1145/3307334.3326084},
abstract = {Passive Radio Frequency IDentification (RFID) tags are commonly used to provide Radio Frequency (RF) accessible unique identifiers for physical objects due to their low-cost, lack of battery, and small size. Besides this basic function, many novel RFID-based sensing applications have been proposed in the last decade, including localization, gesture sensing, and touch sensing, among others. Nevertheless, none of these systems are in widespread use today. We hypothesize that this is because the accuracy of these systems does not meet application requirements when there are even minor changes in the RF environment or in tag geometry, i.e., changes in a tag's orientation or flexing. This paper uses both theoretical analysis and real-world experiments to test this hypothesis. Our theoretical analysis shows that even a small phase or RSS noise level can result in significant estimation errors. Our extensive real-world experiments find that both the absolute and differential values of phase and RSS readings of an RFID tag's signal can vary as much as by π radians and 10 dB, respectively, due to small changes in the tag's orientation or flexing. Because of these large variations, RFID-based application systems relying on the signal phase or RSS cannot meet application requirements, confirming our hypothesis. In addition to this strong negative result, we also present some insights into designing robust RFID systems that are suitable for use in the real world.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {366–377},
numpages = {12},
keywords = {robustness, rss, phase, rfid},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326085,
author = {Luo, Jiaqing and Shin, Kang G.},
title = {Detecting Misplaced RFID Tags on Static Shelved Items},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326085},
doi = {10.1145/3307334.3326085},
abstract = {A smart shelving system can visualize stock data in real time by leveraging item-level RFID tagging so that we can minimize out-of-stock and reduce warehousing and labor costs. The key issue of smart shelving is to locate RFID tags at any time, especially after misplacing tags. The detection of misplaced tags on stationary shelved items is very challenging due to position ambiguity, phase wrapping, device diversity, and phase ambiguity. Using a combination of theoretical analysis, simulation-based prediction and experimental verification, we propose an effective way of detecting misplaced tags, called FINDS, that integrates Particle Swarm Optimization (PSO), Synthetic Minority Over-sampling TEchnique (SMOTE) and Density-based Spatial Clustering of Applications with Noise (DBSCAN) algorithms to make theoretical and measured phases consistent with each other, and observe the phase shifts caused by misplaced tags. FINDS requires neither antenna movement nor external disturbances. We have implemented a prototype of FINDS with 20 tags and evaluated its performance, demonstrating FINDS's accuracy to be higher than 0.92 in the case of 2 stationary antennas.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {378–390},
numpages = {13},
keywords = {rfid, misplaced tags, smart shelves, stationary tags},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3340955,
author = {Druschel, Peter},
title = {Session Details: Session 8: Waiting for 7G},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340955},
doi = {10.1145/3340955},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326088,
author = {Khazraee, Moein and Guddeti, Yeswanth and Crow, Sam and Snoeren, Alex C. and Levchenko, Kirill and Bharadia, Dinesh and Schulman, Aaron},
title = {SparSDR: Sparsity-Proportional Backhaul and Compute for SDRs},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326088},
doi = {10.1145/3307334.3326088},
abstract = {We present SparSDR, a resource-efficient architecture for softwaredefined radios whose backhaul bandwidth and compute power requirements scale in inverse proportion to the sparsity (in time and frequency) of the signals received. SparSDR requires dramatically fewer resources than existing approaches to process many popular protocols while retaining both flexibility and fidelity. We demonstrate that our approach has negligible impact on signal quality, receiver sensitivity, and processing latency. The SparSDR architecture makes it possible to capture signals across bandwidths far wider than the capacity of a radio's backhaul through the addition of lightweight frontend processing and corresponding backend reconstruction to restore the signals to their original sample rate. We employ SparSDR to develop two wideband applications running on a USRP N210 and a Raspberry Pi 3+: an IoT sniffer that scans 100 MHz of bandwidth and decodes received BLE packets, and a wideband Cloud SDR receiver that requires only residential-class Internet uplink capacity. We show that our SparSDR implementation fits in the constrained resources of popular low-cost SDR platforms, such as the AD Pluto.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {391–403},
numpages = {13},
keywords = {fpga, software defined radio, sparsity, cloud sdr, fft},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326082,
author = {Lee, Gyuhong and Lee, Jihoon and Lee, Jinsung and Im, Youngbin and Hollingsworth, Max and Wustrow, Eric and Grunwald, Dirk and Ha, Sangtae},
title = {This is Your President Speaking: Spoofing Alerts in 4G LTE Networks},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326082},
doi = {10.1145/3307334.3326082},
abstract = {Modern cell phones are required to receive and display alerts via the Wireless Emergency Alert (WEA) program, under the mandate of the Warning, Alert, and Response Act of 2006. These alerts include AMBER alerts, severe weather alerts, and (unblockable) Presidential Alerts, intended to inform the public of imminent threats. Recently, a test Presidential Alert was sent to all capable phones in the United States, prompting concerns about how the underlying WEA protocol could be misused or attacked. In this paper, we investigate the details of this system, and develop and demonstrate the first practical spoofing attack on Presidential Alerts, using both commercially available hardware as well as modified open source software. Our attack can be performed using a commercially-available software defined radio, and our modifications to the open source NextEPC and srsLTE software libraries. We find that with only four malicious portable base stations of a single Watt of transmit power each, almost all of a 50,000-seat stadium can be attacked with a 90% success rate. The true impact of such an attack would of course depend on the density of cell phones in range; fake alerts in crowded cities or stadiums could potentially result in cascades of panic. Fixing this problem will require a large collaborative effort between carriers, government stakeholders, and cell phone manufacturers. To seed this effort, we also discuss several defenses to address this threat in both the short and long term.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {404–416},
numpages = {13},
keywords = {wea, spoofing, security, presidential alert, cmas, lte},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326086,
author = {Lee, Jihoon and Lee, Jinsung and Im, Youngbin and Dhawaskar Sathyanarayana, Sandesh and Rahimzadeh, Parisa and Zhang, Xiaoxi and Hollingsworth, Max and Joe-Wong, Carlee and Grunwald, Dirk and Ha, Sangtae},
title = {CASTLE over the Air: Distributed Scheduling for Cellular Data Transmissions},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326086},
doi = {10.1145/3307334.3326086},
abstract = {This paper presents a fully distributed scheduling framework called CASTLE (Client-side Adaptive Scheduler That minimizes Load and Energy), which jointly optimizes the spectral efficiency of cellular networks and battery consumption of smart devices. To do so, we focus on scenarios when many smart devices compete for cellular resources in the same base station: spreading out transmissions over time so that only a few devices transmit at once improves both spectral efficiency and battery consumption. To this end, we devise two novel features in CASTLE. First, we explicitly consider inter-cell interference for accurate cellular load estimation. Based on our observations, we exploit the RSRQ (Reference Signal Received Quality) and SINR as features in a machine learning algorithm to accurately estimate the cellular load. Second, we propose a fully distributed scheduling algorithm that coordinates transmissions between clients based on the locally estimated load level at each client. Our formulation for minimizing battery consumption at each device leads to an optimized backoff-based algorithm that fits practical environments. To evaluate these features, we prototype a complete LTE system testbed consisting of mobile devices, eNodeBs, EPC (Evolved Packet Core) and application servers. Our comprehensive experimental results show that CASTLE's load estimation is up to 91% accurate, and that CASTLE achieves higher spectral efficiency with less battery consumption, compared to existing centralized scheduling algorithms as well as a distributed CSMA-like protocol. Furthermore, we develop a light-weight SDK that can expedite the deployment of CASTLE into smart devices and evaluate it in a commercial LTE network.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {417–429},
numpages = {13},
keywords = {lte, distributed scheduling, energy saving, cell load},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326104,
author = {Netravali, Ravi and Sivaraman, Anirudh and Mickens, James and Balakrishnan, Hari},
title = {WatchTower: Fast, Secure Mobile Page Loads Using Remote Dependency Resolution},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326104},
doi = {10.1145/3307334.3326104},
abstract = {Remote dependency resolution (RDR) is a proxy-driven scheme for reducing mobile page load times; a proxy loads a requested page using a local browser, fetching the page's resources over fast proxy-origin links instead of a client's slow last-mile links. In this paper, we describe two fundamental challenges to efficient RDR proxying: the increasing popularity of encrypted HTTPS content, and the fact that, due to time-dependent network conditions and page properties, RDR proxying can actually increase load times. We solve these problems by introducing a new, secure proxying scheme for HTTPS traffic, and by implementing WatchTower, a selective proxying system that uses dynamic models of network conditions and page structures to only enable RDR when it is predicted to help. WatchTower loads pages 21.2%-41.3% faster than state-of-the-art proxies and server push systems, while preserving end-to-end HTTPS security.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {430–443},
numpages = {14},
keywords = {mobile web, web performance, cloud browsers, remote dependency resolution, page load times},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326103,
author = {Tai, Tzu-Chun and Lin, Kate Ching-Ju and Tseng, Yu-Chee},
title = {Toward Reliable Localization by Unequal AoA Tracking},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326103},
doi = {10.1145/3307334.3326103},
abstract = {Emerging applications require the location information of clients to enable human-environment interactions or personalized services. With an increasing number of antennas equipped in today's wireless devices, recent research has shown possibility of sub-meter level localization based only on the angle of arrival (AoA) of WiFi sig- nals. While most existing work provides promising median accu- racy, their tail performance however is usually far worse. We ob- serve from measurements that the root cause is due to unequal AoA estimation reliability. In some critical areas, a small variation in the channel state information of signals could introduce an extremely large AoA estimation error. With this observation, we propose UAT (Unequal Angle Tracking), a confidence-aware AoA-based localiza- tion system. We show that unequal reliability of AoA measures can be mathematically quantified, allowing a system to weigh the de- cisions of different APs according to their confidence. Our testbed evaluation shows that UAT's confidence-aware design provides reli- able decimeter level localization for around 90% of locations. UAT is especially effective for risky areas and can reduce their localiza- tion errors by 27.5%, as compared to reliability-oblivious designs.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {444–456},
numpages = {13},
keywords = {unequal tracking, localization, aoa estimation},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326070,
author = {Xiao, Ao and Liu, Yunhao and Li, Yang and Qian, Feng and Li, Zhenhua and Bai, Sen and Liu, Yao and Xu, Tianyin and Xin, Xianlong},
title = {An In-Depth Study of Commercial MVNO: Measurement and Optimization},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326070},
doi = {10.1145/3307334.3326070},
abstract = {Recent years have witnessed the rapid growth of mobile virtual network operators (MVNOs), which operate on top of the existing cellular infrastructures of base carriers while offering cheaper or more flexible data plans compared to those of the base carriers. In this paper, we present a nearly two-year measurement study towards understanding various key aspects of today's MVNO ecosystem, including its architecture, performance, economics, customers, and the complex interplay with the base carrier. Our study focuses on a large commercial MVNO with reviseabout 1 million customers, operating atop a nation-wide base carrier. Our measurements clarify several key concerns raised by MVNO customers, such as inaccurate billing and potential performance discrimination with the base carrier. We also leverage big data analytics and machine learning to optimize an MVNO's key businesses such as data plan reselling and customer churn mitigation. Our proposed techniques can help achieve %will lead to higher revenues and improved services for commercial MVNOs.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {457–468},
numpages = {12},
keywords = {mvno, network performance, data prediction, machine learning, churn mitigation},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3340956,
author = {LiKamWa, Robert},
title = {Session Details: Session 9: Nuts and Bolts},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340956},
doi = {10.1145/3340956},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326075,
author = {Choi, Yonghun and Park, Seonghoon and Cha, Hojung},
title = {Graphics-Aware Power Governing for Mobile Devices},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326075},
doi = {10.1145/3307334.3326075},
abstract = {Graphics increasingly play a key role in modern mobile devices. The graphics pipeline requires a close relationship between the CPU and the GPU to ensure energy efficiency and the user's quality of experience (QoE). Our preliminary analysis showed that the current techniques employed to achieve energy efficiency in the Android graphics pipeline are not optimized especially in the frame generation process. In this paper, we aim to improve the energy efficiency of the Android graphics pipeline without degrading the user's QoE. To achieve this goal, we studied the internals of the Android graphics pipeline and observed the energy inefficiency in the existing governing framework of the CPU and GPU. Based on the findings, we propose three techniques for addressing energy inefficiency: (1) aggressively capping the maximum CPU frequency, (2) lowering the CPU frequency by raising the GPU minimum frequency, and (3) allocating the frame rendering-related threads in the energy-efficient CPU cores. These techniques are integrated into a single governing framework, called the GFX Governor, and implemented in the newest Android-based smartphones. Experimental results show that without hampering the user's QoE the average energy consumption of Nexus 6P, Pixel XL, and Pixel 2 XL is reduced at the device level by 24.2%, 18.6%, and 13.7%, respectively, for the 60 chosen applications. We also analyzed the efficacy of the proposed technique in comparison with the state-of-the-art Energy-Aware Scheduling (EAS) implemented in the latest smartphone.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {469–481},
numpages = {13},
keywords = {dvfs, android graphics pipeline, heterogeneous multi-core platform, energy efficiency, smartphones},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326083,
author = {Dang, Fan and Li, Zhenhua and Liu, Yunhao and Zhai, Ennan and Chen, Qi Alfred and Xu, Tianyin and Chen, Yan and Yang, Jingyu},
title = {Understanding Fileless Attacks on Linux-Based IoT Devices with HoneyCloud},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326083},
doi = {10.1145/3307334.3326083},
abstract = {With the wide adoption, Linux-based IoT devices have emerged as one primary target of today's cyber attacks. Traditional malware-based attacks can quickly spread across these devices, but they are well-understood threats with effective defense techniques such as malware fingerprinting and community-based fingerprint sharing. Recently, fileless attacks---attacks that do not rely on malware files---have been increasing on Linux-based IoT devices, and posing significant threats to the security and privacy of IoT systems. Little has been known in terms of their characteristics and attack vectors, which hinders research and development efforts to defend against them. In this paper, we present our endeavor in understanding fileless attacks on Linux-based IoT devices in the wild. Over a span of twelve months, we deploy 4 hardware IoT honeypots and 108 specially designed software IoT honeypots, and successfully attract a wide variety of real-world IoT attacks. We present our measurement study on these attacks, with a focus on fileless attacks, including the prevalence, exploits, environments, and impacts. Our study further leads to multi-fold insights towards actionable defense strategies that can be adopted by IoT vendors and end users.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {482–493},
numpages = {12},
keywords = {fileless attack, honeypot, iot},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3326096,
author = {AlDuaij, Naser and Van't Hof, Alexander and Nieh, Jason},
title = {Heterogeneous Multi-Mobile Computing},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326096},
doi = {10.1145/3307334.3326096},
abstract = {As smartphones and tablets proliferate, there is a growing demand for multi-mobile computing, the ability to combine multiple mobile systems into more capable ones. We present M2, a system for multi-mobile computing that enables existing unmodified mobile apps to share and combine multiple devices, including cameras, displays, speakers, microphones, sensors, GPS, and input. M2 introduces a new data-centric approach that leverages higher-level device abstractions and hardware acceleration to efficiently share device data, not API calls. To support heterogeneous devices, M2 introduces device transformation, a new technique to mix and match different types of devices. Example transformations include combining multiple displays into a single larger display for better viewing, or substituting accelerometer for touchscreen input to provide a Nintendo Wii-like experience with existing mobile gaming apps. We have implemented M2 and show that it (1) operates across heterogeneous systems, including multiple versions of Android and iOS, (2) can enable unmodified Android apps to use multiple mobile devices in new and powerful ways, including supporting users with disabilities and better audio conferencing, and (3) can run apps across mobile systems with modest overhead and qualitative performance indistinguishable from using local device hardware.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {494–507},
numpages = {14},
keywords = {mobile devices, distributed computing, operating systems, ios, mobile computing, remote display, android},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328596,
author = {Lee, Sangjae and Han, Dongsoo},
title = {Rover Who Make Indoor Radio Map (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328596},
doi = {10.1145/3307334.3328596},
abstract = {The fingerprinting-based indoor positioning technique requires a database, i.e., a radio map, containing indoor scenes through the training phase. Since that offline phase is labor intensive, numerous studies are underway to minimize the effort. In this paper, we present a concept that applies to a collaborative crowdsourcing method. We designed a system that relies on people and robots moving in the indoor space to construct a radio map. Experiments at two testbeds provide proof of the concept and are the result of the last step of the proposed system.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {508–509},
numpages = {2},
keywords = {crowdsourcing, fingerprint, radio map, indoor positioning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328597,
author = {Choi, Hyunwoo and Gong, Taesik and Kim, Jaehun and Shin, Jaemin and Lee, Sung-Ju},
title = {Dissecting 802.11ac Performance - Why You Should Turn Off MU-MIMO (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328597},
doi = {10.1145/3307334.3328597},
abstract = {While the recent Wi-Fi standard 802.11ac achieves Gb/s theoretical capacity with Multi-User MIMO (MU-MIMO) technology, several studies reported that throughput of 802.11ac in practice is far from Gb/s link speed. We investigate the downlink throughput of Wi-Fi systems with commercially available 802.11ac products in multiple indoor environments to reveal the throughput of MU-MIMO system that user experiences in practice. From our experiments, Single-User MIMO (SU-MIMO) outperformed MU-MIMO at every experimental environments. We further provide analysis on our experimental results considering channel sounding overhead, user grouping, environmental impact, and transmission mode selection.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {510–511},
numpages = {2},
keywords = {mu-mimo, user experienced throughput, 802.11ac},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328599,
author = {Kim, Kihwan and Kim, Sanghoon and Lee, Chunggi and Ko, Sungahn},
title = {Modeling Exploration/Exploitation Decisions through Mobile Sensing for Understanding Mechanisms of Addiction (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328599},
doi = {10.1145/3307334.3328599},
abstract = {Addiction is a brain disease manifested by the loss of control over drugs or behaviors, despite negative consequences. Although addiction research has been conducted for decades in psychiatry and neuroscience, a comprehensive understanding of the mechanisms underlying addiction has not yet been achieved. Recent studies in neuroscience [1] have sought to bring light upon this issue by measuring exploration/exploitation decisions in sequential choice tasks, requiring balancing the need to exploit known options and to explore new ones. These studies show a relationship between addiction and exploration/exploitation decisions. For example, people addicted to substances (e.g. alcohol or methamphetamine) or behaviors (e.g. gambling) have tendencies to explore less, which implies they have difficulties 'seeing the big picture".There is a small yet growing literature modeling explore/exploit decisions of addicted people through inverse reinforcement learning (IRL) [4]. In this previous work, the models made by decision history of addicted people have higher learning weights and probability to exploit than those of normal people, which means that addicted people are more sensitive to their most recent activity. However, existing methods to measure exploration/exploitation decisions are lab-based game experiments such as n-armed bandit [3] or clock task [6], which are high cost, time-consuming and not scalable. Therefore, they are not suitable for modeling through IRL, which requires large behavioral trajectories. In this work, we argue for the first time that mobile sensing is a more cost-efficient and scalable alternative to the lab-based game experiments for understanding and modeling the mechanisms of addiction (Figure 1).},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {512–513},
numpages = {2},
keywords = {inverse reinforcement learning, mobile sensing, computational psychiatry},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328601,
author = {Kim, Joon-Gyum and Gong, Taesik and Huang, Evey and Kim, Juho and Lee, Sung-Ju and Kim, Bogoan and Park, JaeYeon and Kim, Woojeong and Han, Kyungsik and Ko, JeongGil},
title = {Bringing Context into Emoji Recommendations (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328601},
doi = {10.1145/3307334.3328601},
abstract = {We present Reeboc that combines machine learning and k-means clustering to analyze the conversation of a chat, extract different emotions or topics of the conversation, and recommend emojis that represent various contexts to the user. Instead of simply analyzing a single input sentence, we consider recent sentences exchanged in a conversation. we performed a user study with 17 participants in 8 groups in a realistic mobile chat environment. Participants spent the least amount of time in identifying and selecting the emojis of their choice with Reeboc (38% faster than without emoji recommendation).},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {514–515},
numpages = {2},
keywords = {machine learning, mobile applications, user experience, emoji recommendation},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328602,
author = {Jang, Sooyoung and Son, Youngsung},
title = {Virtual-to-Real Transfer via Dynamics Models (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328602},
doi = {10.1145/3307334.3328602},
abstract = {The virtual world is essential for deep reinforcement learning. Since the deep reinforcement learning agent learns the optimal policy by interacting with the environment in a trial and error manner, training the agent in the real world is not only cost expensive and time-consuming but also unsafe. Several researches are ongoing in the field of but not limited to drone, vehicle, and robot arm control as the deep reinforcement learning is proven to be an effective solution to sequential decision-making problems such as Atari games [2] and several board games including Go [4]. Due to the above issue, most of these researches are done in the virtual world that mimics the real world.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {516–517},
numpages = {2},
keywords = {virtual-to-real transfer, dynamics models, deep reinforcement learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328603,
author = {Liu, Yang and Lin, Chengdong and Li, Zhenjiang and Liu, Zhidan and Wu, Kaishun},
title = {When Wearable Sensing Meets Arm Tracking (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328603},
doi = {10.1145/3307334.3328603},
abstract = {In this poster, we present our recent work, a wearable system for achieving real-time 3D arm skeleton. We have coped with the major challenge that the skeleton of each arm is determined from the locations of the elbow and wrist, whereas a wearable device only senses a single point from the wrist. Result shows that the potential solution space is huge. This underconstrained nature fundamentally challenges the achievement of accurate and real-time arm skeleton tracking. In this study, we propose Hidden Markov Model (HMM) state reorganization and hierarchical search two methods to improve the heavyweight computation of the state-of-art arm tracking model and achieve real-time tracking even on mobile phone.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {518–519},
numpages = {2},
keywords = {arm tracking, mobile sensing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328604,
author = {Byun, Hyungho and Kim, Chong-kwon},
title = {When Friends Move: A Deep Learning-Based Approach for Friendship Prediction in Mobility Network (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328604},
doi = {10.1145/3307334.3328604},
abstract = {Considering location data for friendship prediction has become prevalent due to the huge success of online social networks. However, few studies have focused on investigating the possibility of using mobility information in a dense place such as a campus. The research direction for those mobility networks should be treated differently. We propose a CNN-based noble framework for friendship prediction, which starts from collecting location data to a classification model to learn their relation between friendships and mobility. From the experiment, we show that our system outperforms empirical supervised learning techniques and also can be useful for friendship prediction of the future.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {520–521},
numpages = {2},
keywords = {neural networks, recommendation, bluetooth low energy, link prediction, datasets},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328605,
author = {Han, Yunha and Lee, Chunggi and Kim, Sanghoon and Ko, Sungahn},
title = {System Architecture for Progressive Augmented Reality (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328605},
doi = {10.1145/3307334.3328605},
abstract = {In spite of the evolution of Augmented Reality~(AR) technology, it is not wide spread in everyday life. There may be many reasons, but one of the reasons is that it has been developed for very specific users, such as researchers and professionals. To overcome this problem, Grubert et al. proposed the pervasive AR. It is not limited to a specific situation, but is usable in various instances and providing continuous and flexible AR experience. The AR browser is the example of utilizing pervasive AR. The AR browser understands the context of the user and provides corresponding information. However, if the corresponding information to the context of user cannot reach the user in time due to massive data transmission, unexpected network congestion, poor service quality or signal strength, it cannot be guaranteed to be continuous. This leads to a degradation of the user experience, and it cannot support pervasive AR. This paper presents the Progressive Augmented Reality, the way which quickly send incomplete, yet informative, response about the user's current context rather than wait for sending complete information to the user. The concept of Progressive Augmented Reality comes from Progressive Data Science. Our system is aware of network quality by collecting various network health parameters. According to the network status quality, it divides the chunk information to the optimal number and transmits the one that have the highest priority among the divided information. By conducting the above process iteratively, all the divided information is updated. Our client-side system utilizes Android ARCore and has been tested on Google Pixel 2XL.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {522–523},
numpages = {2},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328606,
author = {Kwon, Dohyun and Park, Soohyun and Kim, Joongheon},
title = {Multi-Agent Deep Reinforcement Learning for Connected Vehicles (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328606},
doi = {10.1145/3307334.3328606},
abstract = {The vehicles take a role of mobile devices so that resource management issue among them in cellular networks is getting highlighted. In addition, the millimeter-wave (mmWave) base station is expected to be included in existing heterogeneous networks. In this regard, we present a multi-agent deep reinforcement learning (MADRL) based resource allocation strategy for mobile devices in heterogeneous vehicular networks, which suffer from shortage issue of shared frequency band. The downlink throughput of each mobile device is cooperatively enhanced by the proposed MADRL method, and thus each mobile device associates with a base station and uses a frequency band within low delay.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {524–525},
numpages = {2},
keywords = {resource allocation, connected vehicle, multi-agent deep reinforcement learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328607,
author = {Choi, Hong-Beom and Lim, Keun-Woo and Ko, Young-Bae},
title = {Sensor Localization System for AR-Assisted Disaster Relief Applications (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328607},
doi = {10.1145/3307334.3328607},
abstract = {In this poster, we propose a sensor localization system assisted by wireless communication and augmented reality (AR) suitable for disaster relief applications. Generally, disaster environments are considered extremely hazardous and deteriorated, with unpredictable effects to human mobility and digital devices. To maximize the safety and efficiency of first responders, deployment of wireless sensors are of utmost importance, as sensor nodes can provide sensing information as well as location information. We analyze the issues and challenges that need to be tackled for high accuracy localization of sensor nodes in such environments, and then propose a system that we plan to develop in the near future.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {526–527},
numpages = {2},
keywords = {visual odometry, sensor localization, disaster relief},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328608,
author = {Mun, Hyunsu and Lee, Hyungjin and Kim, Soohyun and Lee, Youngseok},
title = {Measurement of Smart Speaker Wake-up Response Time with Camera (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328608},
doi = {10.1145/3307334.3328608},
abstract = {Voice-controlled smart speakers are popular due to Amazon Echo and Google Home. Though many smart speakers have appeared in the market, we do not know the exact performance of smart speakers. In particular, when we call a smart speaker to issue a voice command, we recognize that the smart speaker is ready when it turns its LED lamps on. The wake-up response time is important for improving user experience. Therefore, we have to measure the wake-up response time, which requires the video analysis of smart speaker LED's status for the voice command. In this work, we present a smart speaker wake-up response time measurement method with a camera. We record video files with camera while testing a smart speaker and analyze image similarity to find a wake-up event. For this purpose, we use the Google Inception-v3 model to improve the accuracy of detecting the image change of a small area.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {528–529},
numpages = {2},
keywords = {smart speaker, transfer learning, wake-up response time, measurements},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328609,
author = {Zhang, Xianzhong and Zhao, Dong and Lyu, Dian and Ma, Huadong},
title = {AutoCUP: A Platform for Automatically Creating Aerial Panoramic Map with Multi-UAVs (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328609},
doi = {10.1145/3307334.3328609},
abstract = {Unmanned Aerial Vehicle (UAV) provides an effective way to create an Aerial Panoramic Map (APM). Generally, it consists of three steps: 1) select a set of locations from a map, 2) take photos from different angles at each selected location one by one, and 3) make panoramic images by the Panoramic Mosaic technology, and then create an APM with these images. However, it is always labor-intensive and time-consuming to complete these steps in a large region such as a campus and a park, due to multiple reasons: 1) inexperience for location selection, 2) low-efficiency for manually operating UAV to fly among different locations one by one and make photos from different angles, and 3) limited energy supply and low-efficiency for a single UAV. DJI GO[1] has been developed to simplify a part of operations in steps 2) and 3), by which we only need one button to take photos automatically from different angles at a selected location. However, it is still required to manually select locations and control UAV to fly among different locations. Moreover, the defects of using a single UAV still exist. By contrast, we aim to design an Auto nomously C ooperative U AV system platform for P anoramic map generation, AutoCUP, which leverages multiple UAVs to full-automatically and high-efficiently complete all steps of creating an APM.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {530},
numpages = {1},
keywords = {navigation, UAV, GCS, path planning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328610,
author = {Li, Tengpeng and Nguyen, Nam Son and Zhang, Xiaoqian and Wang, Teng and Sheng, Bo},
title = {PROMAR: Practical Reference Object-Based Multi-User Augmented Reality (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328610},
doi = {10.1145/3307334.3328610},
abstract = {Mobile Augmented Reality (MAR) represents an emerging category of applications that bring users interactive experiences with the physical experiencesnvironment. In such applications, users can place virtual objects in real-world space, and view them through a camera view. In this work, we develop a framework that supports multi-users interactions for MAR apps, where one user places a virtual object that can be recognized by other users.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {531–532},
numpages = {2},
keywords = {computer version, augmented reality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328611,
author = {Ahn, Sumin},
title = {Automation of Memory Leak Detection and Correction on Android JNI (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328611},
doi = {10.1145/3307334.3328611},
abstract = {As many people use smartphones, many Android applications are being developed and distributed. They are usually written in Java, including C legacy libraries through Java native interface (JNI). To execute these applications written in Java, a virtual machine (VM) is required. For Android, Google's own Dalvic VM had been used, and recently Android Runtime (ART) is being used.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {533–534},
numpages = {2},
keywords = {JNI, memory leak, dynamic memory},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328729,
author = {Zhang, Tao and Zuck, Aviad and Porter, Donald E. and Tsafrir, Dan},
title = {Apps Can Quickly Destroy Your Mobile's Flash - Why They Don't, and How to Keep It That Way (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328729},
doi = {10.1145/3307334.3328729},
abstract = {Smartphones typically include flash-based storage, because flash offers benefits such as fast random access, shock resistance, high density, and decreasing costs. A main drawback, however, is that flash cells can tolerate only a limited number of writes before becoming unusable.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {535–536},
numpages = {2},
keywords = {android, flash storage, app characterization, device lifespan},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328612,
author = {Soleiman, Andreas and Varshney, Ambuj},
title = {Towards Backscatter-Enabled Networked Utensils (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328612},
doi = {10.1145/3307334.3328612},
abstract = {Backscatter communication enables wireless transmissions at orders of magnitude lower power consumption when compared to conventional radio transceivers. This introduces novel opportunities for battery-free and ubiquitous sensing. We take advantage of backscatter communication to enable networked utensils. We imagine a scenario where such utensils can provide essential information about the state of the food or the beverage; for instance, the temperature or the quality of food contained in the utensils. We propose flex sensors, to achieve this capability, by augmenting utensils with flexible and inexpensive battery-free sensors that can communicate wirelessly. We demonstrate our efforts by designing a smart cup that tracks the temperature of the beverage.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {537–538},
numpages = {2},
keywords = {backscatter communication, battery-free sensing, food quality monitoring},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328613,
author = {Park, Gunhoo and Paek, Jeongyeup},
title = {Audio-Based Drone Ranging and Localization Using Deep Learning (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328613},
doi = {10.1145/3307334.3328613},
abstract = {As the use of micro-UAV (a.k.a drone) increases, distance measurement and localization of drones becomes important. We propose a real-time audio-based system that uses deep learning for not only detecting but also ranging and localization of a drone. In the proposed system scenario, each node records sound and sends it to the server after processing, and the server receives the data from each node and computes the final location of a drone. To explore the design space and investigate the feasibility of real-time acoustic ranging using deep learning, we first measure the drone detection accuracy and processing latency using two deep learning models (CNN, DNN) on both an embedded and a server-class device. By analyzing the relationship between detection probability and distance measurement, and comparing between binary and multi-class classification, we suggest a system design to range and localize the drone.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {539–540},
numpages = {2},
keywords = {drone, deep learning, UAV, localization, ranging},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328614,
author = {Tsai, Lillian and De Viti, Roberta and Lentz, Matthew and Saroiu, Stefan and Bhattacharjee, Bobby and Druschel, Peter},
title = {EnClosure: Group Communication via Encounter Closures (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328614},
doi = {10.1145/3307334.3328614},
abstract = {New applications enabled by personal smart devices and the Internet-of-Things (IoT) require communication in the context of an encounter (a period of spatial co-location). However, existing encounter-based communication (EbC) systems are limited to communication among participants that share a direct encounter. This work is inspired by two insights: (1) encounters also enable group communication among devices connected by paths in the encounter graph that is contextual, spontaneous, secure, and privacy-preserving; and (2) addressing communication partners using encounter closures subject to causal, spatial, and temporal constraints enables powerful new forms of group communication. We present the design of enClosure, a service providing group communication based on encounter closures for mobile and IoT applications, and a prototype implementation for Android and the Microsoft Embedded Social Cloud platform. Using real-world traces, we show that enClosure provides a privacy-preserving, secure platform for a wide range of group communication applications ranging from connecting attendees of a large event to disseminating health risk warnings and tracing missing persons.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {541–542},
numpages = {2},
keywords = {group communication, internet-of-things (IoT), mobile computing, privacy, encounter-based communication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328615,
author = {Arora, Nivedita and Xue, Qiuyue and Bansal, Dhruva and McAughan, Peter and Bahr, Ryan and Osorio, Diego and Ma, Xiaomeng and Sample, Alanson P. and Starner, Thad E. and Abowd, Gregory D.},
title = {Surface++: A Scalable and Self-Sustainable Wireless Sound Sensing Surface (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328615},
doi = {10.1145/3307334.3328615},
abstract = {We present Surface++, which leverages our previous work SATURN, a self-powered flexible acoustic sensor, and ZEUSSS, a passive wireless sound communication technique using analog backscatter, to create a scalable and self-sustainable wireless sound sensing surface. Our new prototype allows for large area acoustic sensing using modular fabrication techniques with the promise of being fully printable. A single small Surface++ patch can be used to extend voice and gesture input for everyday surfaces, while our more sensitive Surface++ modular array allows for large-area context sensing and localization.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {543–544},
numpages = {2},
keywords = {sound, low-power, interaction and control, backscatter communication, triboelectric nanogenerator, self-sustainable, acoustic localization, vibration, sensing, flexible electronics},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328617,
author = {Ali, Jehad and Lee, Seungwoon and Roh, Byeong-hee},
title = {Using the Analytical Network Process for Controller Placement in Software Defined Networks (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328617},
doi = {10.1145/3307334.3328617},
abstract = {The Software Defined Networking (SDN) paradigm has shifted the network intelligence from the network devices to the centralized controller. The controllers are placed in a distributed manner in a network for reliability and load balancing. However, the placement of controllers considering the whole network is not an efficient approach because applying the objective function to the overall network is a challenging task. Therefore, the division of the network into clusters makes the assignment of the switches to the controller more efficient. The placement of the controller in a cluster not only reduces the latency between the switches and the controller but other objectives such as reliability, load balancing, robustness and energy saving can also be applied to the clusters. Therefore, in this poster, a multi-criteria-decision-making (MCDM) scheme known as the Analytical Network Process (ANP) is proposed for controller place selection using clustering.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {545–546},
numpages = {2},
keywords = {analytical network process, SDN, controller placement problem, multi-objective},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328618,
author = {Tariq, Shahroz and Kim, Hoyoung and Ryoo, Jihoon},
title = {AuthGPS: Lightweight GPS Authentication against GPS and LTE Spoofing (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328618},
doi = {10.1145/3307334.3328618},
abstract = {While GPS (Global Positioning System) navigation and GPS based autonomous car driving techniques are mature, the security of GPS signal has not been a primary system concern. In fact, it has been shown that an ordinary GPS can be easily spoofed by a low-cost, open-source based software defined radio (SDR) system such as bladeRF and HackRF [3, 4] which can cause serious complications to the navigation system of the car especially for self-driving cars which are driven based on the information from sensors, cameras, and GPS. In this work, we design a new GPS authentication system called lightweight authentication GPS (AuthGPS) to authenticate GPS signal against GPS spoofing and LTE base station broadcast message spoofing. In the past, there have been many successful attempts on GPS spoofing which resulted in shifting the destination of the car to the spoofer's desired location. In a case where the car is connected to the Internet via LTE network, the navigation system can find out if the GPS is spoofed by acquiring the correct GPS satellite information from LTE base stations' location information. However, a skillful attacker can spoof the LTE base station signals [7] as well using another SDR which will produce spoofed LTE base station information. Hence giving wrong information about GPSinformation according to the will of the attacker. Currently, there are defense methods against the GPS spoofing [6]. One of them is signal-processing-based methods. By monitoring unusual or unreasonable signal changes at GPS receivers, GPS spoofing attack can be detected. Received Power Monitoring (RPM) looks at all the received amplitude and automatic gain control (AGC) setpoint [1]. The receiver will sense drastic power jump if a spoofing attack occurs. However, an overly powerful spoofing attack with noise is not detectable in the case of this mechanism. Another way to detect spoofing is the symmetric-key encryption mechanism of GPS signals. According to previous research [2], encrypted precision code for anti-spoofing referred to as P(Y) code, might not be able to be spoofed. A spoofing attack can be detected by calculating cross-correlation between spoofed coarse/acquisition code, referred to as C/A code, and P(Y) code. Unfortunately, this P(Y) code is only for military purpose while the C/A code can be publicly accessible. This method requires knowledge of specific key which is not revealed to the public to decrypt P(Y) code. Monitoring the direction of arrival of the signals can be one of the methods [6]. A GPS receiver measures the direction-of-arrival vector with more than 3 antennas. Even though this signal-geometrybased system with multiple antennas makes GPS robust, an attacker can spoof signals from multiple directions, which is more difficult to detect the spoofing. The idea here is to develop a system that can discriminate the spoofed signal without complex computation or heavy message exchange. An important component of AuthGPS is a verification of valid GPS satellite information via LTE base stations' location information. We propose 6-digit one-time password-based authentication system in this paper.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {547–548},
numpages = {2},
keywords = {mobile and wireless security, GPS spoofing, LTE authentication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328619,
author = {Lee, Ahyun and Jang, Insung},
title = {Visualization of City Model with VWorld (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328619},
doi = {10.1145/3307334.3328619},
abstract = {The VWorld Data Center provides high quality spatial information data with 3D terrains and buildings of major cities in Korea. In this paper, we proposed the visualization method for the city model using VWorld data. Anyone can use through the VWorld 3D map service site. We expect that our platform can be used to visualize 3D spatial information for various applications.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {549},
numpages = {1},
keywords = {vworld, 3d map, gis},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328620,
author = {Park, Eunjeong and Lee, Myung-Sup and Bahk, Saewoong},
title = {Data Rate and Transmission Power Adaptation for Bluetooth Low Energy (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328620},
doi = {10.1145/3307334.3328620},
abstract = {The use of Bluetooth Low Energy (BLE) has steadily increased since 2010. Bluetooth specification 4.2 defined only one data rate, 1 Mb/s. However, Bluetooth specification 5 released in 2016 specifies 2 Mb/s and coded PHY for higher throughput and for more stable transmission, respectively. In addition, this version of specification defines transmission power from -20 dBm to 20 dBm. In this paper, we propose AdaptaBLE, an algorithm that selects the data rate and transmission power of BLE by considering link stability and energy consumption. We implement AdaptaBLE on real devices and measure its performance. As a result, we confirm that AdaptaBLE successfully lowers energy consumption while keeping the link stable.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {550–551},
numpages = {2},
keywords = {rate adaptation, bluetooth low energy, power adaptation},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328621,
author = {Kim, Donghwi and Park, Soo Young and Ko, Jihoon and Ko, Steven Y. and Lee, Sung-Ju},
title = {Prototyping Functional Android App Features with ProDroid (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328621},
doi = {10.1145/3307334.3328621},
abstract = {We present ProDroid, a framework that provides Android app developers an ability to quickly produce functional prototypes. With ProDroid, developers can create a new app that imports various kinds of functionality provided by other existing Android apps. Our evaluation shows that with the help of ProDroid, a developer was able to import a function from an existing Android app into a new prototype with only 55 lines of Java code, while the function itself requires 10,334 lines of Java code to implement.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {552–553},
numpages = {2},
keywords = {android, development frameworks, functional prototyping},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328622,
author = {Gong, Taesik and Kim, Yeonsu and Shin, Jinwoo and Lee, Sung-Ju},
title = {Towards Condition-Independent Deep Mobile Sensing (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328622},
doi = {10.1145/3307334.3328622},
abstract = {Deep mobile sensing applications are suffering from various individual conditions in the wild. We propose a meta-learned adaptation technique to adapt to a target condition with a few labeled data. We evaluate our system on a public dataset and it outperforms baselines.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {554–555},
numpages = {2},
keywords = {mobile sensing, speech recognition, activity recognition, deep learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328623,
author = {Berkner, Joseph},
title = {Sensorless Indoor Localization Utilizing Collaborative Data Acquisition through Gamification (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328623},
doi = {10.1145/3307334.3328623},
abstract = {Most of the currently developed indoor localization techniques depend on some kind of sensory input, utilizing, among others, WiFi-signals (e.g. [2]), smartphone sensors (e.g. [4]) or Bluetooth beacons (e.g. [1]). However, each of these systems has its own downsides, such as a lack of infrastructure, power consumption and proneness to noise. These are the reasons no such system is currently able to be truly considered as the "GPS for the indoors", as they cannot provide worldwide coverage.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {556–557},
numpages = {2},
keywords = {landmarks, indoor localization, isovist, sensor-independent},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328624,
author = {Urano, Kenta and Hiroi, Kei and Yonezawa, Takuro and Kawaguchi, Nobuo},
title = {Basic Study of BLE Indoor Localization Using LSTM-Based Neural Network (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328624},
doi = {10.1145/3307334.3328624},
abstract = {In this paper, LSTM-based neural network is applied to indoor localization using mobile BLE tag's signal strength collected by multiple scanners. Stability of signal strength is a critical factor of wireless indoor localization for higher accuracy. While traditional methods like trilateration and fingerprinting suffer from noise and packet loss, deep learning based methods perform well. We focus on large-scale exhibition where wireless signal gets unstable due to many people. Proposed neural network consists of fully connected layers for noise removal and LSTM layers for time-series feature extraction. The network takes the time-series of signal strength as input and outputs the estimated location. In the evaluation, the number of layers is changed to find the optimal structure. As a result, the best configuration achieved the error of 2.44m at 75 percentile for the data of a large-scale exhibition in Tokyo.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {558–559},
numpages = {2},
keywords = {ble, indoor localization, lstm, deep learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328625,
author = {Alawami, Mohsen A. and Aiken, William and Kim, Hyoungshick},
title = {The Light Will Be with You. Always -- A Novel Continuous Mobile Authentication with the Light Sensor (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328625},
doi = {10.1145/3307334.3328625},
abstract = {Existing continuous authentication proposals tend to have two major drawbacks. First, touch-based smartphone authentication approaches typically require explicit user interactions with the smartphone to collect sufficient touch data. These approaches may provide an attacker the opportunity to steal a victim's sensitive data before the system detects the attacker's intrusion. Likewise, an attacker may disable the continuous authentication scheme itself before detection. Second, sensor-based continuous authentication approaches inherently suffer from high energy consumption due to the constant usage of multiple sensors. In this paper, we present a novel continuous authentication system that collects light sensor data from a user's smartphone and analyzes them to authenticate users using support vector machines. We focus on the possibility of collecting light sensor data from users' smartphones while they are conducting daily behaviors to develop an anomaly detection system.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {560–561},
numpages = {2},
keywords = {machine learning, smartphones, continuous mobile authentication, indoor environments, light readings},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328626,
author = {Tazawa, Kouki and Hamada, Kana and Hara, Michiki and Komazawa, Makoto and Tobe, Yoshito},
title = {Relationship Between LF/HF Value in Heart Rate and Used Mobile Applications (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328626},
doi = {10.1145/3307334.3328626},
abstract = {We explore the possibility of detecting person's mood with the usage pattern of mobile applications. Towards this ultimate goal, we first examine the relationship between LF/HF values in heart rate and the CDR (Call Detail Record) logs. Our evaluation result shows that different LF/HF values correspond to different types of mobile applications.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {562–563},
numpages = {2},
keywords = {lf/hf, kolmogorov-smirnov test, mobile application},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328627,
author = {Allen, Ryan and Nekrasov, Michael and Belding, Elizabeth},
title = {Data Collection from Outdoor IoT 802.15.4 Sensor Networks Using Unmanned Aerial Systems (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328627},
doi = {10.1145/3307334.3328627},
abstract = {Unmanned Aircraft Systems (UAS) are a promising technology for data collection from outdoor sensor networks. Environmental and agricultural networks may not have existing internet backhauls for data delivery due to low population densities in rural areas, making UASs a potential data delivery alternative. UASs can be deployed as aerial network relay nodes [1, 2, 3, 4] or as data mules [5, 6]. In addition to mending network fragmentation, UAS applications include post-disaster data collection involving inoperative communication infrastructure [7, 8, 9], supplementing existing communication in- frastructure for vehicular networks [10], and rural applications in environmental monitoring [11, 12] and precision agriculture [13, 14].},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {564–565},
numpages = {2},
keywords = {sensor network, wireless networks, uas, experimental measurements, internet of things, aerial networks, drone, uav, 802.15.4},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328628,
author = {Luo, Jiaqing and Shin, Kang G.},
title = {Detection of Misplaced Stationary RFID Tags (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328628},
doi = {10.1145/3307334.3328628},
abstract = {A smart shelving system can visualize stock data in real time by leveraging item-level RFID tagging. The detection of misplaced tags on stationary shelved items is very challenging due to position ambiguity, phase wrapping, device diversity, and phase ambiguity. We propose an effective way of detecting misplaced tags, called FINDS, that requires neither antenna movement nor external disturbances.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {566–567},
numpages = {2},
keywords = {misplaced tags, rfid, stationary tags},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328629,
author = {Park, JaeYeon and Cho, Hyeon and Hwang, Wonjun and Balan, Rajesh Krishna and Ko, JeongGil},
title = {Deep ECG Wave Estimation Model with Seismograph Sensor (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328629},
doi = {10.1145/3307334.3328629},
abstract = {Electrocardiogram (ECG) signals offer rich information for analyzing and understanding the cardiac activity of a person. The continuous monitoring of ECG can help diagnose cardiac disorders, such as arrhythmia, effectively. While many wearable healthcare platforms offer continuous ECG monitoring, these devices are cumbersome in the fact that they need to be continuously attached to the human body, which causes uncomfortableness, and limits their usage when monitoring a person's ECG throughout the night as they sleep. In this work, we propose a fully non-intrusive sensing system for monitoring the ECG of a person while in bed. Specifically, we present Heartquake, a geophone-based sensing system for extracting ECG patterns using heartbeat vibrations that penetrate through the mattress. The cardiac activity-originated vibration patterns are captured on the geophone and sent to a server, where the data is filtered to remove external noise and passed on to a bidirectional long short term memory (Bi-LSTM) deep learning model for ECG waveform extraction. Our experimental results with 21study participants suggest that Heartquake can detect all five ECG peaks (e.g., P, Q, R, S, T) with an average error of as low as 16 msec when participants are stationary on the bed. With additional noise factors, this error shows an increase, but can be mitigated from model personalization to still be sufficient enough as a screening tool to detect urgent situations.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {568–569},
numpages = {2},
keywords = {signal estimation, seismograph, noise filter, electrocardiogram (ecg), seismocardiogram (scg), bi-lstm},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328630,
author = {Boo, EunSeong and Raza, Shahid and H\"{o}glund, Joel and Ko, JeongGil},
title = {Towards Supporting IoT Device Storage and Network Security Using DTLS (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328630},
doi = {10.1145/3307334.3328630},
abstract = {This work presents FDTLS, a security framework that combines storage and network/communication-level security for resource limited Internet of Things (IoT) devices using Datagram Transport Layer Security (DTLS). While coalescing storage and networking security scheme can reduce redundent and unnecessary operations, we identify security- and system-level challenges that can occur when applying DTLS. FDTLS addresses these challenges by employing asymmetric key generation, a virtual peer, and header reduction-based storage optimization. Our results obtained using a Contiki-based implementation on OpenMote platforms show that compared to using storage and networking security separately, FDTLS can reduce the latency of packet transmission responses and also contribute to saving energy.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {570–571},
numpages = {2},
keywords = {dtls, self-key generation, secure internet of things},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328631,
author = {Kim, Dongwoo and Lee, Euihyeok and Kang, Seungwoo},
title = {Expediting IoT Application Testing (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328631},
doi = {10.1145/3307334.3328631},
abstract = {We propose TITAN, a tool that enables efficient testing of IoT applications during a development process. TITAN is designed to allow developers to execute and verify IoT applications in a development environment without being constrained by the physical environment and user behaviors required to test the application logic being developed. We present the initial design and prototype of TITAN and the preliminary study to evaluate its usefulness.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {572–573},
numpages = {2},
keywords = {iot application, testing, development tool},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328632,
author = {Miyagawa, Yuta and Segawa, Norihisa and Yazawa, Masato and Yamamoto, Masa-yuki},
title = {Development of a Low-Cost Gas Sensor Unit for Wide Area Air Pollution Monitoring System (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328632},
doi = {10.1145/3307334.3328632},
abstract = {In this paper, we discuss the development of a low cost sensor unit for the monitoring of nitrogen dioxide (NO2). The developed sensor unit can operate at 267.21 mW and collect NO2 concentration, temperature, and relative humidity. The sensor unit was installed outdoors near a main road, for a 122 h experiment. The data collected from the sensor unit were stable. Further, the selected electrochemical NO2 sensor was effective, confirming that NO2 concentrations were high on weekdays (during heavy traffic) and low at night.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {574–575},
numpages = {2},
keywords = {air pollution, monitoring system, nitrogen dioxide},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328633,
author = {Toshnazarov, Kobiljon and Baazizi, Hamza and Narziev, Nematjon and Noh, Youngtae and Lee, Uichin},
title = {EasyTrack - Orchestrating Large-Scale Mobile User Experimental Studies (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328633},
doi = {10.1145/3307334.3328633},
abstract = {In recent years, large-scale data collection has become crucial in Human-Computer Interaction (HCI) research. With a sharp climb of the amount of data being gathered due to an increasing number of mobile and wearable devices, real-time maintenance of Data Quality (DQ) of data-collection campaigns has already become an overwhelming task, especially in large-scale experiments. This paper proposes EasyTrack, a platform that collects large-scale data in an automatized manners. We describe how our proposed solution detects and tackles issues in data collection campaigns in an automated manner.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {576–577},
numpages = {2},
keywords = {wearable devices, user studies, streaming sensor data, human-computer interaction, human-centered computing, data quality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328634,
author = {Kalm\'{a}r, Gy\"{o}rgy and Wittemyer, George and V\"{o}lgyesi, P\'{e}ter and Rasmussen, Henrik Barner and Mar\'{o}ti, Mikl\'{o}s and L\'{e}deczi, \'{A}kos},
title = {Animal-Borne Acoustic Gunshot Detector (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328634},
doi = {10.1145/3307334.3328634},
abstract = {Poaching is one of the primary drivers of wildlife decline [1]. Animalborne sensors, particularly GPS-equipped collars, are used to enhance real-time wildlife protection. Innovations that can be integrated into these systems can immediately scale, offering broad application. GPS tracking data streams have been valuable to resolve a number of conservation challenges, but these systems have not been particularly effective in identifying poaching in real-time. Detecting poaching events is a critical need to provide actionable information for law enforcement.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {578–579},
numpages = {2},
keywords = {poaching, shockwave, low-power, acoustics, wearable},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328635,
author = {Shin, Hoon and Han, Dongsoo},
title = {Detecting Arrivals and Departure of Subway Train Using Linear Accelerometer (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328635},
doi = {10.1145/3307334.3328635},
abstract = {Subway is one of the public transport which carries people at the exact time. In the metropolis all over the world, it transfers countless people in the rush hour. Since there is no traffic jam in the subway, accuracy is one of the most crucial characters of the subway. However, subway trains are often delayed by some reasons like an accident. The delay can make many people confused and inconvenient. In this context, the need for dynamic timetable model which corrects the error of timetable in real time has emerged. Since the method to detect train moving is necessary to modify timetable, various solutions are proposed in the indoor positioning way, such as Wi-Fi fingerprint, magnetometer and so on. A method using Wi-Fi fingerprint is a primary way in indoor positioning, but it is tough to build a radio map for every single station. Shin et al. suggested a solution using a magnetometer, with simple judging criteria named 'decision peak.' This research proved that a magnetometer is a practical solution. Nonetheless, it can not detect the train moving in some cases. We propose a new method to detect the subway moving using a linear accelerometer, based on the essence of the problem.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {580–581},
numpages = {2},
keywords = {sensing data, linear accelerometer, subway timetable},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328636,
author = {Kang, Hangil and Baek, Duin and Ryoo, Jihoon},
title = {Saliency Based 360° Video Contents Encoding for Streaming Service (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328636},
doi = {10.1145/3307334.3328636},
abstract = {Video streaming service has been essential to the Internet ecosystem since a majority of Internet contents is consumed via streaming ser-vices, such as Netflix and Youtube [3]. Moreover, contents providers started to upload 4K and even 8K videos on streaming service to satisfy users' demand for higher quality of streaming service in accordance with the recent refinement on display technology.However, the available bandwidth in most of the developed countries can barely support single full HD contents streaming service [1]. Such bandwidth shortage intensifies in 360 video streaming service even at a larger scale, as 360 video contents providers started to upload 4K or 8K videos at the higher frame rate(60FPS or 120FPS). No current ISP (Internet service provider) can sustain the bandwidth needed for such scale of video contents [1]. To overcome the aforementioned network limitations, many re-searchers and engineers suggested ingenious mechanisms to reduce contents size. One of the mechanisms is viewport-only streaming service that streams a partial region in each video frame that fits in the exact viewport in an HMD device (e.g., HTC Vive, OculusVR, Google Daydream VR, and Samsung GearVR) in real-time [6].Assuming the size of the viewport is set to 90 degree, the bandwidth required for the viewport-only streaming service can be approximately reduced by an eighth of the original 360 video. Although the viewport-only streaming service can reduce con-tents size significantly, it is infeasible yet due to the existing streaming network latency. Even with the state-of-the-art content delivery network (CDN), viewport-only streaming service cannot satisfy the 10ms latency requirement in the standard Internet as demonstrated in other interactive multimedia systems [4]. Consequently, viewers can suffer discontinuity of streaming contents even in the highly optimized streaming service [8]. Thus, the research trend moved to the viewport adaptive stream-ing service that buffers segments of contents where a viewport Such reduction of contents size is achieved by the contents compression process that provides the original resolution in the Field ofView(FoV) while compromising the video quality outside the FoV. Despite the reduction of contents size and delivery of navigable 360 video contents, viewport adaptive streaming service cannot accommodate viewers' head movement within buffered video frames,especially when a viewer's focal point deviates from the viewport within the buffered frames. In this case, viewers can experience video distortions or degradation of resolutions [8]. Therefore, anew encoding mechanism that can handle viewers' deviation from the viewport while reducing contents size is required for viewers'immersive experience.To answer the requirements, we propose a saliency-based view-port adaptive streaming service, SALI360 that focuses on improving viewers' quality of perception in 360 video contents. To achieve high perception quality, we first adopt visual saliency model [9]to predict fixation regions in 360 video contents. Then we render the fixation regions on top of the geometry based encoded regions.Specifically, SALI360 encodes the peripheral regions in lower resolution to reduce the contents size, and encodes the fixation regions in higher resolution to increase the quality of perception.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {582–583},
numpages = {2},
keywords = {virtual reality, saliency, viewport adaptive streaming service, 360 video},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328637,
author = {Son, Jinho and Jo, Hyunwoo and Nyang, Daehun and Noh, Youngtae},
title = {Distributed Network Resource Sharing AP in Inter-WLAN Environments (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328637},
doi = {10.1145/3307334.3328637},
abstract = {As the number of wireless device deployments grows, it is desirable to share the highly limited wireless bandwidth efficiently and cooperatively. In WLAN, using a central controller for resource sharing and management is a common practice in mid-size and large-size network. However, in case of small businesses (i.e., restaurants, coffee shops, etc.), business owners cannot afford to obtain the controller. To realize the bandwidth sharing among Access Points (AP) in a distribute manner, seamless handoff of mobile devices (i.e., smartphones and tablets) between small-business owned Access Points (APs) via association control and maintain stable TCP connection are essential but quite challenging. This poster proposes a novel way to cooperatively share wireless resources among the APs. This includes an efficient association control between stations and APs, dedicated virtual access point per station, and tunneling support maintaining existing TCP connection after relocation to another AP.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {584–585},
numpages = {2},
keywords = {distribued network, virtual access point, wifi, wireless network},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328638,
author = {Park, Boseok and Kim, Sangwook},
title = {Intrusion Detection on IoT Services Using Event Sampling and Correlation (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328638},
doi = {10.1145/3307334.3328638},
abstract = {The IoT services have different types of security frameworks. As a result, it is difficult for security manager or attack response systems to understand the alerts and take appropriate actions. In this paper, we describes the analysis of security methods in the area of IoT and describes a mechanism that analyzes logs generated by IoT devices attacks. We models an event network based on a graph of interconnected logs between network devices and IoT gateways. Moreover, suggests an algorithm that correlate logs into single meaningful messages.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {586–587},
numpages = {2},
keywords = {internet of things, event correlation, network security, intrusion detection},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328639,
author = {Jung, Hyungkun and Lee, Kang-Woo and Cho, Eun-Sun},
title = {Outlier Detection for Ship Trajectory Prediction (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328639},
doi = {10.1145/3307334.3328639},
abstract = {The ACM International Conference on Distributed and Eventbased Systems (ACM DEBS) Grand Challenge is aiming to build faster and more accurate distributed and event based systems. In 2018, the goal of the Grand Challenge was to make predictions for vessels' destinations and arrival times. In our previous work [3], as a participant of the Grand Challenge, we adopted a grid-based Bayesian inference model to yield a decent result. However, we found that a number of serious outliers in the real-world data may adversely affect predictions. This paper introduces our attempts to enhance the performance of the previous model for predicting the destination and arrival time of a vessel issued by ACM DEBS GC 2018, by proposing an outlier detection method based on clustering and refning training data.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {588–589},
numpages = {2},
keywords = {ship trajectory, outlier detection, trajectory clustering},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328640,
author = {Kang, Sungjoo and Lee, Junhee and Jeon, Jaeho and Chun, Ingeol},
title = {Multi-Access Edge Computing Based Simulation Offloading for 5G Mobile Application (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328640},
doi = {10.1145/3307334.3328640},
abstract = {Simulation is a method of predicting future events and system states through analysis of the state model of the system over time. It can support to make decisions of mobile terminals (ex. threat assessment in an autonomous vehicle) operating in various situations under uncertain reality. Unlike a single simulation, which is executed in one mobile terminal using data collected from the same terminal, a multiple simulation, which supports to make sophisticated decisions through data collected from multiple terminals, is not only complicated to implement but also requires a large number of computations and has network delay problem in collecting data from plenty of data sources [1]. Consequently, it is impossible to implement in a single mobile terminal.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {590–591},
numpages = {2},
keywords = {simulation offloading, kubernetes, simulation-as-a-service, multi-access edge computing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328641,
author = {Segawa, Norihisa and Yazawa, Masato and Yamamoto, Masa-yuki},
title = {Sensor Network for Transmitting Tsunami Information Using MAD-SS Technology in Tosa Bay (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328641},
doi = {10.1145/3307334.3328641},
abstract = {In Japan, more than 1,000 earthquakes occur annually, thus causing enormous damage. However, in areas facing the ocean, the risks of secondary disasters due to tsunamis are extremely high. We conducted research the on an emergency disaster prevention system for transmitting tsunami information using ultra-low- frequency sound sensors and tide-level gauges. The system conveyed the information to members in the crisis management staff for the area concerned, and we assumed that the staff in charge made evacuation recommendations to the citizens of the area based on the information. In addition, when a tsunami occurs, there is a high possibility that an existing infrastructure cannot be used because an earthquake has already occurred. In this research, we develop a disaster prevention system using tsunami information using long-distance wireless communication technology, MAD-SS.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {592–593},
numpages = {2},
keywords = {sensor network, narrow band spread spectrum, direct sequence of spread spectrum communication (ds-ss), lpwa},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328642,
author = {Cherrared, Sihem and Imadali, Sofiane and Fabre, Eric and G\"{o}ssler, Gregor},
title = {SAKURA a Model Based Root Cause Analysis Framework for VIMS (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328642},
doi = {10.1145/3307334.3328642},
abstract = {Model based machine learning (MBML) techniques solve novel diagnosis problems and provide explanations for their decisions. However, current MBMLs suffer some limitations, since virtualization of network brings new challenges such as the dynamic topology and elasticity. Those limitations include the high dependency on previous knowledge and the difficulty to represent the model. To face those limitations, we propose SAKURA: a root cause analysis framework for the virtual Ip Multimedia Subsystem (vIMS). SAKURA is composed of a self-modeling and a constraints solver.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {594–595},
numpages = {2},
keywords = {root cause analysis, self-modeling, service function chain},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328643,
author = {Li, Biyi and Cheng, Bo and Wang, Meng and Niu, Meng and Chen, Junliang},
title = {A Lightweight Network Slicing Orchestration Architecture (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328643},
doi = {10.1145/3307334.3328643},
abstract = {With the explosive growth of large scale services, traditional mobile networks have become increasingly unable to guarantee the efficient operation of services. However in the fifth generation (5G), supported by Software Defined Network (SDN) and Network Function Virtualization (NFV), network slicing technology [1] makes mobile networks more intelligent and flexible. 5G network slicing allows a set of logically independent virtual networks to be created on a common physical infrastructure and provides appropriate monitoring, management and resource allocation for a variety of different types of communication services [2].},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {596–597},
numpages = {2},
keywords = {network slicing, template, network interface, network function virtualization},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328644,
author = {Park, Seongjoon and Lee, Joon Yeop and Um, Inseop and Joe, Changhwan and Kim, Hyeong Tae and Kim, Hwangnam},
title = {RC Function Virtualization - You Can Remote Control Drone Squadrons (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328644},
doi = {10.1145/3307334.3328644},
abstract = {This poster presents a virtual control interface for Unmanned Vehicle System (UVS), to improve scalability and accessibility of Human-Computer Interaction (HCI) in their maneuvering. After the first remote control vehicle was born, the remote control unit was paired with a single vehicle for safety and security. To overcome this constrained remote control design, we propose a concept that a single manufacturing stand-alone RC can control one or several unmanned vehicles (UVs), regardless of vehicle type, named RC Function Virtualization (RFV). We can abstract the RC input to a high-level set of control commands and apply it to the numerous types of UVs connected through a wireless network. Our contribution is the separation of the RC and UV pairs so that the user can control all types of UVs even mixed types of UVs. We implemented the prototype of the RFV system, and demonstrated with Unmanned Ground Vehicle (UGV), Unmanned Air Vehicle (UAV), and the combinations of them, with only one RC.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {598–599},
numpages = {2},
keywords = {remote control virtualization, unmanned vehicle system, multi robot control},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328645,
author = {Rehman, Ubaid Ur and Lee, Sungyoung},
title = {Natural Language Voice Based Authentication Mechanism for Smartphones (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328645},
doi = {10.1145/3307334.3328645},
abstract = {We have designed and implement a random text dependent voice based authentication protocol for smartphones. The objective was to provide an efficient and reliable authentication mechanism that ensure prevention against the emerging attacks. In this paper, we have focused on the architecture, protocol, and prevention against replay attack only.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {600–601},
numpages = {2},
keywords = {authentication, replay attack, voice, smartphones},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328646,
author = {Lee, Jihyun and Park, Gyeongcheol and Jung, Hyunggu},
title = {SEEjang: Smart, Easy, and Economical Offline Shopping Assist App Development through a Design Thinking Proces (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328646},
doi = {10.1145/3307334.3328646},
abstract = {It is difficult for shoppers to estimate the amount of cost spent while shopping offline. Existing mobile platforms can be used to assist offline shoppers, but there still remain questions about the usability and affordability of such platforms. To reduce this gap, we propose SEEjang, a prototype for providing users with a smart, easy, and economical experience with offline shopping. We developed the application through a design thinking process to maximize consumer satisfaction with offline shopping.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {602–603},
numpages = {2},
keywords = {offline shopping experiences, user centered design, human-computer interaction, mobile computing, design thinking},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328647,
author = {Zhang, Dan and Woo, Simon S.},
title = {Predicting Air Quality Using Moving Sensors (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328647},
doi = {10.1145/3307334.3328647},
abstract = {In recent years, interest in measuring air quality has spiked due to rising environmental and health concerns in South Korea. In particular, microfine dust (microdust) is known to cause serious health issues to people. Therefore, measuring and predicting mircodust is an important problem. A typical way of measuring microdust is to use sensors from fixed location. However, this cannot capture the local dynamics of microdust and is limited to accurate measurement near fixed locations. Therefore, there is an immediate need to provide more accurate local air quality measurements in the areas where fixed local sensors are not installed. In this preliminary research, we focus on modeling the air quality pattern in a given local area by using vehicles equipped with cheap IoT sensors, where vehicles move around the area. As a pilot study, We measured the microdust level running experiments for 2 weeks with 3 different cars. Also, we developed an machine learning algorithm to better predict the local air quality using moving sensors. Further, we built an application where measured air quality is reported to the end users. We demonstrated the feasibility of using inexpensive IoT sensors in moving vehicles to provide better local air quality to end users.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {604–605},
numpages = {2},
keywords = {mobile sensors, air quality, real time prediction, machine learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328648,
author = {Shen, Yilin and Nama, Sandeep and Jin, Hongxia},
title = {Teach Once and Use Everywhere -- Building AI Assistant Eco-Skills via User Instruction and Demonstration (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328648},
doi = {10.1145/3307334.3328648},
abstract = {Voice-enabled AI assistants rely on developers to build every single skill, although many skills share similar functions. We propose a concept and prototype system, ksystem, to automatically build a set of similar skills in the ecosystem (eco-skills) with one-time teaching from end users. During teaching, a user only needs to demonstrate on the screen in one (native) mobile app and provides natural language (NL) instructions.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {606–607},
numpages = {2},
keywords = {auto natural language development, eco-skill development for ai assistants, auto action fulfillment},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328649,
author = {Lee, HyunJong and Lee, Hee Won and Ra, Moo-Ryong and Xiang, Yu and Flinn, Jason},
title = {Accelerating Applications in the Fast-Moving Devices with Proactive Provisioning (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328649},
doi = {10.1145/3307334.3328649},
abstract = {An increasing number of applications that leverage built-in sensors is hosted on new types of devices such as vehicles and drones. Example applications are augmented reality Head-Up-Display in a connected car [2], scout drone that chases a target suspect among the crowd [3], autonomous fleet drones [1], and so on. These futuristic applications in various genres of devices are latency-sensitive and require a significant computation power to process a tremendous amount of data from built-in sensors [8]. However, the capabilities of processors shipped with these devices are limited. A natural solution is offloading to an edge surrogate,1 running on a 'nearby' edge-cloud that offers more computation capacity at low latency.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {608–609},
numpages = {2},
keywords = {fast-moving devices, proactive provisioning, edge provisioning, edge node prediction},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328650,
author = {Vishwanathan, Harishankar and Park, Chang Min and Mishra, Sidharth Kumar and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
title = {Partitioning Garbage Collection Between the Secure and Normal Worlds for Trusted Applications (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328650},
doi = {10.1145/3307334.3328650},
abstract = {Trusted Applications (TAs) written for Trusted Execution Environments (TEEs) using ARM TrustZone are currently written in C; there is limited support for higher-level languages. This leads to common manual memory management problems like buffer overflow and use-after-free. Higher-level languages, which have managed runtimes, allow for automated memory management, the benefits of which are widely accepted. To allow for automated memory management of TAs, we need to have a runtime that handles allocation and garbage collection (GC). However, having the entire allocator and GC in the secure world would increase the Trusted Computing Base (TCB) of the secure world. We propose TrustGC, a mechanism to partition garbage collection and allocation between the secure world and the normal world. TrustGC allows for automated memory management of TAs by leveraging the help of a GC partly running in the normal world.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {610–611},
numpages = {2},
keywords = {memory management, security, trustzone, garbage collection},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328651,
author = {Tao, Linfeng and Xu, Rui and Tian, Teng and Xiang, Zikun and Li, Yifei and Jin, Xi and Ren, Jun and Li, Zhengda and Li, Chenxia},
title = {CINT -- An Energy-Efficient Mixed-Signal In-Memory CNN Accelerator Based on NOR Flash Memory (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328651},
doi = {10.1145/3307334.3328651},
abstract = {Convolutional neural network (CNN) is a power-hungry and resource-consuming application, which makes it hard to deploy on end devices. We propose a method to perform convolution operations in NOR flash memory. Experiment results show that our method has great performance and high energy efficiency.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {612–613},
numpages = {2},
keywords = {nor flash, neural network, computing in memory},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328652,
author = {Kil, Woogeun and Ko, Kwangpyo and Lee, Seungwoon and Roh, Byeong-hee},
title = {MR and IoT Convergence Platform with AI Support for Disaster Recognition (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328652},
doi = {10.1145/3307334.3328652},
abstract = {Because disaster situations can cause damage to people and property, fast recognition and Countermeasure is important. IoT and MR, the technologies that have become popular nowadays, expected to play a key role in this domain. In this paper, we will introduce MR and IoT Convergence Platform with AI Support for Disaster Recognition This platform can recognize a disaster situation with sensors and AI system, and report to the user's MR devices. Also, we build a prototype using OneM2M-based Mobius Platform, Microsoft Hololens, and CNN-based AI Camera for proving feasibility.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {614–615},
numpages = {2},
keywords = {internet of things, artificial intelligence, disaster recognition, mixed-reality, disaster countermeasure},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328653,
author = {Lee, Soyeon and Park, Sangjoon},
title = {High Precision Relative Positioning on a Mobile (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328653},
doi = {10.1145/3307334.3328653},
abstract = {Although there are many commercial products and services advertising their capability of indoor navigation using smartphone, still the service coverage is highly restricted to the specific area due to tremendous effort on pre-survey and maintenance on positioning resources such as radio map of Wi-Fi signals. Most of indoor positioning is dependent on the installed facilities such as Wi-Fi APs and BLE beacons in service area. Without pre-surveyed information such as fingerprint database, one can not localize himself at the first visiting site.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {616–617},
numpages = {2},
keywords = {indoor positioning, pedestrian dead reckoning, heading adjustment},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328654,
author = {Bilal, Hafiz Syed Muhammad and Lee, Sungyoung},
title = {Right Intervention at Right Time to Right Person for Healthy Behavior Adaptation (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328654},
doi = {10.1145/3307334.3328654},
abstract = {Smart gadgets play a vital role to adapt the unhealthy lifestyle by converging science and technology in this digital world. The challenge of behavior change through step-by-step coaching and guidance is realized by just-in-time intervention using mobile computing. The amalgamation of behavior change theories with digital technologies support us to mold the behavior in a scientific manner. Wellness platform based behavior analysis is performed through unbiased life-log as well as questionnaire for permanent and ad-hoc users. Daily personalized coaching has been provided to motivate the users, whereas instant context-based recommendations have supported stage-wise adaptation of healthy behavior.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {618–619},
numpages = {2},
keywords = {just-in-time intervention, recommendations, lifestyle habits, wellness services, mobile computing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328655,
author = {Kim, Sunwoo and Kang, Hyunwoo and Kim, Song Min and Lee, Sung-Ju},
title = {Gas Sensing with COTS RFID Devices (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328655},
doi = {10.1145/3307334.3328655},
abstract = {Gas monitoring, often as a part of safety and health systems, is widely used in a variety of sectors such as manufacturing, auto- mobiles, medical, households, food and beverages, environments, and HVACs. Existing gas monitoring approaches such as the use of catalytic and infrared sensors and electrochemical and metal oxide semiconductor technologies, typically require expensive hardware or are power hungry, and thus not suitable for long-term and large scale deployments. We propose a gas intensity measuring system with cost-effective commercial off-the-shelf (COTS) RFID devices. Our key intuition is that the changes in phase and strength of the signal result from not only the signal propagation but also from the hardware (i.e., tag's circuit). To this end, we propose a method to in- tegrate RFID with a chemiresistor, called Carbon Nanotubes (CNTs), whose electrical property varies with the nearby gas concentration. Our system shows the potential of low-cost, easy-to-make, and wireless sensing based gas monitoring systems.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {620–621},
numpages = {2},
keywords = {rfid, gas sensors, wireless sensing, sensors},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328656,
author = {Abbas, Asim and Bilal, Hafiz Syed Muhammad and Lee, Sungyoung},
title = {Smartphone Based Wellness Application for Healthy Lifestyle Promotion (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328656},
doi = {10.1145/3307334.3328656},
abstract = {Wellness platform plays a vital role to prevent chronic disease. In this paper, we have introduced wellness smartphone application within the ambit of the Mining Mind project, which aims to support the people to adopt healthy behavior and lifestyle. When an unhealthy behavior is detected, personalized physical recommendations are generated automatically by the Mining Mind wellness platform. Recommendations are delivered through Push notification and display on the application main screen for the user. The application has feedback functionalities on the effectiveness of recommendation and education. The application also supports descriptive analytics of wellness goals achieved on a monthly, weekly and daily basis.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {622–623},
numpages = {2},
keywords = {lifestyle monitoring, healthy lifestyle program, behavior change, wellness application},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328657,
author = {Dolui, Koustabh and Cuba Gyllensten, Illapha and Lowet, Dietwig and Michiels, Sam and Hallez, Hans and Hughes, Danny},
title = {Towards Privacy-Preserving Mobile Applications with Federated Learning: The Case of Matrix Factorization (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328657},
doi = {10.1145/3307334.3328657},
abstract = {Recommender systems have gained prominence in bringing users tailor-made content from the web aiding their decision making process. However, this personalization comes at a cost of privacy of sharing personal information with the recommendation provider. Moreover, with growing sizes of datasets and models, centralized processing of such data has become challenging. To this end, we propose a federated matrix factorization algorithm to enable personal data to be stored and used on-device for training while sending updates to train a centralized model. We illustrate preliminary results from our algorithm applied to recommendation of articles to users of a mobile application based on their reading history. We compare our performance with centralized matrix factorization applied on the same dataset.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {624–625},
numpages = {2},
keywords = {machine learning, recommender systems, federated learning, privacy-preserving},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328659,
author = {Kim, Sanghun and Kwon, Dongwoo and Ji, Youngmin},
title = {CNN Based Human Detection for Unmanned Aerial Vehicle (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328659},
doi = {10.1145/3307334.3328659},
abstract = {In order to utilize a unmanned aerial device such as a drone in terms of reconnaissance, surveillance and disaster management, a technique capable of performing real-time human detection is needed. In this study, we introduce a method of human detection by constructing environment similar to a drone by installing wide angle lens camera on the ceiling. Tiny-Yolo, which is a kind of Convolutional Neural Network, was used as recognition technology. Camera sensors were installed on ceilings in various places inside the building to collect training data for human detection. The Training was performed based on 4,000 pieces of collected data, and the accuracy of recognition was measured. As a result, 95.37% precision and 96.60% recall were obtained.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {626–627},
numpages = {2},
keywords = {human detection, drone, convolutional neural networks},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328660,
author = {Reksten-Monsen, Christian August and Han, Jun},
title = {Towards Precise Localization of E-Scooters Using Sidewalk Ramps (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328660},
doi = {10.1145/3307334.3328660},
abstract = {Electric scooters (e-scooters) are proliferating rapidly as an inexpensive mode of transportation. GPS equipped smartphones are used to guide riders from points A to B, but GPS is known to have hundreds of meters of error in areas where the line of sight to navigation satellites is fully or partially obscured. To address this problem, we present ScootLoc, which enables precise e-scooter localization, by leveraging physical characteristics of sidewalk ramps, to correct for GPS error. We show that e-scooters equipped with a gyroscope and an accelerometer are able to uniquely identify sidewalk ramps and match the ramp to its physical location, thereby augmenting noisy GPS based navigation systems. We implement ScootLoc and present a preliminary evaluation on a route containing ten ramps, achieving 97% classification accuracy.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {628–629},
numpages = {2},
keywords = {positioning and tracking, mobile sensing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328661,
author = {Abbas, Asim and Ansaar, Muhammad Zaki and Lee, Sungyoung},
title = {Medical Concept Extraction Using Smartphone and Natural Language Processing Techniques (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328661},
doi = {10.1145/3307334.3328661},
abstract = {Over the past few decade, smartphone technology has played a vital role in the healthcare domain. In this paper, we proposed a methodology to allow end users to automatically process the medical text image using a camera or enter text manually. Then the system output allows to extract medical concepts, its semantic type and entity type from medical text apply Natural Processing Language techniques from UMLS medical dictionary. The medical text can be a health report, a clinical case, or other kinds of a text containing medically related information. The aim of this kind of methodology of the mobile application is to contribute in the area of natural language processing (NLP), intelligent system and to increase the medical students and bioinformatics researchers interest to quickly accessing information about medical data.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {630–631},
numpages = {2},
keywords = {umls, information extraction, intelligent system, nlp},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328662,
author = {Ramesh, Soundarya and Pathier, Thomas and Han, Jun},
title = {SoundUAV: Fingerprinting Acoustic Emanations for Delivery Drone Authentication (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328662},
doi = {10.1145/3307334.3328662},
abstract = {Delivery drones may become potential targets for package theft. An adversary may launch a drone impersonation attack, where the adversary's drone purports to be a legitimate delivery drone. To protect against such attacks, authenticating drones is crucial. Existing authentication schemes based on digital certificates have been shown to be compromised by security breaches on certificate authorities. Thus, we propose SoundUAV as a second factor of authentication for drones that leverages uniqueness in acoustic emanations to fingerprint drones, even within the same make and model. This uniqueness is attributed to hardware defects in motors, making SoundUAV secure against impersonation and robust to large scale attacks. Further, SoundUAV requires no hardware modifications to drones as it utilizes the pervasive acoustic emanations. We perform preliminary evaluation on eleven drones and obtain a fingerprinting accuracy of 99.48%.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {632–633},
numpages = {2},
keywords = {acoustic analysis, drones, authentication, fingerprinting},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328663,
author = {Yang, Jin Mo and Kang, Byungjun and Bahk, Saewoong},
title = {RSSI Based Power Control Algorithm for C-V2X Mode 4 (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328663},
doi = {10.1145/3307334.3328663},
abstract = {We propose transmission power control algorithm for Cellular-Vehicle-to-everything (C-V2X) mode 4, based on standard-compliant sensing scheme. We show that standard resource allocation scheme for Vehicle-to-vehicle (V2V) communication mode 4, with fixed transmission power, has room for improvement. Assuming channel reciprocity, proposed algorithm estimates neighbor's SINR and controls transmission power based on the estimation. We show that proposed scheme enhances system level PRR and also, performance of the algorithm increases as vehicles get more dense.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {634–635},
numpages = {2},
keywords = {v2v, power control, cellular v2x, mode 4, cam},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328664,
author = {Ha, Donghee and Kwon, Jinse and Kim, Hyungshin},
title = {Accelerating Colorizer of Shaded Image for Autonomous Driving in Resource-Constrained SoC (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328664},
doi = {10.1145/3307334.3328664},
abstract = {Image-based convolutional neural network(CNN) algorithms are spreading across a variety of applications. In particular, an autonomous vehicle recognizes objects and the surrounding situation using the CNN models. CNN models for image classification are trained using clear image dataset, so they are not robust to grayscale images or noise-intensive data. Therefore, there is a risk of an accident because the quality of the input image drops rapidly during night driving. The region that is revealed by the headlight can have colors, but in the shaded area it has a brightness that is not enough to get color values. We intend to increase the safety of autonomous driving by coloring this region of interest(ROI).},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {636},
numpages = {1},
keywords = {computer vision, mobile gpu, deep learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328665,
author = {Lee, Euihyeok and Kang, Seungwoo},
title = {Towards the Experience of Daytime Driving at Night (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328665},
doi = {10.1145/3307334.3328665},
abstract = {What if the window of our cars is a magic window, which transforms dark views outside of the window at night into bright ones as we can see in the daytime? In this paper, we investigate the feasibility of implementing such a magic window, addressing two important requirements: (1) the quality of transformed images (from the nighttime to the daytime) and (2) the frame rate of transformed image stream. We present our initial ideas to address the problem and report preliminary results towards the experience of daytime driving at night.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {637–638},
numpages = {2},
keywords = {image translation, image interpolation, real-time processing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328666,
author = {Lee, Daehwa Rayer and Jang, Yunhee and Jang, Hanbin and Kim, Hyoungshick},
title = {80% of Block Propagation Rate is Enough - Towards Secure and Efficient PoW-Based Blockchain Consensus (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328666},
doi = {10.1145/3307334.3328666},
abstract = {Recently, Samsung released Galaxy S10 supporting the cryptowallet feature [5]. However, it is still questionable whether cryptocurrency can be popularly used for mobile payments because processing transactions in existing blockchain systems are too slow. For example, public blockchain systems such as Bitcoin [6] (7 transactions per second (TPS)) and Ethereum (15 TPS) are significantly slower than mainstream payment systems such as Visa (2,000 TPS) using a centralized database.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {639–640},
numpages = {2},
keywords = {consensus algorithm, blockchain, security},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328667,
author = {Yoshida, Takuto and Nozaki, Junto and Urano, Kenta and Hiroi, Kei and Yonezawa, Takuro and Kawaguchi, Nobuo},
title = {Gait Dependency of Smartphone Walking Speed Estimation Using Deep Learning (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328667},
doi = {10.1145/3307334.3328667},
abstract = {This paper proposes an accurate estimation method of walking speed using deep learning for smartphone-based Pedestrian Dead Reckoning (PDR).PDR requires to estimate speed and direction of pedestrians accurately using accelerometer and gyroscope.To improve the accuracy of PDR, existing works focused to improve the key factors of speed estimation (i.e., stride and/or step estimation) by adapting deep learning.On the contrary, our research proposes to adapt deep learning more directly to estimate walking speed from sensor data of smartphone. We evaluate the accuracy of proposed method by comparing with conventional PDR method. As a result, we confirmed that proposed method can estimate the speed more accurately.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {641–642},
numpages = {2},
keywords = {pdr, deep learning, location estimation},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328717,
author = {Jung, Hyunwoo and Kang, Cholmin and Lee, Youngki},
title = {Machine Learning without Real-World Data (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328717},
doi = {10.1145/3307334.3328717},
abstract = {It has been a common approach to apply Machine Learning (ML) techniques over sensory data for inferring human behavior, activities, emotions, and surrounding contexts. Especially, IMU (Inertial Measurement Unit) sensors are widely used to obtain dataset to train ML models for human activity recognition. A key challenge in building highly accurate ML models lies in collecting a wide variety of activity data from a large number of users. Such data collection is often a highly time-consuming and costly process.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {643–644},
numpages = {2},
keywords = {machine learning, simulation, human activity recognition, sensor},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328718,
author = {Son, Kyuho and Han, Dongsoo},
title = {Grid-Based Gaussian Modeling for Cellular Positioning (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328718},
doi = {10.1145/3307334.3328718},
abstract = {By the infrastructure of cellular network changing, the conventional methods has became not be adequate. As an alternative, a probabilistic model for dynamic input aiming on signals from multiple cellular station is proposed in this study, and the feasibility was verified. The result from the experiment can be shown a little petty, but if one experiments in a better environment and utilizes LTE and 5G network, about 20~30m of the positioning error can be expected.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {645–646},
numpages = {2},
keywords = {cellular positioning, grid, gaussian model},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328719,
author = {Yonezawa, Takuro and Nishiyama, Yuuki and Hiroi, Kei and Kawaguchi, Nobuo},
title = {Capturing Subjective Time as Context and It's Applications (Poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328719},
doi = {10.1145/3307334.3328719},
abstract = {We propose an integrated framework for sensing, recognizing and utilizing of subjective time as context. Various studies on experimental psychology have showed several factors which affects subjective time. Those factors should be partially captured by ubiquitous sensors such as smartphones and wearable devices, therefore, we tackle to create common and individual model for subjective time based on the sensor data. We report our first prototype implementation for the framework based on AWARE framework with adding experience sampling method for subjective time recognition. In addition, we discuss potential applications which leveraging advantages of subjective time as context.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {647–648},
numpages = {2},
keywords = {experience sampling method, context-awareness, subjective time},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328565,
author = {Shin, Jaemin and Lee, Seungjoo and Lee, Sung-Ju},
title = {Accurate Eating Detection on a Daily Wearable Necklace (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328565},
doi = {10.1145/3307334.3328565},
abstract = {While there are many research proposals for wearable Automatic Dietary Monitoring (ADM) systems that detect eating of a user, it is difficult to notice real-world users wearing such devices in public. We propose a new wearable ADM system that could be used daily by real-world users. It is designed in a form of necklace, providing natural and firm contact of sensor on user's skin to accurately capture eating activities. At our preliminary experiments, our wearable ADM system detected eating of a user with 86.1% accuracy.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {649–650},
numpages = {2},
keywords = {automatic dietary monitoring, eating episode detection, food journal},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328566,
author = {Shi, Shu and Hwang, Michael and Gupta, Varun and Jana, Rittwik},
title = {Latency Adaptive Streaming of 8K 360 Degree Video to Mobile VR Headsets (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328566},
doi = {10.1145/3307334.3328566},
abstract = {In this demo, we showcase how to stream 8K 360° video to commod- ity mobile devices without pre-processing or viewpoint prediction using our Freedom system. Users can freely select the viewpoint, zoom in and zoom out to enjoy the full quality of the 8K resolu- tion using any Samsung GearVR compatible smartphone. We also present how our system works internally to dynamically adjust margin size to accommodate to network latency and how our ap- proach can save up to 80% bandwidth compared to streaming full video to mobile devices.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {651–652},
numpages = {2},
keywords = {mobile vr, 360 degree video, mobile edge cloud},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328567,
author = {Kim, Junhui and Kim, Joongheon},
title = {Light-Weight Programming Language for Blockchain (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328567},
doi = {10.1145/3307334.3328567},
abstract = {This demo abstract introduces a new light-weight programming language koa which is suitable for blockchain system design and implementation. In this abstract, the basic features of koa are introduced including working system (with playground), architecture, and virtual machine operations. Rum-time execution of software implemented by koa will be presented during the session.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {653–654},
numpages = {2},
keywords = {smart contract, blockchain, programming language},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328568,
author = {Lee, Jungho and Ryu, Woo-Jong and Ahn, Yoonjoo and Lee, Song-Eun and Kim, Kang-Min and Park, Jun-Hyung and Lee, SangKeun},
title = {MeChat: In-Device Conversational Photo Sharing Service (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328568},
doi = {10.1145/3307334.3328568},
abstract = {In this demo, we demonstrate an in-device conversational photo sharing service, termed meChat, which helps users share in-device photos easily in messaging applications by searching conversation-related photos automatically. In particular, meChat understands the semantics of on-going conversation and in-device photos by projecting both of them into a single semantic space. Subsequently, it retrieves in-device photos related to the conversation context. Through this process, meChat makes it easy for the users to share the photos while communicating in messaging applications. In addition, it is worth noting that meChat works in a stand-alone, privacy-protecting manner without sending out any in-device photos and conversations to the external servers. This is different from existing photo services (e.g., Google Photos) which resort on the cloud server.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {655–656},
numpages = {2},
keywords = {on-device intelligence, personal service},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328569,
author = {Katayama, Shin and Mathur, Akhil and Okoshi, Tadashi and Nakazawa, Jin and Kawsar, Fahim},
title = {Situation-Aware Conversational Agent with Kinetic Earables (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328569},
doi = {10.1145/3307334.3328569},
abstract = {Conversational agents are increasingly becoming digital partners of our everyday computing experiences offering a variety of purposeful information and utility services. Although rich on competency, these agents are entirely oblivious to their users' situational and emotional context today and incapable of adjusting their interaction style and tone contextually. To this end, we present a first-of-its-kind situation-aware conversational agent on kinetic earable that dynamically adjusts its conversation style, tone, volume in response to users emotional, environmental, social and activity context gathered through speech prosody, ambient sound and motion signatures.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {657–658},
numpages = {2},
keywords = {emotion regulation, earables, conversational agent, context awareness},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328570,
author = {Prakash, Siddhant and Bahremand, Alireza and Nguyen, Linda D. and LiKamWa, Robert},
title = {GLEAM -- An Illumination Estimation Framework for Real-Time Photorealistic Augmented Reality on Mobile Devices (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328570},
doi = {10.1145/3307334.3328570},
abstract = {Mixed reality mobile platforms attempt to co-locate virtual scenes with physical environments, towards creating immersive user experiences. However, to create visual harmony between virtual and physical spaces, the virtual scene must be accurately illuminated with realistic lighting that matches the physical environment. To this end, we design GLEAM, a framework that provides robust illumination estimation in real-time by integrating physical light-probe estimation with current mobile AR systems. We present a demo implementation of GLEAM by means of an AR application that estimates environmental illumination and renders the scene with real-time illumination updates. We demonstrate the efficacy of GLEAM's estimation against a current commercial status quo solution, Apple's ARKit, with the same application.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {659–660},
numpages = {2},
keywords = {image-based lighting, image processing, geometry, augmented reality, lighting models, light estimation, light probe},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328571,
author = {Hwang, Inseok and Rozner, Eric and Yoo, Chungkuk},
title = {Telekinetic Thumb Summons Out-of-Reach Touch Interface Beneath Your Thumbtip (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328571},
doi = {10.1145/3307334.3328571},
abstract = {As personal interactive devices become more ingrained into our daily lives, it becomes more important to understand how seamless interaction with those devices can be fostered. A typical mechanism to interface with a personal device is via a touch screen, in which users use their fingertip or stylus to scroll, type, select, or otherwise control device usage. Touch-based techniques, however, can become restrictive or inconvenient under a variety of scenarios. For example, personal devices such as phones or tablets are continuously increasing in size, making one-handed interaction difficult because one cannot easily hold the phone and touch the screen (with the thumb) at the same time with one hand. Therefore, in this demo, we present a new technique to interact with personal devices in which the screen and touch screen interactions can adapt to a user's grip or current touch constraints.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {661–662},
numpages = {2},
keywords = {adaptive interface, user interface programming, hand-held device, intelligent interface, gesture input, mobile computing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328572,
author = {Hollingsworth, Max and Lee, Gyuhong and Lee, Jihoon and Lee, Jinsung and Im, Youngbin and Wustrow, Eric and Grunwald, Dirk and Ha, Sangtae},
title = {This is Your President Speaking: Spoofing Alerts in 4G LTE Networks (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328572},
doi = {10.1145/3307334.3328572},
abstract = {4G LTE networks across the world (e.g., United States, Europe, and South Korea) use the same mechanism to broadcast emergency alerts. These alerts include AMBER, severe weather alerts, and the (unblockable) Presidential Alert in the US. We demonstrate the ability to spoof these alerts by forcing any 4G phone in the area of our malicious cell tower to receive and display a fabricated message. This demonstration uses a commercially-available software-defined radio, an LTE base station, and our modifications to the open-source NextEPC and srsLTE libraries to send the Presidential Alert to phones volunteered from the audience.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {663–664},
numpages = {2},
keywords = {security, presidential alert, lte, cmas, spoofing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328573,
author = {Mukhopadhyay, Shalini and Ahmed, Nasimuddin and Jaiswal, Dibyanshu and Ghose, Avik},
title = {A Robust and Customizable Tracking Algorithm for Accurate Heart Rate Estimation (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328573},
doi = {10.1145/3307334.3328573},
abstract = {Wearable health monitoring has become a very familiar term in today'sworld. One of the most popular means ofwearable sensing is photoplethysmogram (PPG). Due to its unobtrusive and ubiquitous nature, it is gaining popularity among people everywhere. Due to the ease of use, the utility of such technology is increasing day by day. However, in theworld of researchers, the accurate estimation of heart rate (HR) in presence of motion artefacts remains an unsolved problem due to the susceptibility of PPG signals to corruption by motion artefacts. The way in which a person fastens the device on the wrist plays an important role in the acquisition of signal from the device. While there are various research works going on in this field, there is always a trade-off between accuracy and complexity of algorithm and hardware resources. Also, in such scenarios where the sensor gets misplaced due to movements, there might be no PPG signal component available in the acquired signal data. In such cases the sophisticated denoising algorithms make no sense.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {665–666},
numpages = {2},
keywords = {heart rate, photoplethysmography, wearable health, motion artefacts},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328574,
author = {Zakaria, Camellia and Lee, Youngki and Balan, Rajesh},
title = {Passive Detection of Perceived Stress Using Location-Driven Sensing Technologies at Scale (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328574},
doi = {10.1145/3307334.3328574},
abstract = {Much research argues that feeling overwhelmed by stress and for prolonged periods can lead to severe mental illness such as early onset depression and anxiety among many others. Recovering from severe stress to a normal state is much easier, in terms of the length of time and treatment required, compared to when more serious conditions have manifested [1]. Unfortunately, existing stress monitoring applications either require dedicated applications to be installed on the user's mobile device or use various mobile and wearable sensors [2, 4, 6, 7]; thus are not scalable to large number of users. Our goal is to provide a community-wide "safety net" that will automatically and non-intrusively detect individuals exhibiting signs of excessive stress without them installing any dedicated app. YouTube Demo Link https://youtu.be/LKQvIX4W6L0},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {667–668},
numpages = {2},
keywords = {wifi indoor localisation, mental health, stress, machine learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3329407,
author = {Cho, Hyunsung and Oh, Jinyoung and Kim, Juho and Lee, Sung-Ju},
title = {Sender-Controlled Mobile Instant Message Notifications Using Activity Information (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3329407},
doi = {10.1145/3307334.3329407},
abstract = {We propose the design of MyButler, a sender-controlled notification management system that mitigates disruption caused by mobile instant messaging through sharing the receiver's activity information with the sender.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {669–670},
numpages = {2},
keywords = {interruptions, mobile instant messaging, context-aware computing, smartphone notifications},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328575,
author = {Katsumata, Kento and Eigen, Yusaku and Noda, Yuka and Tsuruoka, Masayoshi and Hashiba, Satsuki and Numoto, Shotaro and Katayama, Shin and Okoshi, Tadashi and Nakazawa, Jin},
title = {Motivating Long-Term Dietary Habit Modification through Mobile MR Gamification (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328575},
doi = {10.1145/3307334.3328575},
abstract = {In correlation with the socio-economic development, changes in people's lifestyle brought about significant impact on dietary patterns.&nbsp;&nbsp;Though public concerns over healthy eating are increasing, many are still uncertain when choosing a well balanced meal amid welter of information.&nbsp;&nbsp;In this paper, we propose "KomaFLens'', a mobile system and application built for Microsoft HoloLens, which aims to motivate long term dietary habit modification through gamification.&nbsp;&nbsp;The primary purpose of this research is to enhance the users' nutritional knowledge and to guide them to make healthier choices in their diet. Our preliminary evaluation revealed interesting points for discussion regarding the procedure for capturing food labels. Streamlining the operational method to boost tractability will improve the accuracy when recording food intakes.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {671–672},
numpages = {2},
keywords = {mixed reality, well-being, gamification},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328576,
author = {Dhawaskar Sathyanarayana, Sandesh and Lee, Jihoon and Lee, Jinsung and Im, Youngbin and Rahimzadeh, Parisa and Zhang, Xiaoxi and Hollingsworth, Max and Joe-Wong, Carlee and Grunwald, Dirk and Ha, Sangtae},
title = {CASTLE over the Air -- Distributed Scheduling for Cellular Data Transmissions (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328576},
doi = {10.1145/3307334.3328576},
abstract = {We present the demonstration of a fully distributed scheduling framework called CASTLE (Client-side Adaptive Scheduler That minimizes Load and Energy) that jointly optimizes the spectral efficiency of cellular networks and battery consumption of smart devices. To do so, we focus on scenarios when many smart devices compete for cellular resources in the same base station: spreading out transmissions over time so that only a few devices transmit at once and improves both spectral efficiency and battery consumption. To this end, we devise two novel features in CASTLE. First, we explicitly consider inter-cell interference for accurate cellular load estimation in our machine learning algorithm. Second, we propose a fully distributed scheduling algorithm that coordinates transmissions between clients based on the locally estimated load level at each client. Our formulation for minimizing battery consumption at each device leads to an optimized back off-based algorithm that fits practical environments. Our comprehensive experimental results show that CASTLE's load estimation is up to 91 % accurate, and that CASTLE achieves higher spectral efficiency with less battery consumption, compared to existing centralized scheduling algorithms as well as a distributed CSMA-like protocol. Furthermore,we develop a light-weight SDK that can expedite the deployment of CASTLE into smart devices and evaluate it in a commercial LTE network.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {673–674},
numpages = {2},
keywords = {cell load, distributed scheduling, energy saving, lte},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328577,
author = {Ramachandran, Gowri Sankar and Bogosian, Biayna and Vasudeva, Kunal and Sriramaraju, Sushanth Ikshwaku and Patel, Jay and Amidwar, Shubhesh and Malladi, Lavanya and Shylaja, Rohan Doddaiah and Kumar, Nishant Revur Bharath and Krishnamachari, Bhaskar},
title = {An Immersive Visualization of Micro-Climatic Data Using USC AiR (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328577},
doi = {10.1145/3307334.3328577},
abstract = {The air pollution level is increasing globally at an alarming rate. In the last two decades, many cities have adopted policies to control the emission of pollutants to the atmosphere as well as to promote sustainable urban developments. However, many of these initiatives have concluded that a long term success would require investing in the environmental literacy of the general population. In this demonstration paper, we present USC AiR, a mobile application that translates the air quality sensor feeds from the CCITI smart campus testbed into augmented reality visualizations for the USC community. USC AiR also allows users to report alarming air quality conditions and recommend environmental interventions such as planting trees. We believe that the integration of augmented reality for air quality monitoring enables the citizens to become more engaged with the air quality data while encouraging them to contribute to the reduction of anthropogenic air pollutants.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {675–676},
numpages = {2},
keywords = {iot, smart campus, air quality, mixed reality, smart city, augmented reality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328578,
author = {Kang, Bumsoo and Hwang, Inseok and Lee, Jinho and Lee, Seungchul and Lee, Taegyeong and Chang, Youngjae and Lee, Min Kyung},
title = {Towards Peripheral Awareness of Remote Family Member's Context Using Self-Mobile Robotic Avatars (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328578},
doi = {10.1145/3307334.3328578},
abstract = {Real-time remote interaction has become easier and richer powered by recent advances in mobile computing and communication. A number of research have been explored on enriching family interaction by augmenting an interaction channel with asynchronous communication [6] or additional sensory stimuli [5]. However, it is still far from achieving a sense of living together for family members involuntarily living apart, especially in context-aware impromptu interaction. For families living together, it is trivial to naturally perceive behavioral and situational contexts of the other and initiate a relevant interaction intuitively. For example, a wife starts a casual chat with asking her husband what he is going to cook when she sees him going to the kitchen or hears a simmering sound.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {677–678},
numpages = {2},
keywords = {context-aware impromptu interaction, robotic avatar, peripheral awareness},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328579,
author = {Park, Juyoung and Im, Kiyoung and Lee, Jung Hee},
title = {PotholeEye -- How Can We Effectively Maintain the Pavement Distress? (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328579},
doi = {10.1145/3307334.3328579},
abstract = {We propose a mobile system, called PotholeEye, for automatically monitoring the surface of a roadway and providing real-time analysis of images, with the specific goal of detecting the pavement distress. PotholeEye pre-processes the images, extracts features, and classifies the distress into a variety of types, while the road manager is driving. We have tested PotholeEye on real highway involving real settings, a camera, a mini computer, a GPS receiver, and so on, and have shown how we can effectively maintain the pavement distress.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {679–680},
numpages = {2},
keywords = {image processing, pavement distress, convolution neural network},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328580,
author = {Jeon, Sanghoon and Lee, Yang-Soo and Son, Sang Hyuk},
title = {Automatic Assessment Framework for Range of Motion Test Using Wearable Device and Smartphone (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328580},
doi = {10.1145/3307334.3328580},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {681–682},
numpages = {2},
keywords = {goniometer, automatic assessment framework, range of motion test},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328581,
author = {Soleiman, Andreas and Varshney, Ambuj},
title = {Backscatter-Enabled Polymorphic Light Sensors (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328581},
doi = {10.1145/3307334.3328581},
abstract = {Light as a medium for sensing and communication enables new scenarios, such as controlling devices with gestures, or communication for Internet of Things~(IoT) devices. However, a limitation of existing systems is that they often sense only a narrow part of the light spectrum. We argue that the ability to sense a broad light spectrum significantly enhances ability of such systems expanding possible application scenarios. We demonstrate our work in progress to develop the concept of polymorphic light sensing~(PLS). PLS sensor morphs itself according to applications requirements, to track desired parts of the light spectrum (colours, infrared, and ultraviolet light). We couple the PLS sensor with ultra-low power backscatter mechanism, and demonstrate this enables us to sense and communicate the broad spectrum, while operating battery-free.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {683–684},
numpages = {2},
keywords = {polymorphic sensing, light sensing, battery-free, backscatter communication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328582,
author = {Pham, Nhat and Kim, Taeho and Thayer, Frederick M. and Nguyen, Anh and Vu, Tam},
title = {Earable -- An Ear-Worn Biosignal Sensing Platform for Cognitive State Monitoring and Human-Computer Interaction (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328582},
doi = {10.1145/3307334.3328582},
abstract = {Cognitive state monitoring is crucial for neurological disorders such as epilepsy, narcolepsy, insomnia, and many other human health concerns. The capability to continuously monitor an individual wearing the device and accurately provide early warnings of seizures or narcolepsy sleep attacks would be game-changing for these disorders. Beyond human health, complete hand-free/voice-free human-computer interaction is desirable for privacy-sensitive use cases or people with disabilities. To achieve this goal, we propose Earable, an ear-worn biosensing platform for cognitive state quantification and human-computer interaction. Earable can capture biosignal including brain waves activities, eyes movements, and facial muscle contractions from the back of the ears. Its form factor is convenient to use in everyday life. In this demo, we show two use cases for our Earable platform. First, as an example of cognitive state monitoring, our system plays relaxing music and dims the light when the user is trying to relax or sleep by detecting alpha and beta waves generated by the brain. Second, as an example of human-computer interaction, our system controls a drone with eye movements and facial muscle activity.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {685–686},
numpages = {2},
keywords = {cognitive state monitoring, ear-worn biosensing, human-computer interaction, wearable computing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328583,
author = {Balaji, Ananta Narayanan and Yuan, Chen and Wang, Bo and Peh, Li-Shiuan and Shao, Huilin},
title = {PH Watch - Leveraging Pulse Oximeters in Existing Wearables for Reusable, Real-Time Monitoring of PH in Sweat (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328583},
doi = {10.1145/3307334.3328583},
abstract = {Most present day fitness trackers and smart watches measure critical health indicators such as heart rate, SpO2 concentration, sleep cycle etc. but they fail in their ability to track health indicators at the molecular level. This has attracted rapid research in the development of chemical sensors which can non-invasively measure analytes available in raw biofluids such as sweat, tears and urine. Of all the available raw bio-fluids, sweat can be obtained non-intrusively and readily, and thus is the most suitable choice for continuous real-time monitoring of indicators at a molecular level.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {687–688},
numpages = {2},
keywords = {wearables, ph sensing, sweat sensor, iot},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328584,
author = {Ji, Youngmin and Ok, Kisu and Kwon, Dongwoo},
title = {The Indoor Environment Monitoring System for Intelligent Buildings Using Wifi Mesh Based Internet of Things (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328584},
doi = {10.1145/3307334.3328584},
abstract = {Retrofit could be still expensive solution to existing building. However, with IoT(Internet of Things) environment sensors, it is possible to build a powerful intelligent building monitoring system with relatively low costs. The IoT environment sensor can analyze the IAQ(Indoor Air Quality), occupancy, and comfort level of the individual space by integrating temperature, humidity, carbon dioxide, sound, illuminance, organic compound, human body detection and IR sensor in the individual space of the building. In addition, because it supports Wifi mesh network, it can be easily installed without performing construction for retrofit in existing building, and real time monitoring can be performed. In this paper, we introduce the result of applied the IoT environment sensors to three buildings and visualization interface based on the result of analysis and real environment sensing},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {689–690},
numpages = {2},
keywords = {occupants detection, internet of things, indoor comfort, wifi mesh network, indoor air quality, building application},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328586,
author = {Mondal, Jayeeta and Dey, Swarnava and Mukherjee, Arijit and Dutta, Jeet and Pal, Arpan and P, Balamurali},
title = {Edge Acceleration of Deep Neural Networks (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328586},
doi = {10.1145/3307334.3328586},
abstract = {Running deep learning algorithms at the edge is a necessity in many industrial use-cases, especially in applications that use robots and drones in disaster recovery, surveillance, oil &amp; gas operations etc. Current state of the art deep learning algorithms are extremely efficient in analysing image, audio, video and other time-series signals. However, their performance degrades considerably on constrained edge devices. In this demo, we show how standard pretrained CNN (Convolutional Neural Network) models can be partitioned for efficient parallel execution between constrained devices and also achieve real-time response.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {691–692},
numpages = {2},
keywords = {network, acceleration, dnn, computing, latency, edge, partitioning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328587,
author = {Choi, Jaewon and Ko, JeongGil},
title = {RemoteGL - Towards Low-Latency Interactive Cloud Graphics Experience for Mobile Devices (Demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328587},
doi = {10.1145/3307334.3328587},
abstract = {can enable futuristic applications including many Virtual Reality, Augmented Reality, and cloud gaming applications on resource constraint mobile devices. While RGR requires a high-level of networking bandwidth for seamless servicing, emerging high-speed communication technologies such as IEEE 802.11ax and millimeter wavebased communications are expected to provide high-bandwidth and low-latency networking performance. Thus, they can potentially resolve the transmission latency constraint, which is one of the most tricky obstacles to resolve prior to applying various RGR applications in the real world.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {693–694},
numpages = {2},
keywords = {remote graphics rendering, low-latency},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328589,
author = {Ananthanarayanan, Ganesh and Bahl, Victor and Cox, Landon and Crown, Alex and Nogbahi, Shadi and Shu, Yuanchao},
title = {Video Analytics - Killer App for Edge Computing},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328589},
doi = {10.1145/3307334.3328589},
abstract = {The world is witnessing an unprecedented increase in camera deployment. The USA and UK, for instance, have one camera for every 8 people. Video analytics from these cameras are becoming more and more pervasive, exerting important functions on a wide range of verticals including manufacturing, transportation, and retails. While vision techniques have seen considerable advancement, they have come at the expense of compute and network cost.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {695–696},
numpages = {2},
keywords = {camera, cloud, dnn, video analytics, edge computing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328590,
author = {Lan, Kun-Chan and Li, Guan-Sheng and Zhang, Jun-Xiang},
title = {Robot-Assisted Acupuncture (Video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328590},
doi = {10.1145/3307334.3328590},
abstract = {An acupuncture points localization method is implemented on an Android platform. Such a system can be used to locate the relevant acupuncture point and/or drive a robot arm for the purpose of symptom relief (e.g. through acupressure).},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {697–698},
numpages = {2},
keywords = {3d morphable model, acupuncture point estimation, augmented reality, robot arm},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328591,
author = {Ko, Ju-Chun},
title = {Crypto Wallet Working on Low-Cost 4G LTE Mobile Phone (Video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328591},
doi = {10.1145/3307334.3328591},
abstract = {In this paper, we describe a simple and light way of using 4G LTE low-cost phone as blockchain cryptocurrencies wallet on-the-go. The main purpose of this project is to make general mobile phone user could easily use Crypto Wallet " a crypto currency wallet connected to the blockchain without installing an App, to get benefit from decentralized financial services such as e-commerce, Peer to Peer financial services etc. In this research, we have implemented a full-functional e-commerce Web App through WordPress combining with WooCommerce open-source package, with additional Crypto Wallet plugin compose by PHP installed, which allows user to create crypto wallet and make transaction on a very low-cost phone such like Nokia 8810 4GLTE, worth only $80. With the possibility of using low-cost phone to do Blockchain and cryptocurrency related operations, it may lead us to a more distributed commerce, and equally traded world. YouTube link: https://youtu.be/Dqmh-OgbvM8},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {699–700},
numpages = {2},
keywords = {crypto wallet, mobile web applications, dapp, blockchain},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328592,
author = {Ramachandran, Gowri Sankar and Ji, Xiang and Navaney, Pavas and Zheng, Licheng and Martinez, Martin and Krishnamachari, Bhaskar},
title = {Micropayments for Trusted Vehicular Services Using MOTIVE (Video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328592},
doi = {10.1145/3307334.3328592},
abstract = {The connected and autonomous vehicles are expected to rely heavily on connectivity to exchange data and computation services with other vehicles and remote infrastructure including roadside units and other edge infrastructure to increase their immediate view, which leads to greater safety, coordination and more comfortable experience for their human occupants. In order for vehicles to obtain data, compute and other services from other vehicles or road-side infrastructure, it is important to be able to make micropayments for those services and for the services to run seamlessly despite the challenges posed by mobility and ephemeral interactions with a dynamic set of neighboring devices. We present MOTIVE, a trusted and decentralized framework that allows vehicles to make peer-to-peer micropayments for data, compute and other services obtained from other vehicles or road-side infrastructure within radio range. The framework utilizes distributed ledger technologies including smart contracts to enable autonomous operation and trusted interactions between vehicles and nearby entities.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {701–702},
numpages = {2},
keywords = {micropayments, edge computing, v2x, blockchain, connected and autonomous vehicles},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328593,
author = {Gong, Taesik and Cho, Hyunsung and Lee, Bowon and Lee, Sung-Ju},
title = {Real-Time Object Identification with a Smartphone Knock (Video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328593},
doi = {10.1145/3307334.3328593},
abstract = {We propose Knocker, a real-time object identification technique with smartphones. Knocker leverages unique impulse signals that are generated by knocking on an object with a smartphone. Knocker does not require any special augmentation for both smartphones and objects.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {703–704},
numpages = {2},
keywords = {smartphone sensing, interaction with objects, object identification, machine learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328594,
author = {Hu, Jinhan and Shearer, Alexander and Rajagopalan, Saranya and LiKamWa, Robert},
title = {Banner -- An Image Sensor Reconfiguration Framework for Seamless Resolution-Based Tradeoffs (Video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328594},
doi = {10.1145/3307334.3328594},
abstract = {Mobile vision systems would benefit from the ability to situationally sacrifice image resolution to save system energy when imaging detail is unnecessary. Unfortunately, any change in sensor resolution leads to a substantial pause in frame delivery -- as much as 280 ms. Frame delivery is bottlenecked by a sequence of reconfiguration procedures and memory management in current operating systems before it resumes at the new resolution. This latency from reconfiguration impedes the adoption of otherwise beneficial resolution-energy tradeoff mechanisms. We propose Banner as a media framework that provides a rapid sensor resolution reconfiguration service as a modification to common media frameworks, e.g., V4L2. Banner completely eliminates the frame-to-frame reconfiguration latency (226 ms to 33 ms), i.e., removing the frame drop during sensor resolution reconfiguration. Banner also halves the end-to-end resolution reconfiguration latency (226 ms to 105 ms). This enables a more than 49% reduction of system power consumption by allowing continuous vision applications to reconfigure the sensor resolution to 480p compared with downsampling from 1080p to 480p, as measured in a cloud-based offloading workload running on a Jetson TX2 board. As a result, Banner unlocks unprecedented capabilities for mobile vision applications to dynamically reconfigure sensor resolutions to balance the energy efficiency and task accuracy tradeoff.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {705–706},
numpages = {2},
keywords = {operating systems, device drivers, energy efficiency, resolution-based tradeoff, efficient visual computing, reconfiguration},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3332163,
author = {AlDuaij, Naser and Van't Hof, Alexander and Nieh, Jason},
title = {Heterogeneous Multi-Mobile Computing (Video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3332163},
doi = {10.1145/3307334.3332163},
abstract = {As smartphones and tablets proliferate, there is a growing demand for multi-mobile computing [1, 2], the ability to combine multiple commodity mobile systems into more capable ones, including using multiple hardware devices such as cameras, displays, speakers, microphones, sensors, GPS, and input. However, the tremendous device, hardware, and software heterogeneity of mobile systems makes this difficult. In this demo, we present M2, a system for multi-mobile computing that enables existing unmodified mobile apps to make use of new ways of sharing and combining multiple devices. M2 introduces a new data-centric approach that leverages higher-level device abstractions and encoding/decoding hardware to efficiently share device data as opposed to low-level device-specific APIs.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {707},
numpages = {1},
keywords = {android, mobile computing, operating systems, ios, distributed computing, mobile devices, remote display},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3307334.3328595,
author = {Park, KyuHwon and Jeong, Young-Seob},
title = {Indoor Dialog Agent in Mixed Reality (Video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328595},
doi = {10.1145/3307334.3328595},
abstract = {We aimed at implementing an indoor dialog agent, namely PhoenixBot, working in a mixed-reality environment. The agent occupies a certain position in a real-world space, and interacts with other nearby human.We developed a server that maintains information of agents and smartphone users, where the information includes current indoor position and direction. We also developed an Android application as a client, which collects real-time data from various sensors such as gyroscope, accelerometer, step detector, WiFi, magnetic field, and gravity sensor. The step detector values and WiFi signals are used to estimate the current location of the user, and the other remaining sensors are used to compute the user direction. The client application displays the real-world scene covered with some virtual objects (e.g., agent, board), as depicted in Fig. 1, where the cartoon character at the center is the dialog agent. In order to compute the right position to display the components, the client keeps consistent information of the virtual objects with the server. That is, if a user moves to other position, then it will be reported to the server and will be disclosed to the other agents and users. The dialog agent works in the way similar to other dialog agents, as it has a pipeline of modules such as Natural Language Understanding (NLU), Dialog Management (DM), and Natural Language Generation (NLG). The agent currently supports four domains: weather, campus, transport, and bible. The agent speaks only Korean for now, but will be portable to other langauges if a dataset for the target language is prepared. You can see the video clip at https://youtu.be/U2FA-XxVPvM},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {708–709},
numpages = {2},
keywords = {dialog agent, mobile phone, mixed reality, chatbot},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}

@inproceedings{10.1145/3210240.3210334,
author = {Lentz, Matthew and Sen, Rijurekha and Druschel, Peter and Bhattacharjee, Bobby},
title = {SeCloak: ARM Trustzone-Based Mobile Peripheral Control},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210334},
doi = {10.1145/3210240.3210334},
abstract = {Reliable on-off control of peripherals on smart devices is a key to security and privacy in many scenarios. Journalists want to reliably turn off radios to protect their sources during investigative reporting. Users wish to ensure cameras and microphones are reliably off during private meetings. In this paper, we present SeCloak, an ARM TrustZone-based solution that ensures reliable on-off control of peripherals even when the platform software is compromised. We design a secure kernel that co-exists with software running on mobile devices (e.g., Android and Linux) without requiring any code modifications. An Android prototype demonstrates that mobile peripherals like radios, cameras, and microphones can be controlled reliably with a very small trusted computing base and with minimal performance overhead.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {1–13},
numpages = {13},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210338,
author = {Ying, Kailiang and Ahlawat, Amit and Alsharifi, Bilal and Jiang, Yuexin and Thavai, Priyank and Du, Wenliang},
title = {TruZ-Droid: Integrating TrustZone with Mobile Operating System},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210338},
doi = {10.1145/3210240.3210338},
abstract = {Mobile devices today provide a hardware-protected mode called Trusted Execution Environment (TEE) to help protect users from a compromised OS and hypervisor. Today TEE can only be leveraged either by vendor apps or by developers who work with the vendor. Since vendors consider third-party app code untrusted inside the TEE, to allow an app to leverage TEE, app developers have to write the app code in a tailored way to work with the vendor's SDK. We proposed a novel design to integrate TEE with mobile OS to allow any app to leverage the TEE. Our design incorporates TEE support at the OS level, allowing apps to leverage the TEE without adding app-specific code into the TEE, and while using existing interface to interact with the mobile OS. We implemented our design, called TruZ-Droid, by integrating TrustZone TEE with the Android OS. TruZ-Droid allows apps to leverage the TEE to protect the following: (i) user's secret input and confirmation, and (ii) sending of user's secrets to the authorized server. We built a prototype using the TrustZone-enabled HiKey board to evaluate our design. We demonstrated TruZ-Droid's effectiveness by adding new security features to existing apps to protect user's sensitive information and attest user's confirmation. TruZ-Droid's real-world use case evaluation shows that apps can leverage TrustZone while using existing OS APIs. Our usability study proves that users can correctly interact with TruZ-Droid to protect their security sensitive activities and data.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {14–27},
numpages = {14},
keywords = {TrustZone, Android},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210330,
author = {Li, Wenhao and Luo, Shiyu and Sun, Zhichuang and Xia, Yubin and Lu, Long and Chen, Haibo and Zang, Binyu and Guan, Haibing},
title = {VButton: Practical Attestation of User-Driven Operations in Mobile Apps},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210330},
doi = {10.1145/3210240.3210330},
abstract = {More and more malicious apps and mobile rootkits are found to perform sensitive operations on behalf of legitimate users without their awareness. Malware does so by either forging user inputs or tricking users into making unintended requests to online service providers. Such malware is hard to detect and generates large revenues for cybercriminals, which is often used for committing ad/click frauds, faking reviews/ratings, promoting people or business on social networks, etc.We find that this class of malware is possible due to the lack of practical and robust means for service providers to verify the authenticity of user-driven operations (i.e., operations supposed to be performed, or explicitly confirmed, by a user). We design and build the VButton system to fill this void. Our system introduces a class of attestation-enabled app UI widgets (called VButton UI). Developers can easily integrate VButton UI in their apps to allow service providers to verify that a user-driven operation triggered by a VButton UI is indeed initiated and intended by a real user. Our system contains an on-device Manager, and a server-side Verifier. Leveraging ARM TrustZone, our system can attest operation authenticity even in the presence of a compromised OS. We have implemented the VButton system on an ARM development board as well as a commercial off-the-shelf smartphone. The evaluation results show that the system incurs negligible overhead.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {28–40},
numpages = {13},
keywords = {TrustZone, Attestation, Mobile platform, User-driven security},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210317,
author = {Khan, Hassan and Hengartner, Urs and Vogel, Daniel},
title = {Augmented Reality-Based Mimicry Attacks on Behaviour-Based Smartphone Authentication},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210317},
doi = {10.1145/3210240.3210317},
abstract = {We develop an augmented reality-based app that resides on the attacker's smartphone and leverages computer vision and raw input data to provide real-time mimicry attack guidance on the victim's phone. Our approach does not require tampering or installing software on the victim's device, or specialized hardware. The app is demonstrated by attacking keystroke dynamics, a method leveraging the unique typing behaviour of users to authenticate them on a smartphone, which was previously thought to be hard to mimic. In addition, we propose a low-tech AR-like audiovisual method based on spatial pointers on a transparent film and audio cues. We conduct experiments with 31 participants and mount over 400 attacks to show that our methods enable attackers to successfully bypass keystroke dynamics for 87% of the attacks after an average mimicry training of four minutes. Our AR-based method can be extended to attack other input behaviour-based biometrics. While the particular attack we describe is relatively narrow, it is a good example of using AR guidance to enable successful mimicry of user behaviour---an approach of increasing concern as AR functionality becomes more commonplace.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {41–53},
numpages = {13},
keywords = {Authentication, Behavioural biometrics, Mimicry attacks, Augmented reality},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210348,
author = {Kang, Bumsoo and Hwang, Inseok and Lee, Jinho and Lee, Seungchul and Lee, Taegyeong and Chang, Youngjae and Lee, Min Kyung},
title = {My Being to Your Place, Your Being to My Place: Co-Present Robotic Avatars Create Illusion of Living Together},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210348},
doi = {10.1145/3210240.3210348},
abstract = {People in work-separated families have been heavily relying on cutting-edge face-to-face communication services. Despite their ease of use and ubiquitous availability, experiences in living together are still far incomparable to those through remote face-to-face communication. We envision that enabling a remote person to be spatially superposed in one's living space would be a breakthrough to catalyze pseudo living-together interactivity. We propose HomeMeld, a zero-hassle self-mobile robotic system serving as a co-present avatar to create a persistent illusion of living together for those who are involuntarily living apart. The key challenges are 1) continuous spatial mapping between two heterogeneous floor plans and 2) navigating the robotic avatar to reflect the other's presence in real time under the limited maneuverability of the robot. We devise a notion of functionally equivalent location and orientation to translate a person's presence into another in a heterogeneous floor plan. We also develop predictive path warping to seamlessly synchronize the presence of the other. We conducted extensive experiments and deployment studies with real participants.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {54–67},
numpages = {14},
keywords = {co-presesnce, Robotic avatar, telepresence, co-located interaction},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210313,
author = {Liu, Luyang and Zhong, Ruiguang and Zhang, Wuyang and Liu, Yunxin and Zhang, Jiansong and Zhang, Lintao and Gruteser, Marco},
title = {Cutting the Cord: Designing a High-Quality Untethered VR System with Low Latency Remote Rendering},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210313},
doi = {10.1145/3210240.3210313},
abstract = {This paper introduces an end-to-end untethered VR system design and open platform that can meet virtual reality latency and quality requirements at 4K resolution over a wireless link. High-quality VR systems generate graphics data at a data rate much higher than those supported by existing wireless-communication products such as Wi-Fi and 60GHz wireless communication. The necessary image encoding, makes it challenging to maintain the stringent VR latency requirements. To achieve the required latency, our system employs a Parallel Rendering and Streaming mechanism to reduce the add-on streaming latency, by pipelining the rendering, encoding, transmission and decoding procedures. Furthermore, we introduce a Remote VSync Driven Rendering technique to minimize display latency. To evaluate the system, we implement an end-to-end remote rendering platform on commodity hardware over a 60Ghz wireless network. Results show that the system can support current 2160x1200 VR resolution at 90Hz with less than 16ms end-to-end latency, and 4K resolution with 20ms latency, while keeping a visually lossless image quality to the user.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {68–80},
numpages = {13},
keywords = {Virtual Reality, High-quality, 60GHz, Untethered, Low latency},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210319,
author = {Qiu, Hang and Ahmad, Fawad and Bai, Fan and Gruteser, Marco and Govindan, Ramesh},
title = {AVR: Augmented Vehicular Reality},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210319},
doi = {10.1145/3210240.3210319},
abstract = {Autonomous vehicle prototypes today come with line-of-sight depth perception sensors like 3D cameras. These 3D sensors are used for improving vehicular safety in autonomous driving, but have fundamentally limited visibility due to occlusions, sensing range, and extreme weather and lighting conditions. To improve visibility and performance, not just for autonomous vehicles but for other Advanced Driving Assistance Systems (ADAS), we explore a capability called Augmented Vehicular Reality (AVR). AVR broadens the vehicle's visual horizon by enabling it to wirelessly share visual information with other nearby vehicles, but requires the design of novel relative positioning techniques, new perspective transformation methods, approaches to isolate and predict the motion of dynamic objects in order to hide latency, and adaptive transmission strategies to cope with wireless bandwidth variability. We show that AVR is feasible using off-the-shelf wireless technologies, and it can qualitatively change the decisions made by autonomous vehicle path planning algorithms. Our AVR prototype achieves positioning accuracies that are within a few percent of car lengths and lane widths, and is optimized to process frames at 30fps.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {81–95},
numpages = {15},
keywords = {Extended Vision, Autonomous Cars, Collaborative Sensing},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210339,
author = {Li, Toby Jia-Jun and Riva, Oriana},
title = {Kite: Building Conversational Bots from Mobile Apps},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210339},
doi = {10.1145/3210240.3210339},
abstract = {Task-oriented chatbots allow users to carry out tasks (e.g., ordering a pizza) using natural language conversation. The widely-used slot-filling approach for building bots of this type requires significant hand-coding, which hinders scalability. Recently, neural network models have been shown to be capable of generating natural "chitchat" conversations, but it is unclear whether they will ever work for task modeling. Kite is a practical system for bootstrapping task-oriented bots, leveraging both approaches above. Kite's key insight is that while bots encapsulate the logic of user tasks into conversational forms, existing apps encapsulate the logic of user tasks into graphical user interfaces. A developer demonstrates a task using a relevant app, and from the collected interaction traces Kite automatically derives a task model, a graph of actions and associated inputs representing possible task execution paths. A task model represents the logical backbone of a bot, on which Kite layers a question-answer interface generated using a hybrid rule-based and neural network approach. Using Kite, developers can automatically generate bot templates for many different tasks. In our evaluation, it extracted accurate task models from 25 popular Android apps spanning 15 tasks. Appropriate questions and high-quality answers were also generated. Our developer study suggests that developers, even without any bot developing experience, can successfully generate bot templates using Kite.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {96–109},
numpages = {14},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210327,
author = {Farooq, Umar and Zhao, Zhijia},
title = {RuntimeDroid: Restarting-Free Runtime Change Handling for Android Apps},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210327},
doi = {10.1145/3210240.3210327},
abstract = {Portable devices, like smartphones and tablets, are often subject to runtime configuration changes, such as screen orientation changes, screen resizing, keyboard attachments, and language switching. When handled improperly, such simple changes can cause serious runtime issues, from data loss to app crashes.This work presents, to our best knowledge, the first formative study on runtime change handling with 3,567 Android apps. The study not only reveals the current landscape of runtime change handling, but also points out a common cause of various runtime change issues -- activity restarting. On one hand, the restarting facilitates the resource reloading for the new configuration. On the other hand, it may slow down the app, and more critically, it requires developers to manually preserve a set of data in order to recover the user interaction state after restarting.Based on the findings of this study, this work further introduces a re starting-free runtime change handling solution -- RuntimeDroid. RuntimeDroid can completely avoid the activity restarting, at the same time, ensure proper resource updating with user input data preserved. These are achieved with two key components: an online resource loading module, called HotR and a novel UI components migration technique. The former enables proper resources loading while the activity is still live. The latter ensures that prior user changes are carefully preserved during runtime changes.For practical use, this work proposes two implementations of RuntimeDroid: an IDE plugin and an auto-patching tool. The former allows developers to easily adopt restarting-free runtime change handling during the app developing; The latter can patch released app packages without source code. Finally, evaluation with a set of 72 apps shows that RuntimeDroid successfully fixed all the 197 reported runtime change issues, meanwhile reducing the runtime change handling delays by 9.5X on average.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {110–122},
numpages = {13},
keywords = {Runtime Configuration Change, Event Handling, Android},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210331,
author = {Kim, Wonjung and Choo, Kenny Tsu Wei and Lee, Youngki and Misra, Archan and Balan, Rajesh Krishna},
title = {Empath-D: VR-Based Empathetic App Design for Accessibility},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210331},
doi = {10.1145/3210240.3210331},
abstract = {With app-based interaction increasingly permeating all aspects of daily living, it is essential to ensure that apps are designed to be inclusive and are usable by a wider audience such as the elderly, with various impairments (e.g., visual, audio and motor). We propose Empath-D, a system that fosters empathetic design, by allowing app designers, in-situ, to rapidly evaluate the usability of their apps, from the perspective of impaired users. To provide a truly authentic experience, Empath-D carefully orchestrates the interaction between a smartphone and a VR device, allowing the user to experience simulated impairments in a virtual world while interacting naturally with the app, using a real smartphone. By carefully orchestrating the VR-smartphone interaction, Empath-D tackles challenges such as preserving low-latency app interaction, accurate visualization of hand movement and low-overhead perturbation of I/O streams. Experimental results show that user interaction with Empath-D is comparable (both in accuracy and user perception) to real-world app usage, and that it can simulate impairment effects as effectively as a custom hardware simulator.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {123–135},
numpages = {13},
keywords = {empathetic design, multi-device, mobile design, accessibility, distributed user interfaces, virtual reality},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210324,
author = {Erd\'{e}lyi, Viktor and Le, Trung-Kien and Bhattacharjee, Bobby and Druschel, Peter and Ono, Nobutaka},
title = {Sonoloc: Scalable Positioning of Commodity Mobile Devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210324},
doi = {10.1145/3210240.3210324},
abstract = {We present Sonoloc, a mobile app and system that allows a set of co-located commodity smart devices to determine their relative positions without local infrastructure. Sonoloc enables users to address each other based on their relative positions at events like meetings, talks, or conferences. This capability can, for instance, aid spontaneous communication among users based on their relative position (e.g., in a given section of a room, at the same table, or in a given seat), facilitate interaction between speaker and audience in a lecture hall, and enable the distribution of materials, crowdsensing, and feedback collection based on users' location. Sonoloc can position any number of devices within acoustic range with a constant number of chirps emitted by a self-organized subset of devices. Our experimental evaluation shows that the system can locate up to hundreds of devices with an accuracy of tens of centimeters using up to 15 audio chirps emitted by dynamically selected devices, in actual rooms and despite substantial background noise.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {136–149},
numpages = {14},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210316,
author = {Chen, Kongyang and Tan, Guang},
title = {BikeGPS: Accurate Localization of Shared Bikes in Street Canyons via Low-Level GPS Cooperation},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210316},
doi = {10.1145/3210240.3210316},
abstract = {The past few years have seen a surge of stationless bike sharing services in many modern cities. The service allows the bikes to be dropped off freely, and to be found through GPS localization. For maximum convenience, the bikes are often parked in close proximity to the buildings, where GPS may perform poorly, making bike search a challenging task. This paper proposes a novel approach to addressing this problem. Inspired by multi-antenna systems, our method tries to collect GPS signals from multiple distributed bikes, by organizing a group of bikes into a network, called the BikeGPS. Formed by pedestrian users who opportunistically measure interbike distance via radio sensing and step tracking, the generated network permits one to map all the nodes' satellite range measurements into a single lead node's view. By considering both signal and geometry properties of satellite raw measurements, and using an asynchronous coarse time navigation algorithm, the lead node can accurately derive the locations of all the network nodes. Real-world experiments show that BikeGPS significantly improves the localization performance, in terms of both accuracy and solution availability, compared with the naive GPS approach and a high-level cooperative localization method.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {150–162},
numpages = {13},
keywords = {Localization, Shared Bikes, Street Canyons, GPS},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210343,
author = {Liu, Xiaochen and Nath, Suman and Govindan, Ramesh},
title = {Gnome: A Practical Approach to NLOS Mitigation for GPS Positioning in Smartphones},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210343},
doi = {10.1145/3210240.3210343},
abstract = {Accurate positioning in urban areas is important for personal navigation, geolocation apps, and ride-sharing. Smartphones localize themselves using GPS position estimates, and augment these with a variety of techniques including dead reckoning, map matching, and WiFi localization. However, GPS signals suffer significant impairment in urban canyons because of limited line-of-sight to satellites and signal reflections. In this paper, we focus on scalable and deployable techniques to reduce the impact of one specific impairment: reflected GPS signals from non-line-of-sight (NLOS) satellites. Specifically, we show how, using publicly available street-level imagery and off-the-shelf computer vision techniques, we can estimate the path inflation incurred by (the extra distance traveled by) a reflected signal from a satellite. Using these path inflation estimates we develop techniques to estimate the most likely actual position given a set of satellite readings at some position. Finally, we develop optimizations for fast position estimation on modern smartphones. Using extensive experiments in the downtown area of several large cities, we find that our techniques can reduce positioning error by up to 55% on average.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {163–177},
numpages = {15},
keywords = {Localization, GPS, NLOS Mitigation, Mobile Computing},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210318,
author = {Yin, Zhimeng and Li, Zhijun and Kim, Song Min and He, Tian},
title = {Explicit Channel Coordination via Cross-Technology Communication},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210318},
doi = {10.1145/3210240.3210318},
abstract = {Under significant coexistence in the ISM band, the impact of cross-technology interference (CTI) has become a major threat to low-power IoT. This paper presents ECC that uniquely enables explicit channel coordination among heterogeneities via cross-technology communication (CTC) introduced in the latest studies, while maintaining full compatibility to commodity devices. Unlike any implicit coordination designs adopting statistical models to probabilistically predict white spaces, ECC generates the white space using WiFi CTS, which is then explicitly notified to ZigBee through CTC for immediate use. Technical highlight of ECC lies in ensuring ZigBee communication under CTI, without disrupting WiFi operation. This is effectively achieved by the dynamic adjustment of CTS duration with respect to traffic amount and spectrum availability, which essentially enables ECC to be generally applied to various scenarios without prior knowledge. Lastly, ECC significantly reduces delay and energy in low duty cycled ZigBee, by waking them up upon channel availability (via CTC). We evaluate ECC on commercial platforms: Atheros AR2425 WiFi card and TelosB motes. Experiment results show that ECC achieves 1.8x ZigBee packet reception ratio, and cuts down delay and energy by 98.6% and 51% under the low duty cycle.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {178–190},
numpages = {13},
keywords = {Internet of Things, ZigBee, WiFi},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210329,
author = {Zhao, Jia and Gong, Wei and Liu, Jiangchuan},
title = {Spatial Stream Backscatter Using Commodity WiFi},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210329},
doi = {10.1145/3210240.3210329},
abstract = {Backscatter WiFi offers a novel low-cost and low-energy solution for RFID tags to communicate with existing WiFi devices. State-of-the-art backscatter WiFi solutions have seldom explored advanced features in the latest WiFi standards, in particular, spatial multiplexing, which has been the cornerstone for 802.11n and beyond. In this paper, we present MOXcatter, a WiFi backscatter communication system that works with spatial streams using commodity radios, while keeping the ongoing data communication unaffected. In MOXcatter, a backscatter tag can embed its sensing data on ambient spatial-stream packets, and both the sensing data and the original packets can be decoded by commodity WiFi devices. We have built a MOXcatter prototype with FPGAs and commodity WiFi devices. The experiments show that MOXcatter achieves up to 50 Kbps throughput for a single stream and up to 1 Kbps for double streams with a communication range (tag-to-RX) up to 14 m. We discuss the tradeoffs therein and possible enhancements, and also showcase the applicability of our design through a sensor communication system.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {191–203},
numpages = {13},
keywords = {WiFi Backscatter, Internet of Things, Spatial Stream},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210346,
author = {Li, Yan and Chi, Zicheng and Liu, Xin and Zhu, Ting},
title = {Chiron: Concurrent High Throughput Communication for IoT Devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210346},
doi = {10.1145/3210240.3210346},
abstract = {The exponentially increasing number of heterogeneous Internet of Things (IoT) devices motivate us to explore more efficient and higher throughput communication, especially at the bottleneck (i.e., edge) of the IoT networks. Our work, named Chiron, opens a promising direction for Physical (PHY) layer concurrent high throughput communication to heterogeneous IoT devices (e.g., wider-band WiFi and narrower-band ZigBee). Specifically, at the PHY layer, Chiron enables concurrently transmitting (or receiving) 1 stream of WiFi data and up to 4 streams of ZigBee data to (or from) commodity WiFi and ZigBee devices as if there is no interference between these simultaneous connections. We extensively evaluate our system under different real-world settings. Results show that Chiron's concurrent WiFi and ZigBee communication can achieve similar throughput as the sole WiFi or ZigBee communication. Chiron's spectrum utilization is more than 16 times better than the traditional gateway.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {204–216},
numpages = {13},
keywords = {Internet of things (IoT), Concurrent Communication, Wireless},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210341,
author = {Das, Tanmoy and Chen, Lu and Kundu, Rupam and Bakshi, Arjun and Sinha, Prasun and Srinivasan, Kannan and Bansal, Gaurav and Shimizu, Takayuki},
title = {CoReCast: Collision Resilient Broadcasting in Vehicular Networks},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210341},
doi = {10.1145/3210240.3210341},
abstract = {Reliable and timely delivery of periodic V2V (vehicle-to-vehicle) broadcast messages is essential for realizing the benefits of connected vehicles. Existing MAC protocols for ad hoc networks fall short of meeting these requirements. In this paper, we present, CoReCast, the first collision embracing protocol for vehicular networks. CoReCast provides high reliability and low delay by leveraging two unique opportunities: no strict constraint on energy consumption, and availability of GPS clocks to achieve near-perfect time and frequency synchronization.Due to low coherence time, the channel changes rapidly in vehicular networks. CoReCast embraces packet collisions and takes advantage of the channel dynamics to decode collided packets. The design of CoReCast is based on a preamble detection scheme that estimates channels from multiple transmitters without any prior information about them. The proposed scheme reduces the space and time requirement exponentially than the existing schemes. The system is evaluated through experiments with USRP N210 and GPS devices placed in vehicles driven on roads in different environments as well as using trace-driven simulations. It provides 15x and 2x lower delay than 802.11p and OCP (Omniscient Clustering Protocol), respectively. Reliability of CoReCast is 8x and 2x better than 802.11p and OCP, respectively.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {217–229},
numpages = {13},
keywords = {CoReCast, Vehicular Networks, Preamble detection},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210321,
author = {Razeen, Ali and Lebeck, Alvin R. and Liu, David H. and Meijer, Alexander and Pistol, Valentin and Cox, Landon P.},
title = {SandTrap: Tracking Information Flows On Demand with Parallel Permissions},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210321},
doi = {10.1145/3210240.3210321},
abstract = {The most promising way to improve the performance of dynamic information-flow tracking (DIFT) for machine code is to only track instructions when they process tainted data. Unfortunately, prior approaches to on-demand DIFT are a poor match for modern mobile platforms that rely heavily on parallelism to provide good interactivity in the face of computationally intensive tasks like image processing. The main shortcoming of these prior efforts is that they cannot support an arbitrary mix of parallel threads due to the limitations of page protections.In this paper, we identify parallel permissions as a key requirement for multithreaded, on-demand native DIFT, and we describe the design and implementation of a system called SandTrap that embodies this approach. Using our prototype implementation, we demonstrate that SandTrap's native DIFT overhead is proportional to the amount of tainted data that native code processes. For example, in the photo-sharing app Instagram, SandTrap's performance is close to baseline (1x) when the app does not access tainted data. When it does, SandTrap imposes a slowdown comparable to prior DIFT systems (~8x).},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {230–242},
numpages = {13},
keywords = {native code, dynamic information-flow tracking, parallel memory permissions},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210332,
author = {Liu, Tian and Liu, Ziyu and Huang, Jun and Tan, Rui and Tan, Zhen},
title = {Detecting Wireless Spy Cameras Via Stimulating and Probing},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210332},
doi = {10.1145/3210240.3210332},
abstract = {The rapid proliferation of wireless video cameras has raised serious privacy concerns. In this paper, we propose a stimulating-and-probing approach to detecting wireless spy cameras. The core idea is to actively alter the light condition of a private space to manipulate the spy camera's video scene, and then investigates the responsive variations of a packet flow to determine if it is produced by a wireless camera. Following this approach, we develop Blink and Flicker -- two practical systems for detecting wireless spy cameras. Blink is a lightweight app that can be deployed on off-the-shelf mobile devices. It asks the user to turn on/off the light of her private space, and then uses the light sensor and the wireless radio of the mobile device to identify the response of wireless cameras. Flicker is a robust and automated system that augments Blink to detect wireless cameras in both live and offline streaming modes. Flicker employs a cheap and portable circuit, which harnesses daily used LEDs to stimulate wireless cameras using human-invisible flickering. The time series of stimuli is further encoded using FEC to combat ambient light and uncontrollable packet flow variations that may degrade detection performance. Extensive experiments show that Blink and Flicker can accurately detect wireless cameras under a wide range of network and environmental conditions.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {243–255},
numpages = {13},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210333,
author = {Schulz, Matthias and Link, Jakob and Gringoli, Francesco and Hollick, Matthias},
title = {Shadow Wi-Fi: Teaching Smartphones to Transmit Raw Signals and to Extract Channel State Information to Implement Practical Covert Channels over Wi-Fi},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210333},
doi = {10.1145/3210240.3210333},
abstract = {Wi-Fi chips offer vast capabilities, which are not accessible through the manufacturers' official firmwares. Unleashing those capabilities can enable innovative applications on off-the-shelf devices. In this work, we demonstrate how to transmit raw IQ samples from a large buffer on Wi-Fi chips. We further show how to extract channel state information (CSI) on a per frame basis. As a proof-of-concept application, we build a covert channel on top of Wi-Fi to stealthily exchange information between two devices by prefiltering Wi-Fi frames prior to transmission. On the receiver side, the CSI is used to extract the embedded information. By means of experimentation, we show that regular Wi-Fi clients can still demodulate the underlying Wi-Fi frames. Our results show that covert channels on the physical layer are practical and run on off-the-shelf smartphones. By making available our raw signal transmitter, the CSI extractor, and the covert channel application to the research community, we ensure reproducibility and offer a platform for further innovative applications on Wi-Fi devices.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {256–268},
numpages = {13},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210322,
author = {Nguyen, Phuc and Bui, Nam and Nguyen, Anh and Truong, Hoang and Suresh, Abhijit and Whitlock, Matt and Pham, Duy and Dinh, Thang and Vu, Tam},
title = {TYTH-Typing On Your Teeth: Tongue-Teeth Localization for Human-Computer Interface},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210322},
doi = {10.1145/3210240.3210322},
abstract = {This paper explores a new wearable system, called TYTH, that enables a novel form of human computer interaction based on the relative location and interaction between the user's tongue and teeth. TYTH allows its user to interact with a computing system by tapping on their teeth. This form of interaction is analogous to using a finger to type on a keypad except that the tongue substitutes for the finger and the teeth for the keyboard. We study the neurological and anatomical structures of the tongue to design TYTH so that the obtrusiveness and social awkwardness caused by the wearable is minimized while maximizing its accuracy and sensing sensitivity. From behind the user's ears, TYTH senses the brain signals and muscle signals that control tongue movement sent from the brain and captures the miniature skin surface deformation caused by tongue movement. We model the relationship between tongue movement and the signals recorded, from which a tongue localization technique and tongue-teeth tapping detection technique are derived. Through a prototyping implementation and an evaluation with 15 subjects, we show that TYTH can be used as a form of hands-free human computer interaction with 88.61% detection rate and promising adoption rate by users.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {269–282},
numpages = {14},
keywords = {Brain-Muscles Sensing, Skin Deformation Sensing, Human Computer Interaction (HCI), Wearable Devices, Tongue-Teeth Typing},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210315,
author = {Sun, Ke and Wang, Wei and Liu, Alex X. and Dai, Haipeng},
title = {Depth Aware Finger Tapping on Virtual Displays},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210315},
doi = {10.1145/3210240.3210315},
abstract = {For AR/VR systems, tapping-in-the-air is a user-friendly solution for interactions. Most prior in-air tapping schemes use customized depth-cameras and therefore have the limitations of low accuracy and high latency. In this paper, we propose a fine-grained depth-aware tapping scheme that can provide high accuracy tapping detection. Our basic idea is to use light-weight ultrasound based sensing, along with one COTS mono-camera, to enable 3D tracking of user's fingers. The mono-camera is used to track user's fingers in the 2D space and ultrasound based sensing is used to get the depth information of user's fingers in the 3D space. Using speakers and microphones that already exist on most AR/VR devices, we emit ultrasound, which is inaudible to humans, and capture the signal reflected by the finger with the microphone. From the phase changes of the ultrasound signal, we accurately measure small finger movements in the depth direction. With fast and light-weight ultrasound signal processing algorithms, our scheme can accurately track finger movements and measure the bending angle of the finger between two video frames. In our experiments on eight users, our scheme achieves a 98.4% finger tapping detection accuracy with FPR of 1.6% and FNR of 1.4%, and a detection latency of 17.69ms, which is 57.7ms less than video-only schemes. The power consumption overhead of our scheme is 48.4% more than video-only schemes.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {283–295},
numpages = {13},
keywords = {Ultrasound, Computer Vision, Depth aware, Finger tapping},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210344,
author = {Lin, Feng and Cho, Kun Woo and Song, Chen and Xu, Wenyao and Jin, Zhanpeng},
title = {Brain Password: A Secure and Truly Cancelable Brain Biometrics for Smart Headwear},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210344},
doi = {10.1145/3210240.3210344},
abstract = {In recent years, biometric techniques (e.g., fingerprint or iris) are increasingly integrated into mobile devices to offer security advantages over traditional practices (e.g., passwords and PINs) due to their ease of use in user authentication. However, existing biometric systems are with controversy: once divulged, they are compromised forever - no one can grow a new fingerprint or iris. This work explores a truly cancelable brain-based biometric system for mobile platforms (e.g., smart headwear). Specifically, we present a new psychophysiological protocol via non-volitional brain response for trustworthy mobile authentication, with an application example of smart headwear. Particularly, we address the following research challenges in mobile biometrics with a theoretical and empirical combined manner: (1) how to generate reliable brain responses with sophisticated visual stimuli; (2) how to acquire the distinct brain response and analyze unique features in the mobile platform; (3) how to reset and change brain biometrics when the current biometric credential is divulged. To evaluate the proposed solution, we conducted a pilot study and achieved an f -score accuracy of 95.46% and equal error rate (EER) of 2.503%, thereby demonstrating the potential feasibility of neurofeedback based biometrics for smart headwear. Furthermore, we perform the cancelability study and the longitudinal study, respectively, to show the effectiveness and usability of our new proposed mobile biometric system. To the best of our knowledge, it is the first in-depth research study on truly cancelable brain biometrics for secure mobile authentication.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {296–309},
numpages = {14},
keywords = {Wearable computing, event-related potential, cancelable biometrics, mobile authentication},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210326,
author = {Corner, Mark D. and Levine, Brian N.},
title = {MicroMobile: Leveraging Mobile Advertising for Large-Scale Experimentation},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210326},
doi = {10.1145/3210240.3210326},
abstract = {Mobile systems researchers struggle with conducting experiments with real users: either the scale of the study lacks sufficient scale and diversity, or a great effort must be used to recruit and manage subjects. In this paper, we describe MicroMobile, a system for deploying short data-gathering experiments to an extremely diverse set of users via mobile advertising. We conduct experiments in three mediums: interactive advertisements, mobile browsers, and native applications on both major mobile operating systems.We use MicroMobile to demonstrate how researchers can use mobile advertising to recruit users, for as little as $1.50 per completed experiment. Across almost 500 completed experiments, we found that interactive ads have the highest participation rate (and thus lowest cost), which was 2x the participation rate of browser experiments and more than 6x native app experiments. Users were also highly diverse, spanning age, income, and ethnicity. While native apps are the most powerful platform, they constitute the most expensive targets. However, as mobile browsers add sensor APIs, browser-based experimentation has increasing applicability.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {310–322},
numpages = {13},
keywords = {Mobile measurement, Mobile advertising},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210342,
author = {Liu, Xiaochen and Jiang, Yurong and Jain, Puneet and Kim, Kyu-Han},
title = {TAR: Enabling Fine-Grained Targeted Advertising in Retail Stores},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210342},
doi = {10.1145/3210240.3210342},
abstract = {Mobile advertisements influence customers' in-store purchases and boost in-store sales for brick-and-mortar retailers. Targeting mobile ads has become significantly important to compete with online shopping. The key to enabling targeted mobile advertisement and service is to learn shoppers' interest during their stay in the store. Precise shopper tracking and identification are essential to gain the insights. However, existing sensor-based or vision-based solutions are neither practical nor accurate; no commercial solutions today can be readily deployed in a large store. On the other hand, we recognize that most retail stores have the installation of surveillance cameras, and most shoppers carry Bluetooth-enabled smartphones. Thus, in this paper, we propose TAR to learn shoppers' in-store interest via accurate multi-camera people tracking and identification. TAR leverages widespread camera deployment and Bluetooth proximity information to accurately track and identify shoppers in the store. TAR is composed of four novel design components: (1) a deep neural network (DNN) based visual tracking, (2) a user trajectory estimation by using shopper visual and BLE proximity trace, (3) an identity matching and assignment to recognize shopper's identity, and (4) a cross-camera calibration algorithm. TAR carefully combines these components to track and identify shoppers in real-time. TAR achieves 90% accuracy in two different real-life deployments, which is 20% better than the state-of-the-art solution.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {323–336},
numpages = {14},
keywords = {Shopping, Bluetooth, Edge Computing, Tracking, Computer Vision, Mobile Sensing},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210320,
author = {Wu, Fang-Jing and Solmaz, G\"{u}rkan},
title = {CrowdEstimator: Approximating Crowd Sizes with Multi-Modal Data for Internet-of-Things Services},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210320},
doi = {10.1145/3210240.3210320},
abstract = {Crowd mobility has been paid attention for the Internet-of-things (IoT) applications. This paper addresses the crowd estimation problem and builds an IoT service to share the crowd estimation results across different systems. The crowd estimation problem is to approximate the crowd size in a targeted area using the observed information (e.g., Wi-Fi data). This paper exploits Wi-Fi probe request packets ("Wi-Fi probes" for short) broadcasted by mobile devices to solve this problem. However, using only Wi-Fi probes to estimate the crowd size may result in inaccurate results due to various environmental uncertainties which may lead to crowd overestimation or underestimation. Moreover, the ground-truth is unavailable because the coverage of Wi-Fi signals is time-varying and invisible. This paper introduces auxiliary sensors, stereoscopic cameras, to collect the near ground-truth at a specified calibration choke point. Two calibration algorithms are proposed to solve the crowd estimation problem. The key idea is to calibrate the Wi-Fi-only crowd estimation based on the correlations between the two types of data modalities. Then, to share the calibrated results across systems required by different stakeholders, our system is integrated with the FIWARE-based IoT platform. To verify the proposed system, we have launched an indoor pilot study in the Wellington Railway Station and an outdoor pilot study in the Christchurch Re:START Mall in New Zealand. The large-scale pilot studies show that stereoscopic cameras can reach minimum accuracy of 85% and high precision detection for providing the near ground-truth. The proposed calibration algorithms reduce estimation errors by 43.68% on average compared to the Wi-Fi-only approach.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {337–349},
numpages = {13},
keywords = {smart cities, human mobility, cyber-physical systems},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210314,
author = {Qian, Kun and Wu, Chenshu and Zhang, Yi and Zhang, Guidong and Yang, Zheng and Liu, Yunhao},
title = {Widar2.0: Passive Human Tracking with a Single Wi-Fi Link},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210314},
doi = {10.1145/3210240.3210314},
abstract = {This paper presents Widar2.0, the first WiFi-based system that enables passive human localization and tracking using a single link on commodity off-the-shelf devices. Previous works based on either specialized or commercial hardware all require multiple links, preventing their wide adoption in scenarios like homes where typically only one single AP is installed. The key insight underlying Widar2.0 to circumvent the use of multiple links is to leverage multi-dimensional signal parameters from one single link. To this end, we build a unified model accounting for Angle-of-Arrival, Time-of-Flight, and Doppler shifts together and devise an efficient algorithm for their joint estimation. We then design a pipeline to translate the erroneous raw parameters into precise locations, which first finds parameters corresponding to the reflections of interests, then refines range estimates, and ultimately outputs target locations. Our implementation and evaluation on commodity WiFi devices demonstrate that Widar2.0 achieves better or comparable performance to state-of-the-art localization systems, which either use specialized hardwares or require 2 to 40 Wi-Fi links.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {350–361},
numpages = {12},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210340,
author = {Tian, Zhao and Wei, Yu-Lin and Chang, Wei-Nin and Xiong, Xi and Zheng, Changxi and Tsai, Hsin-Mu and Lin, Kate Ching-Ju and Zhou, Xia},
title = {Augmenting Indoor Inertial Tracking with Polarized Light},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210340},
doi = {10.1145/3210240.3210340},
abstract = {Inertial measurement unit (IMU) has long suffered from the problem of integration drift, where sensor noises accumulate quickly and cause fast-growing tracking errors. Existing methods for calibrating IMU tracking either require human in the loop, or need energy-consuming cameras, or suffer from coarse tracking granularity. We propose to augment indoor inertial tracking by reusing existing indoor luminaries to project a static light polarization pattern in the space. This pattern is imperceptible to human eyes and yet through a polarizer, it becomes detectable by a color sensor, and thus can serve as fine-grained optical landmarks that constrain and correct IMU's integration drift and boost tracking accuracy. Exploiting the birefringence optical property of transparent tapes -- a low-cost and easily-accessible material -- we realize the polarization pattern by simply adding to existing light cover a thin polarizer film with transparent tape stripes glued atop. When fusing with IMU sensor signals, the light pattern enables robust, accurate and low-power motion tracking. Meanwhile, our approach entails low deployment overhead by reusing existing lighting infrastructure without needing an active modulation unit. We build a prototype of our light cover and the sensing unit using off-the-shelf components. Experiments show 4.3 cm median error for 2D tracking and 10 cm for 3D tracking, as well as its robustness in diverse settings.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {362–375},
numpages = {14},
keywords = {Inertial tracking, particle filter, light polarization},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210347,
author = {Soltanaghaei, Elahe and Kalyanaraman, Avinash and Whitehouse, Kamin},
title = {Multipath Triangulation: Decimeter-Level WiFi Localization and Orientation with a Single Unaided Receiver},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210347},
doi = {10.1145/3210240.3210347},
abstract = {Decimeter-level localization has become a reality, in part due to the ability to eliminate the effects of multipath interference. In this paper, we demonstrate the ability to use multipath reflections to enhance localization rather than throwing them away. We present Multipath Triangulation, a new localization technique that uses multipath reflections to localize a target device with a single receiver that does not require any form of coordination with any other devices. In this paper, we leverage multipath triangulation to build the first decimeter-level WiFi localization system, called MonoLoco, that requires only a single access point (AP) and a single channel, and does not impose any overhead, data sharing, or coordination protocols beyond standard WiFi communication. As a bonus, it also determines the orientation of the target relative to the AP. We implemented MonoLoco using Intel 5300 commodity WiFi cards and deploy it in four environments with different multipath propagation. Results indicate median localization error of 0.5m and median orientation error of 6.6 degrees, which are comparable to the best performing prior systems, all of which require multiple APs and/or multiple frequency channels. High accuracy can be achieved with only a handful of packets.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {376–388},
numpages = {13},
keywords = {localization, multipath propagation, WiFi, CSI, multipath triangulation, Channel State Information},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210337,
author = {Liu, Sicong and Lin, Yingyan and Zhou, Zimu and Nan, Kaiming and Liu, Hui and Du, Junzhao},
title = {On-Demand Deep Model Compression for Mobile Devices: A Usage-Driven Model Selection Framework},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210337},
doi = {10.1145/3210240.3210337},
abstract = {Recent research has demonstrated the potential of deploying deep neural networks (DNNs) on resource-constrained mobile platforms by trimming down the network complexity using different compression techniques. The current practice only investigate stand-alone compression schemes even though each compression technique may be well suited only for certain types of DNN layers. Also, these compression techniques are optimized merely for the inference accuracy of DNNs, without explicitly considering other application-driven system performance (e.g. latency and energy cost) and the varying resource availabilities across platforms (e.g. storage and processing capability). In this paper, we explore the desirable tradeoff between performance and resource constraints by user-specified needs, from a holistic system-level viewpoint. Specifically, we develop a usage-driven selection framework, referred to as AdaDeep, to automatically select a combination of compression techniques for a given DNN, that will lead to an optimal balance between user-specified performance goals and resource constraints. With an extensive evaluation on five public datasets and across twelve mobile devices, experimental results show that AdaDeep enables up to 9.8x latency reduction, 4.3x energy efficiency improvement, and 38x storage reduction in DNNs while incurring negligible accuracy loss. AdaDeep also uncovers multiple effective combinations of compression techniques unexplored in existing literature.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {389–400},
numpages = {12},
keywords = {deep reinforcement learning, deep learning, model compression},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210335,
author = {Venkatnarayan, Raghav H. and Page, Griffin and Shahzad, Muhammad},
title = {Multi-User Gesture Recognition Using WiFi},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210335},
doi = {10.1145/3210240.3210335},
abstract = {WiFi based gesture recognition has received significant attention over the past few years. However, the key limitation of prior WiFi based gesture recognition systems is that they cannot recognize the gestures of multiple users performing them simultaneously. In this paper, we address this limitation and propose WiMU, a WiFi based Multi-User gesture recognition system. The key idea behind WiMU is that when it detects that some users have performed some gestures simultaneously, it first automatically determines the number of simultaneously performed gestures (Na) and then, using the training samples collected from a single user, generates virtual samples for various plausible combinations of Na gestures. The key property of these virtual samples is that the virtual samples for any given combination of gestures are identical to the real samples that would result from real users performing that combination of gestures. WiMU compares the detected sample against these virtual samples and recognizes the simultaneously performed gestures. We implemented and extensively evaluated WiMU using commodity WiFi devices. Our results show that WiMU recognizes 2, 3, 4, 5, and 6 simultaneously performed gestures with accuracies of 95.0, 94.6, 93.6, 92.6, and 90.9%, respectively.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {401–413},
numpages = {13},
keywords = {Gesture recognition, WiFi, Multi-user},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210336,
author = {Ryoo, Jihoon and Karimi, Yasha and Athalye, Akshay and Stana\'{c}evi\'{c}, Milutin and Das, Samir R. and Djuri\'{c}, Petar},
title = {BARNET: Towards Activity Recognition Using Passive Backscattering Tag-to-Tag Network},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210336},
doi = {10.1145/3210240.3210336},
abstract = {We present the vision of BARNET (Backscattering Activity Recognition NEtwork of Tags), a network of passive RF tags that use RF backscatter for tag-to-tag communication. BARNET not only provides identification of tagged objects but also can serve as a 'device-free' activity recognition system. BARNET's key innovation is the concept of backscatter channel state information (BCSI) which can be measured via systematic multiphase probing of the backscatter tag-to-tag channel using innovative processing on the passive tags. So far such measurements were only possible using active radio receivers that consume much higher power. Changes in BCSI provide signatures for different activities in the environment that can be learned using suitable machine learning tools. We develop the BARNET tag architecture which shows that an ASIC implementation can run on harvested RF power. We develop a printed circuit board (PCB) prototype using discrete components to evaluate activity recognition performance. We show that the prototype can recognize human daily activities with an average error around 6%. Overall, BARNET uses passive tags to achieve the same level of performance as systems that use powered, active radios.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {414–427},
numpages = {14},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210328,
author = {Jin, Haojian and Wang, Jingxian and Yang, Zhijian and Kumar, Swarun and Hong, Jason},
title = {WiSh: Towards a Wireless Shape-Aware World Using Passive RFIDs},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210328},
doi = {10.1145/3210240.3210328},
abstract = {This paper presents WiSh, a solution that makes ordinary surfaces shape-aware, relaying their real-time geometry directly to a user's handheld device. WiSh achieves this using inexpensive, light-weight and battery-free RFID tags attached to these surfaces tracked from a compact single-antenna RFID reader. In doing so, WiSh enables several novel applications: shape-aware clothing that can detect a user's posture, interactive shape-aware toys or even shape-aware bridges that report their structural health.WiSh's core algorithm infers the shape of ordinary surfaces using the wireless channels of signals reflected off RFID tags received at a single-antenna RFID reader. Indeed, locating every RFID tag using a single channel measurement per-tag is challenging, given that neither their 3-D coordinates nor orientation are known a priori. WiSh presents a novel algorithm that models the geometric constraints between the coordinates of the RFID tags based on flexibility of the surface upon which they are mounted. By inferring surface curvature parameters rather than the locations of individual RFID tags, we greatly reduce the number of variables our system needs to compute. Further, WiSh overcomes a variety of system-level challenges stemming from signal multipath, stretching of fabric and modeling large surfaces. We implement WiSh on commodity RFID readers and tags attached to a variety of surfaces and demonstrate mm-accurate shape-tracking across various applications.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {428–441},
numpages = {14},
keywords = {RFID sensing, smart fabric, shape-aware, smart material},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210345,
author = {Dhekne, Ashutosh and Gowda, Mahanth and Zhao, Yixuan and Hassanieh, Haitham and Choudhury, Romit Roy},
title = {LiquID: A Wireless Liquid IDentifier},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210345},
doi = {10.1145/3210240.3210345},
abstract = {This paper shows the feasibility of identifying liquids by shining ultra-wideband (UWB) wireless signals through them. The core opportunity arises from the fact that wireless signals experience distinct slow-down and attenuation when passing through a liquid, manifesting in the phase, strength, and propagation delay of the outgoing signal. While this intuition is simple, building a robust system entails numerous challenges, including (1) pico-second scale time of flight estimation, (2) coping with integer ambiguity due to phase wraps, (3) pollution from hardware noise and multipath, and (4) compensating for the liquid-container's impact on the measurements. We address these challenges through multiple stages of signal processing without relying on any feature extraction or machine learning. Instead, we model the behavior of radio signals inside liquids (using principles of physics), and estimate the liquid's permittivity, which in turn identifies the liquid. Experiments across 33 different liquids (spread over the whole permittivity spectrum) show median permittivity error of 9%. This implies that coke can be discriminated from diet coke or pepsi, whole milk from 2% milk, and distilled water from saline water. Our end system, LiquID, is cheap, non-invasive, and amenable to real-world applications.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {442–454},
numpages = {13},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210312,
author = {Tung, Yu-Chih and Bui, Duc and Shin, Kang G.},
title = {Cross-Platform Support for Rapid Development of Mobile Acoustic Sensing Applications},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210312},
doi = {10.1145/3210240.3210312},
abstract = {LibAS is a cross-platform framework to facilitate the rapid development of mobile acoustic sensing apps. It helps developers quickly realize their ideas by using a high-level Matlab script, and test them on various OS platforms, such as Android, iOS, Tizen, and Linux/Win. LibAS simplifies the development of acoustic sensing apps by hiding the platform-dependent details. For example, developers need not learn Objective-C/SWIFT or the audio buffer management in the CoreAudio framework when they want to implement acoustic sensing algorithms on an iPhone. Instead, developers only need to decide on the sensing signals and the callback function to handle each repetition of sensing signals. We have implemented apps covering three major acoustic sensing categories to demonstrate the benefits and simplicity of developing apps with LibAS. Our evaluation results show the adaptability of LibAS in supporting various acoustic sensing apps and tuning/improving their performance efficiently. Developers have reported that LibAS saves them a significant amount of time/effort and can reduce up to 90% lines of code in their acoustic sensing apps.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {455–467},
numpages = {13},
keywords = {Acoustic sensing, cross-platform development, rapid prototype},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210325,
author = {Mao, Wenguang and Wang, Mei and Qiu, Lili},
title = {AIM: Acoustic Imaging on a Mobile},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210325},
doi = {10.1145/3210240.3210325},
abstract = {The popularity of smartphones has grown at an unprecedented rate, which makes smartphone based imaging especially appealing. In this paper, we develop a novel acoustic imaging system using only an off-the-shelf smartphone. It is an attractive alternative to camera based imaging under darkness and obstruction. Our system is based on Synthetic Aperture Radar (SAR). To image an object, a user moves a phone along a predefined trajectory to mimic a virtual sensor array. SAR based imaging poses several new challenges in our context, including strong self and background interference, deviation from the desired trajectory due to hand jitters, and severe speaker/microphone distortion. We address these challenges by developing a 2-stage interference cancellation scheme, a new algorithm to compensate trajectory errors, and an effective method to minimize the impact of signal distortion. We implement a proof-of-concept system on Samsung S7. Our results demonstrate the feasibility and effectiveness of acoustic imaging on a mobile.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {468–481},
numpages = {14},
keywords = {autofocus, interference cancellation, Acoustic imaging, SAR},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210323,
author = {He, Jian and Qureshi, Mubashir Adnan and Qiu, Lili and Li, Jin and Li, Feng and Han, Lei},
title = {Rubiks: Practical 360-Degree Streaming for Smartphones},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210323},
doi = {10.1145/3210240.3210323},
abstract = {The popularity of 360° videos has grown rapidly due to the immersive user experience. 360° videos are displayed as a panorama and the view automatically adapts with the head movement. Existing systems stream 360° videos in a similar way as regular videos, where all data of the panoramic view is transmitted. This is wasteful since a user only views a small portion of the 360° view. To save bandwidth, recent works propose the tile-based streaming, which divides the panoramic view to multiple smaller sized tiles and streams only the tiles within a user's field of view (FoV) predicted based on the recent head position. Interestingly, the tile-based streaming has only been simulated or implemented on desktops. We find that it cannot run in real-time even on the latest smartphone (e.g., Samsung S7, Samsung S8 and Huawei Mate 9) due to hardware and software limitations. Moreover, it results in significant video quality degradation due to head movement prediction error, which is hard to avoid. Motivated by these observations, we develop a novel tile-based layered approach to stream 360° content on smartphones to avoid bandwidth wastage while maintaining high video quality. Through real system experiments, we show our approach can achieve up to 69% improvement in user QoE and 49% in bandwidth savings over existing approaches. To the best of our knowledge, this is the first 360° streaming framework that takes into account the practical limitations of Android based smartphones.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {482–494},
numpages = {13},
keywords = {Smartphones, 360° Videos, Video Codecs, Rate Adaptation},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3223572,
author = {Feeney, Laura Marie and Gunningberg, Per},
title = {Avoiding an IoT 'Tragedy of the Commons'},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3223572},
doi = {10.1145/3210240.3223572},
abstract = {The large number and wide diversity of IoT networks operating in unlicensed spectrum will create a complex and challenging interference environment. To avoid a 'tragedy of the commons', networks may need to more explicitly coordinate their use of the shared channel.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {495–497},
numpages = {3},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3223573,
author = {Krishnamachari, Bhaskar and Power, Jerry and Kim, Seon Ho and Shahabi, Cyrus},
title = {I3: An IoT Marketplace for Smart Communities},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3223573},
doi = {10.1145/3210240.3223573},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {498–499},
numpages = {2},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3223574,
author = {Nirjon, Shahriar},
title = {Lifelong Learning on Harvested Energy},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3223574},
doi = {10.1145/3210240.3223574},
abstract = {We introduce the vision of lifelong and intermittent learning, which will enable batteryless computing platforms to execute a certain class of machine learning tasks. We identify key properties and challenges to learning on harvested energy which relates to the semantics of machine learning tasks. Each of these challenges leads to a new research direction. We envision that a big chunk of research on batteryless IoT devices in the next 5-10 years will be about making them capable of continuously learning throughout their lifetime. Concepts related to intermittent learning will be at the heart of those works.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {500–501},
numpages = {2},
keywords = {lifelong learning, energy harvester, intermittent learning},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3223570,
author = {Zhao, Jianxin and Tiplea, Tudor and Mortier, Richard and Crowcroft, Jon and Wang, Liang},
title = {Data Analytics Service Composition and Deployment on IoT Devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3223570},
doi = {10.1145/3210240.3223570},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {502–504},
numpages = {3},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3226062,
author = {Psaras, Ioannis},
title = {Decentralised Edge-Computing and IoT through Distributed Trust},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3226062},
doi = {10.1145/3210240.3226062},
abstract = {The emerging Internet of Things needs edge-computing - this is an established fact. In turn, edge computing needs infrastructure decentralisation. What is not necessarily established yet is that infrastructure decentralisation needs a distributed model of Internet governance and decentralised trust schemes. We discuss the features of a decentralised IoT and edge-computing ecosystem and list the components that need to be designed, as well the challenges that need to be addressed.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {505–507},
numpages = {3},
keywords = {Blockchain, Edge-Computing, Programmable Privacy, Distributed Trust},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3223569,
author = {von Maltitz, Marcel and Carle, Georg},
title = {Leveraging Secure Multiparty Computation in the Internet of Things},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3223569},
doi = {10.1145/3210240.3223569},
abstract = {Centralized systems in the Internet of Things---be it local middleware or cloud-based services---fail to fundamentally address privacy of the collected data. We propose an architecture featuring secure multiparty computation at its core in order to realize data processing systems which already incorporate support for privacy protection in the architecture.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {508–510},
numpages = {3},
keywords = {Secure Multiparty Computation, Smart Environments, Internet of Things, Sensor Data},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210803,
author = {Feng, Wendi and Liu, Chuanchang and Ren, Bingfei and Cheng, Bo and Chen, Junliang},
title = {TrustGyges: A Hidden Volume Solution with Cloud Safe Storage and TEE},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210803},
doi = {10.1145/3210240.3210803},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {511},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210804,
author = {Walelgne, Ermias A. and Asrese, Alemnew S. and Bajpai, Vaibhav and Ott, J\"{o}rg and Manner, Jukka},
title = {Using Crowdsourcing Data for Adaptive Video Streaming in Cellular Network},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210804},
doi = {10.1145/3210240.3210804},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {512},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210805,
author = {Kietzmann, Peter and G\"{u}ndo\u{g}an, Cenk and Schmidt, Thomas C. and W\"{a}hlisch, Matthias},
title = {A PUF Seed Generator for RIOT: Introducing Crypto-Fundamentals to the Wild},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210805},
doi = {10.1145/3210240.3210805},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {513},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210806,
author = {Wang, Qing and Xu, Chenren and Leng, Supeng and Pollin, Sofie},
title = {When Autonomous Drones Meet Driverless Cars},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210806},
doi = {10.1145/3210240.3210806},
abstract = {In this poster, we envision the promising cooperation between autonomous drones and driverless cars. We discuss potential applications and opportunities enabled by this cooperation.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {514},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210808,
author = {Ni, Yunzhe and Xu, Chenren},
title = {A Multipath Transport Multihoming Mobile Relay Architecture for High-Speed Rails Networking},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210808},
doi = {10.1145/3210240.3210808},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {515},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210809,
author = {Tavares, Miguel and Aponte, Omar and Mendes, Paulo},
title = {Named-Data Emergency Network Services},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210809},
doi = {10.1145/3210240.3210809},
abstract = {This poster explains how to deploy emergency services leveraging Named-Data Networking with push communications and the capability of operating on intermittent wireless networks.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {516},
numpages = {1},
keywords = {Opportunistic Networking, Named-Data Networking},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210810,
author = {Min, Chulhong and Mathur, Akhil and Kawsar, Fahim},
title = {Audio-Kinetic Model for Automatic Dietary Monitoring with Earable Devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210810},
doi = {10.1145/3210240.3210810},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {517},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210811,
author = {Yang, Jing and S\"{o}r\"{o}s, G\'{a}bor},
title = {Spatial Audio for Human-Object Interactions in Small AR Workspaces},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210811},
doi = {10.1145/3210240.3210811},
abstract = {While spatial audio has been an essential component in Virtual Reality, it has been rarely applied to Augmented Reality. We propose a concept and a prototype to enhance human-object interactions in daily life with 3D audio. We augment real objects in a small workspace around the user with spatial audio notifications.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {518},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210813,
author = {Mortazavi, Seyed Hossein and Balasubramanian, Bharath and de Lara, Eyal and Narayanan, Shankaranarayanan Puzhavakath},
title = {Pathstore, A Data Storage Layer For The Edge},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210813},
doi = {10.1145/3210240.3210813},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {519},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210814,
author = {Forlivesi, Claudio and van den Broeck, Marc and Acer, Utku G\"{u}nay and Kawsar, Fahim},
title = {On-Wearable AI to Model Human Interruptibility},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210814},
doi = {10.1145/3210240.3210814},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {520},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210815,
author = {Fotouhi, Mohammadbagher and Niu, Ruixin and Cheng, Wei},
title = {An Accurate Smartphone Ranging System},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210815},
doi = {10.1145/3210240.3210815},
abstract = {In this poster, an accurate distance ranging system for off-the-shelf smartphones is introduced. Two ranging methods, namely improved Microsoft Beep-Beep and our Single-Beep, are developed and evaluated on 6 different Android phones.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {521},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210816,
author = {Yang, Zhuolin and Li, Zhengxiong and Zhuang, Yan and Xu, Wenyao},
title = {Exploring an Inclusive User Interface through Respiration},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210816},
doi = {10.1145/3210240.3210816},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {522},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210817,
author = {Liaqat, Daniyal and Wu, Robert and Gershon, Andrea and Alshaer, Hisham and Rudzicz, Frank and de Lara, Eyal},
title = {Speech in Smartwatch Based Audio},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210817},
doi = {10.1145/3210240.3210817},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {523},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210818,
author = {Kim, Beomjun and Seo, Juhee and Lim, Jaebong and Baek, Yunju},
title = {Design and Implementation of Driving Information Collection System for Driver Behavior Analysis},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210818},
doi = {10.1145/3210240.3210818},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {524},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210819,
author = {Kwon, HyukSang and Ko, JeongGil},
title = {LightCert: Designing Smaller Certificates for the Internet of Things Devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210819},
doi = {10.1145/3210240.3210819},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {525},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210824,
author = {Collister, Keith and Yoneki, Eiko},
title = {RaDiCS: Distributed Computing Service over Raspberry Pis with Unikernels},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210824},
doi = {10.1145/3210240.3210824},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {526},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3210240.3210820,
author = {Choi, Jaewon and Park, Hyeonjung and Paek, Jeongyeup and Ko, JeongGil},
title = {Reactive Mesh Simplification for Augmented Reality Head Mounted Displays},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210820},
doi = {10.1145/3210240.3210820},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {527},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3081333.3081474,
author = {Maes, Pattie},
title = {Augmenting the Human Experience},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081474},
doi = {10.1145/3081333.3081474},
abstract = {BIO: Pattie Maes is the Alexander W. Dreyfoos (1954) Professor in MIT's Program in Media Arts and Sciences and associate head of the Program in Media Arts and Sciences. She founded and directs the Media Lab's Fluid Interfaces research group. Previously, she founded and ran the Software Agents group. Prior to joining the Media Lab, Maes was a visiting professor and a research scientist at the MIT Artificial Intelligence Lab. She holds bachelor's and PhD degrees in computer science from the Vrije Universiteit Brussel in Belgium. Her areas of expertise are human-computer interaction and artificial intelligence. Maes is the editor of three books, and is an editorial board member and reviewer for numerous professional journals and conferences. She has received several awards: FastCompany named her one of 50 most influential designers (2011). Newsweek magazine named her one of the "100 Americans to watch for" in the year 2000; TIME Digital selected her as a member of the Cyber-Elite, the top 50 technological pioneers of the high-tech world; the World Economic Forum honored her with the title "Global Leader for Tomorrow"; Ars Electronica awarded her the 1995 World Wide Web category prize; and in 2000 she was recognized with the "Lifetime Achievement Award" by the Massachusetts Interactive Media Council. She also received an honorary doctorate from the Vrije Universiteit Brussel in Belgium. Her 2009 TED talk is among the most watched TED talks ever. In addition to her academic endeavors, Maes has been active as an entrepreneur as cofounder of several venture-backed companies including Firefly Networks (sold to Microsoft) and Open Ratings (sold to Dun &amp; Bradstreet). She remains an advisor and investor to several MIT spinoffs.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {1},
numpages = {1},
keywords = {keynote talk},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3257283,
author = {Lane, Nicholas},
title = {Session Details: PAPER SESSION 1: Acoustic Sensing},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257283},
doi = {10.1145/3257283},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081366,
author = {Roy, Nirupam and Hassanieh, Haitham and Roy Choudhury, Romit},
title = {BackDoor: Making Microphones Hear Inaudible Sounds},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081366},
doi = {10.1145/3081333.3081366},
abstract = {Consider sounds, say at 40kHz, that are completely outside the human's audible range (20kHz), as well as a microphone's recordable range (24kHz). We show that these high frequency sounds can be designed to become recordable by unmodified microphones, while remaining inaudible to humans. The core idea lies in exploiting non-linearities in microphone hardware. Briefly, we design the sound and play it on a speaker such that, after passing through the microphone's non-linear diaphragm and power-amplifier, the signal creates a "shadow" in the audible frequency range. The shadow can be regulated to carry data bits, thereby enabling an acoustic (but inaudible) communication channel to today's microphones. Other applications include jamming spy microphones in the environment, live watermarking of music in a concert, and even acoustic denial-of-service (DoS) attacks. This paper presents BackDoor, a system that develops the technical building blocks for harnessing this opportunity. Reported results achieve upwards of 4kbps for proximate data communication, as well as room-level privacy protection against electronic eavesdropping.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {2–14},
numpages = {13},
keywords = {speech privacy, acoustics, smartphone, security, privacy, acoustic jamming, nonlinear acoustics, communication, inaudible sound, voice authentication, ultrasound},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081356,
author = {Yun, Sangki and Chen, Yi-Chao and Zheng, Huihuang and Qiu, Lili and Mao, Wenguang},
title = {Strata: Fine-Grained Acoustic-Based Device-Free Tracking},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081356},
doi = {10.1145/3081333.3081356},
abstract = {Next generation devices, such as virtual reality (VR), augmented reality (AR), and smart appliances, demand a simple and intuitive way for users to interact with them. To address such needs, we develop a novel acoustic based device-free tracking system, called Strata, to enable a user to interact with a nearby device by simply moving his finger. In Strata, a mobile (e.g., smartphone) transmits known audio signals at inaudible frequency, and analyzes the received signal reflected by the moving finger to track the finger location. To explicitly take into account multipath propagation, the mobile estimates the channel impulse response (CIR), which characterizes signal traversal paths with different delays. Each channel tap corresponds to the multipath effects within a certain delay range. The mobile selects the channel tap corresponding to the finger movement and extracts the phase change of the selected tap to accurately estimate the distance change of a finger. Moreover, it estimates the absolute distance of the finger based on the change in CIR using a novel optimization framework. We then combine the absolute and relative distance estimates to accurately track the moving target. We implement our tracking system on Samsung Galaxy S4 mobile phone. Through micro-benchmarks and user studies, we show that our system achieves high tracking accuracy and low latency without extra hardware.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {15–28},
numpages = {14},
keywords = {channel impulse response, gesture recognition, acoustic tracking},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081338,
author = {Islam, Md Tamzeed and Islam, Bashima and Nirjon, Shahriar},
title = {SoundSifter: Mitigating Overhearing of Continuous Listening Devices},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081338},
doi = {10.1145/3081333.3081338},
abstract = {In this paper, we study the overhearing problem of continuous acoustic sensing devices such as Amazon Echo, Google Home, or such voice-enabled home hubs, and develop a system called SoundSifter that mitigates personal or contextual information leakage due to the presence of unwanted sound sources in the acoustic environment. Instead of proposing modifications to existing home hubs, we build an independent embedded system that connects to a home hub via its audio input. Considering the aesthetics of home hubs, we envision SoundSifter as a smart sleeve or a cover for these devices. SoundSifter has hardware and software to capture the audio, isolate signals from distinct sound sources, filter out signals that are from unwanted sources, and process the signals to enforce policies such as personalization before the signals enter into an untrusted system like Amazon Echo or Google Home. We conduct empirical and real-world experiments to demonstrate that SoundSifter runs in real-time, is noise resilient, and supports selective and personalized voice commands that commercial voice-enabled home hubs do not.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {29–41},
numpages = {13},
keywords = {audio privacy, sound source separation, acoustic sensing},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081363,
author = {Zhou, Bing and Elbadry, Mohammed and Gao, Ruipeng and Ye, Fan},
title = {BatMapper: Acoustic Sensing Based Indoor Floor Plan Construction Using Smartphones},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081363},
doi = {10.1145/3081333.3081363},
abstract = {The lack of digital floor plans is a huge obstacle to pervasive indoor location based services (LBS). Recent floor plan construction work crowdsources mobile sensing data from smartphone users for scalability. However, they incur long time (e.g., weeks or months) and tremendous efforts in data collection, and many rely on images thus suffering technical and privacy limitations. In this paper, we propose BatMapper, which explores a previously untapped sensing modality -- acoustics -- for fast, fine grained and low cost floor plan construction. We design sound signals suitable for heterogeneous microphones on commodity smartphones, and acoustic signal processing techniques to produce accurate distance measurements to nearby objects. We further develop robust probabilistic echo-object association, recursive outlier removal and probabilistic resampling algorithms to identify the correspondence between distances and objects, thus the geometry of corridors and rooms. We compensate minute hand sway movements to identify small surface recessions, thus detecting doors automatically. Experiments in real buildings show BatMapper achieves 1-2cm distance accuracy in ranges up around 4m; a 2-3 minute walk generates fine grained corridor shapes, detects doors at 92% precision and 1~2m location error at 90-percentile; and tens of seconds of measurement gestures produce room geometry with errors &lt;0.3m at 80-percentile, at 1-2 orders of magnitude less data amounts and user efforts.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {42–55},
numpages = {14},
keywords = {acoustic sensing, indoor floor plans},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3257284,
author = {Philipose, Matthai},
title = {Session Details: PAPER SESSION 2: Deep Learning on Mobiles},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257284},
doi = {10.1145/3257284},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081336,
author = {Zeng, Xiao and Cao, Kai and Zhang, Mi},
title = {<i>MobileDeepPill</i>: A Small-Footprint Mobile Deep Learning System for Recognizing Unconstrained Pill Images},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081336},
doi = {10.1145/3081333.3081336},
abstract = {Correct identification of prescription pills based on their visual appearance is a key step required to assure patient safety and facilitate more effective patient care. With the availability of high-quality cameras and computational power on smartphones, it is possible and helpful to identify unknown prescription pills using smartphones. Towards this goal, in 2016, the U.S. National Library of Medicine (NLM) of the National Institutes of Health (NIH) announced a nationwide competition, calling for the creation of a mobile vision system that can recognize pills automatically from a mobile phone picture under unconstrained real-world settings. In this paper, we present the design and evaluation of such mobile pill image recognition system called MobileDeepPill. The development of MobileDeepPill involves three key innovations: a triplet loss function which attains invariances to real-world noisiness that deteriorates the quality of pill images taken by mobile phones; a multi-CNNs model that collectively captures the shape, color and imprints characteristics of the pills; and a Knowledge Distillation-based deep model compression framework that significantly reduces the size of the multi-CNNs model without deteriorating its recognition performance. Our deep learning-based pill image recognition algorithm wins the First Prize (champion) of the NIH NLM Pill Image Recognition Challenge. Given its promising performance, we believe MobileDeepPill helps NIH tackle a critical problem with significant societal impact and will benefit millions of healthcare personnel and the general public.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {56–67},
numpages = {12},
keywords = {mobile deep learning systems, deep neural network model compression, unconstrained pill image recognition, mobile health},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081359,
author = {Mathur, Akhil and Lane, Nicholas D. and Bhattacharya, Sourav and Boran, Aidan and Forlivesi, Claudio and Kawsar, Fahim},
title = {DeepEye: Resource Efficient Local Execution of Multiple Deep Vision Models Using Wearable Commodity Hardware},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081359},
doi = {10.1145/3081333.3081359},
abstract = {Wearable devices with built-in cameras present interesting opportunities for users to capture various aspects of their daily life and are potentially also useful in supporting users with low vision in their everyday tasks. However, state-of-the-art image wearables available in the market are limited to capturing images periodically and do not provide any real-time analysis of the data that might be useful for the wearers. In this paper, we present DeepEye - a match-box sized wearable camera that is capable of running multiple cloud-scale deep learn- ing models locally on the device, thereby enabling rich analysis of the captured images in near real-time without offloading them to the cloud. DeepEye is powered by a commodity wearable processor (Snapdragon 410) which ensures its wearable form factor. The software architecture for DeepEye addresses a key limitation with executing multiple deep learning models on constrained hardware, that is their limited runtime memory. We propose a novel inference software pipeline that targets the local execution of multiple deep vision models (specifically, CNNs) by interleaving the execution of computation-heavy convolutional layers with the loading of memory-heavy fully-connected layers. Beyond this core idea, the execution framework incorporates: a memory caching scheme and a selective use of model compression techniques that further minimizes memory bottlenecks. Through a series of experiments, we show that our execution framework outperforms the baseline approaches significantly in terms of inference latency, memory requirements and energy consumption.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {68–81},
numpages = {14},
keywords = {computer vision, local execution, deep learning, wearables, embedded devices},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081360,
author = {Huynh, Loc N. and Lee, Youngki and Balan, Rajesh Krishna},
title = {DeepMon: Mobile GPU-Based Deep Learning Framework for Continuous Vision Applications},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081360},
doi = {10.1145/3081333.3081360},
abstract = {The rapid emergence of head-mounted devices such as the Microsoft Holo-lens enables a wide variety of continuous vision applications. Such applications often adopt deep-learning algorithms such as CNN and RNN to extract rich contextual information from the first-person-view video streams. Despite the high accuracy, use of deep learning algorithms in mobile devices raises critical challenges, i.e., high processing latency and power consumption. In this paper, we propose DeepMon, a mobile deep learning inference system to run a variety of deep learning inferences purely on a mobile device in a fast and energy-efficient manner. For this, we designed a suite of optimization techniques to efficiently offload convolutional layers to mobile GPUs and accelerate the processing; note that the convolutional layers are the common performance bottleneck of many deep learning models. Our experimental results show that DeepMon can classify an image over the VGG-VeryDeep-16 deep learning model in 644ms on Samsung Galaxy S7, taking an important step towards continuous vision without imposing any privacy concerns nor networking cost.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {82–95},
numpages = {14},
keywords = {mobile sensing, deep learning, mobile gpu, continuous vision},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3257285,
author = {Zhou, Xia},
title = {Session Details: PAPER SESSION 3: Light Sensing and Communications},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257285},
doi = {10.1145/3257285},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081335,
author = {Zhu, Shilin and Zhang, Xinyu},
title = {Enabling High-Precision Visible Light Localization in Today's Buildings},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081335},
doi = {10.1145/3081333.3081335},
abstract = {For over one decade, research in visible light positioning has focused on using modulated LEDs as location landmarks. But the need for specialized LED fixtures, and the associated retrofitting cost, has been hindering the adoption of VLP. In this paper, we forgo this approach and design iLAMP to enable reliable, high-precision VLP using conventional LEDs and fluorescent lamps inside today's buildings. Our key observation is that these lamps intrinsically possess hidden visual features, which are imperceptible to human eyes, but can be extracted by capturing and processing the lamps' images using a computational imaging framework. Simply using commodity smartphones' front cameras, our approach can identify lamps within a building with close to 100% accuracy. Furthermore, we develop a geometrical model which combines the camera image with gyroscope/accelerometer output, to estimate a smartphone's 3D location and heading direction relative to each lamp landmark. Our field tests demonstrate a mean localization (heading) precision of 3 cm (2.6 degree) and 90-percentile 3.5 cm (2.8 degree), even if a single lamp falls in the camera's field of view.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {96–108},
numpages = {13},
keywords = {visible light system, indoor localization, mobile computing, ubiquitous computing},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081353,
author = {Chan, Chun-Ling and Tsai, Hsin-Mu and Lin, Kate Ching-Ju},
title = {POLI: Long-Range Visible Light Communications Using Polarized Light Intensity Modulation},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081353},
doi = {10.1145/3081333.3081353},
abstract = {Recent studies have demonstrated the potential of light-to-camera communications for realizing applications such as localization, augmented reality and vehicle-to-vehicle communications. However, the fundamental requirement of visible light communications, flicker-free illumination, becomes a key limitation hindering existing technologies from serving a camera at larger distances. To break this limitation, this paper presents POLI, a light-to-camera communication system that exploits a novel POlarized Light Intensity modulation scheme to provide reliable communications for a wide range of distances. The key idea of POLI is to hide the information with the polarization direction of the light, to which human eyes are insensitive. Taking advantage of this, POLI can change the intensity of the polarized light as slowly as possible, at a rate determined by the range the system would support, but does not generate flickers. By using an optical component to "transform polarization directions to colors", POLI allows a camera to leverage its received RGB values as the three spatial dimensions to recover the information carried in different data streams. POLI further incorporates a number of designs to tackle the non-linearity effect of a camera, which is especially critical for an intensity-based modulation scheme. We implemented a prototype using the USRP N200 combined with off-the-shelf optical components. The experimental results show that POLI delivers to its camera receiver a throughput proportional to the dynamic channel conditions. The achievable throughput can be up to 71 bytes per second at short distances, while the service range can be up to 40 meters.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {109–120},
numpages = {12},
keywords = {intensity modulation, mimo, camera communications, visible light communications},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081357,
author = {Yoo, Chungkuk and Hwang, Inseok and Kang, Seungwoo and Kim, Myung-Chul and Kim, Seonghoon and Won, Daeyoung and Gu, Yu and Song, Junehwa},
title = {Card-Stunt as a Service: Empowering a Massively Packed Crowd for Instant Collective Expressiveness},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081357},
doi = {10.1145/3081333.3081357},
abstract = {Imagine a densely packed crowd that gathers to convey a common message, such as people in a candlelight vigil or a protest. We envision an innovation through mobile computing technologies to empower such a crowd by enabling them simply to hold their phones up and create a massive collective visualization on top of them. We propose Card-stunt as a Service (CaaS). CaaS is a service enabling a densely packed crowd to instantly visualize symbols using their mobile devices and a server-side service. The key challenge toward realizing an instant collective visualization is how to achieve instant, infrastructure-free, decimeter-level localization of individuals in a massively packed crowd, while maintaining low latency. CaaS addresses the challenges by mobile visible-light angle-of-arrival (AoA) sensing and scalable constrained optimization. It reconstructs relative locations of all individuals and dispatches individualized timed pixels to each one so that they can do their part in the overall visualization. We evaluate CaaS with extensive experiments under diverse reality settings as well as under synthetic workloads scaling up to tens of thousands of people. We deploy CaaS to 49 participants so that they successfully perform a collective visualization cheering up MobiSys.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {121–135},
numpages = {15},
keywords = {mobile-crowd service, collective visualization, card stunt, visual light communication, relative localization, optimization},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081352,
author = {Wei, Yu-Lin and Huang, Chang-Jung and Tsai, Hsin-Mu and Lin, Kate Ching-Ju},
title = {CELLI: Indoor Positioning Using Polarized Sweeping Light Beams},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081352},
doi = {10.1145/3081333.3081352},
abstract = {Existing visible light positioning (VLP) systems leverage the high image resolution of a receiving camera to support high positioning accuracy. However, power-hungry cameras might not always be applicable for many scenarios, such as smart factories, in which small objects require to be accurately localized and tracked. In this paper, we introduce CELLI, an indoor VLP system that only uses a single luminary as the transmitter and requires only a simple light sensor to achieve an extremely high accuracy with centimeter-level error. The key idea is to provide the spatial resolution capability from the transmitter instead of the receiver, so that the complexity of the receiver can be minimized. In particular, a small LCD is installed at the transmitter to project a large number of narrow and interference-free polarized light beams to different spatial cells. A receiving light sensor identifies its located cell by detecting the unique polarization-modulated signals projected to that cell. CELLI further incorporates a number of novel designs to overcome the technical challenges such as reducing the positioning latency, which is typically limited by the long optical response time of an LCD, and transforming a cell coordinate to the global 3D position using only a single light. We have prototyped our design using off-the-shelf optical and electrical components, and experimentally shown that CELLI achieves a median 3D positioning error less than 11.8 cm and a median 2D positioning error to less than 2.7 cm.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {136–147},
numpages = {12},
keywords = {visible light positioning, indoor positioning, polarized},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089292,
author = {Kudo, Koki and Sugimoto, Masanori and Akiyama, Takayuki and Hashizume, Hiromichi},
title = {Poster: Multicamera Synchronization for Smartphones Using Optimally Modulated Illuminations},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089292},
doi = {10.1145/3081333.3089292},
abstract = {The paper describes a rapid and accurate time-synchronization technique for smartphones using their built-in cameras and its preliminary evaluations for application development.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {148},
numpages = {1},
keywords = {smartphone, LED illumination, camera synchronization},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089293,
author = {Hong, Shuangxi and Liu, Chuanchang and Ren, Bingfei and Chen, Junliang},
title = {Poster: Sdguard: An Android Application Implementing Privacy Protection and Ransomware Detection},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089293},
doi = {10.1145/3081333.3089293},
abstract = {Currently, the smartphone has become an essential communication and amusement tool, which has strong computing power and a variety of functions. Especially, the market share of smartphone with android system account for 84% in 2016[1]. Under android system, a large of privacy data (e.g. photos or videos) are stored in external storage (emulated Sdcard storage), which can be accessed by installed apps. This not only results in privacy leakage but also incurs ransomware attack[2] (e.g. simplocker). Therefore, we present Sdguard, an app, can implement fine-grain permission control based on Linux DAC mechanism and detect ransomware which encrypts content of file stored in external storage or lock user screen. To install Sdguard app, we need to ensure that the smartphone has been rooted and use FUSE filesystem on external storage. During installing, sdcard daemon of android (i.e. FUSE daemon) is replaced by our customized sdcard daemon. After rebooting system, the customized daemon is loaded, and each component of Sdguard is running.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {149},
numpages = {1},
keywords = {ransomware, fuse filesystem, permission control, android system},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089294,
author = {Feng, Yimeng and Cheng, Bo and Zhao, Shuai and Zhai, Zhongyi and Wang, Zhaoning and Niu, Meng and Chen, Junliang},
title = {Poster: MobiTemplate: A Template-Based Rapid Cross-Platform Mobile Application Development Environment},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089294},
doi = {10.1145/3081333.3089294},
abstract = {Customizable mobile services are usually expressed with complex services composed of different atomic services. Fine-grained atomic mobile services are not so convenient for end users to reuse. Considering that in identical or similar service domains, a great deal of the business logics and functions are reusable within the scope. So we present a template-based framework to allow reuse of services and to achieve rapid mobile application development. The reusable fine-grained service logics and functions are encapsulated into comparatively coarse-grained templates, from which the designers can create the personalized composite services and edit the templates efficiently.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {150},
numpages = {1},
keywords = {mobile application development environment, cross-platform mobile application development, template based service creation, rapid mobile application development},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089295,
author = {Lee, Chulju and Kang, Kyungtae},
title = {Poster: Mobile Power Management Using FreeRTOS-Based Uninterruptable Generator Supply},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089295},
doi = {10.1145/3081333.3089295},
abstract = {Current designs of battery-powered uninterruptible power supplies only provide power for a short time, and offer few control options. We combined a compact synchronous generator with a battery with 10% of the capacity of a UPS of the same rating to produce an uninterruptible generator supply (UGS). The controller of this UGS runs FreeRTOS, which enables it to respond quickly to a power outage. A wifi module provides connectivity to a web server for real-time monitoring and management on a remote PC or cellphone.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {151},
numpages = {1},
keywords = {UGS, mobile power management, freertos},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089296,
author = {He, Liang and Tung, Yu-Chih and Shin, Kang G.},
title = {Poster: Charge My Phone As I Instruct},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089296},
doi = {10.1145/3081333.3089296},
abstract = {Charging mobile devices fast alleviates users' impatience in waiting for their devices to be charged. So, fast charging has been the focus of both industry and academia, developing and deploying various technologies, such as Quick Charge by Qualcomm, TurboPower by Motorola, Flash Charge by OPPO, etc. Fast charging, unfortunately, accelerates the capacity fading of device battery because it follows the Constant Current, Constant Voltage (CCCV) charge principle without considering the behavior of how users charge their devices. CCCV charging principle is a two-phase charging process consisting of (i) Constant-Current Charge (CC-Chg) and (ii) Constant-Voltage Charge (CV-Chg) [2] where CV-Chg is usually triggered at the end of charging (e.g., 80-100%) to stabilize the battery condition. However, fast charging technologies are agnostic of users' available charging time, resulting in premature termination of the planned charging if users only have limited time. This, in turn, leads to an incomplete CV-Chg phase or even skipping it completely. From our empirical measurements, we discovered that CV-Chg relaxes the batteries and slows down their capacity fading by up to 80% [1] incomplete CV-Chg shortens the battery life significantly over time!},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {152},
numpages = {1},
keywords = {interactive charging},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089297,
author = {Niu, Meng and Cheng, Bo and Zhai, Zhongyi and Feng, Yimeng and Chen, Junliang},
title = {Poster: Docker-Based Self-Organizing IoT Services Architecture for Smarthome},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089297},
doi = {10.1145/3081333.3089297},
abstract = {Internet of Things(IoT) was first coined in 1999 by Kevin Ashton. However with the technologies advancement, it seems that intelligent devices will invisibly be embedded in our life in few years. Enormous amounts of data need be exchanged every seconds. It calls for a seamless effect and easily interpretable communicating architecture. The research proposal will try to address some challenges and possible path in IoT enabled smarthome. It focuses primarily on two categories. Firstly, devices in IoT field is always distributed. So, there is a distributed IoT services architecture instead of traditional control-center solution. However, those devices are also limited in a certain area (such as a home local network). In order to reduce delay and burden, those distributed devices collect context information though a self-organizing broadcast network, and determine their next action based on that context data. Secondly, using Docker (a lightweight hardware-agnostic and platform-agnostic container) to package services. In our smarthome network, IoT services are distributed across different home electronics. Docker shields all the differences, so that we can quickly deploy and update module in the smarthome network after purchasing new electronics.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {153},
numpages = {1},
keywords = {internet of thing, IoT service, self-organizing, docker},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089298,
author = {Liu, Xing and Yao, Yunsheng and Qian, Feng},
title = {Poster: Improve Push Notification on Smartwatches},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089298},
doi = {10.1145/3081333.3089298},
abstract = {Receiving push notifications is one of the key features of smartwatches. In our recent measurement study involving 27 smartwatch users [1], we found that push notifications are used by more than 200 applications, dominated by instant messaging, emails, social media, etc. In this work, we propose a suite of methods to optimize the performance, energy efficiency, and usability of smartwatch push notifications, which have several salient features distinguishing them from regular notifications received on a smartphone: requiring heavy phonewatch cooperation, being delivered over short-range Bluetooth link, and incurring non-trivial energy consumption on watches with very limited battery capacity. Considering these factors, our proposed work focuses on four aspects as elaborated.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {154},
numpages = {1},
keywords = {smartwatch, push notification},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089299,
author = {Jeon, Kyungho and Chandrashekhara, Sharath and Dantu, Karthik and Ko, Steven Y.},
title = {Poster: Mobile Photo Data Management as a Platform Service},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089299},
doi = {10.1145/3081333.3089299},
abstract = {This poster presents Pixelsior, a new mobile platform service for photo data management in mobile apps.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {155},
numpages = {1},
keywords = {photo, pixelsior, android, image data, mobile},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089300,
author = {Park, Yongtae and Kuk, Seungho},
title = {Poster: Towards Quick Angular Check to Rebuff Forged Position Attacks in Vehicular Communication},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089300},
doi = {10.1145/3081333.3089300},
abstract = {Although Wireless Access in Vehicular Environment (WAVE) will be legally enforced from 2020 after the recent move by the U.S. Government [1], there is still an unresolved security issue. It is data plausibility, which is not addressed in any standard that comprises the WAVE framework. In particular, an attacker may forge false position values in safety beacons in order to cause unsafe response from startled receiving vehicles. The data plausibility is a longstanding issue for which various approaches based on sensor fusion, behavior analysis and communication constraints have been proposed. However, none of these completely solve the problem.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {156},
numpages = {1},
keywords = {vehicular communication},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089301,
author = {Kim, Taeho and Han, Wongoo and Park, Yongtae},
title = {Poster: Visual Cue-Based VRU Protection on Smartphones},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089301},
doi = {10.1145/3081333.3089301},
abstract = {As autonomous vehicles loom as reality, and the vehicle communication starts to be enforced by law from 2020, protecting vulnerable road users (VRUs) using vehicle communication is receiving attention. The current vehicle-to-pedestrian (V2P) communication as stipulated by the standards such as SAE J2735 implies that it is the vehicles that take the responsibility for VRU protection. User devices are essentially beacons that transmit Personal Safety Messages (PSMs), and upon receiving PSMs, the drivers (or autonomous vehicles) take necessary measures to protect them. We, however, believe that the road users also need information about nearby vehicles to protect themselves from dangerous situations. Using other technologies than the standard Dedicated Short Range Communication (DSRC), there have been existing works for VRU protection. They use Wi-Fi or Wi-Fi Direct as replacements of DSRC. An automaker tested DSRC for VRU protection, but no technical detail has been presented. An important issue with the existing VRU protection proposals is that they are fraught with false alarms, which lowers the utility of the whole idea. Although one can come up with a highly precise collision prediction model, any such model will generate a huge number of false alarms, especially in urban environments. For example, if a pedestrian walks along a sidewalk well protected from the driveway, all passing vehicles will generate an alert to the pedestrian and vice versa. So our approach instead provides intuitive visual cues to the smartphone user looking at the screen, so that they can use their discretion to determine the level of danger for themselves.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {157},
numpages = {1},
keywords = {vehicle-to-everything (V2X) communication, smartphone, vulnerable road user, visual cue},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089302,
author = {Lee, Jaemyoun and Kang, Kyungtae},
title = {Poster: A Lightweight Live Migration Platform with Container-Based Virtualization for System Resilience},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089302},
doi = {10.1145/3081333.3089302},
abstract = {When integrated with push notifications, a live migration function can be used to ensure that systems have a high reliability in cases of hardware failures. However, the dependencies for a large range of hardware devices need to be addressed before realizing emergency live migration. Our platform introduces container-based light virtualization and an automated build function to isolate an application so that it can be deployed on different devices such as Edison, Raspberry Pi model B, BeagleBone Black, and Odroid XU3.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {158},
numpages = {1},
keywords = {live migration, container, virtualization, system resilience},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089303,
author = {Guner, Kemal and Kosar, Tevfik},
title = {Poster: Application-Layer Optimization of Performance vs Energy in Mobile Network I/O},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089303},
doi = {10.1145/3081333.3089303},
abstract = {The number of smartphone users globally has already exceeded 2 Billion, and this number is expected to reach 3 Billion by 2020 [2]. It is also estimated that smartphone mobile data traffic (cellular + WiFi) will reach 370 Exabytes per year by that time, exceeding PC Internet traffic the first time in the history [4].An average smartphone consumes between 300 -- 1200 milliwatts power [1] depending on the type of applications it is running, and most of the energy in smartphone applications is spent for networked I/O. During an active data transfer, the cellular (i.e., GSM) and WiFi components of a smartphone consume more power than its CPU, RAM, and even LCD+graphics card at the highest brightness level [3,1]. Although the mobile data traffic and the amount of energy spent for it increase at a very fast pace, the battery capacities of smartphones do not increase at the same rate.In this work, we analyze the effects of different application layer data transfer protocol parameters (such as the number of parallel data streams per file, the level of concurrent file transfers, and the I/O request size) on mobile data transfer throughput and energy consumption.Figure 1 shows the achieved end-to-end throughput, total energy consumption, and the change in instantaneous power consumption during a wide-area data transfer with increased concurrency level. This figure presents the break point for the throughput versus energy consumption trade-off very well. As long as the energy gain due to the decreased transfer time is more than the loss due to the increased instantaneous power consumption, then we save energy at this device while increasing the throughput. But this is not always the case. We observe that although the throughput continues to increase up to a certain concurrency level, the total energy consumption does not continue to decrease, instead comes to a balance and starts increasing again. The main reason for this is the server and network components are typically not energy proportional.When used wisely, these parameters have a potential to improve the end-to-end data transfer performance and decrease total energy consumption at a great extent, but improper use of these parameters can also hurt the performance of the data transfers due to increased load at the end-systems and congested links in the network. For this reason, it is crucial to find the best combination for these parameters with the least intrusion and overhead to the system resource utilization and power consumption.Our contributions within this work are the following: (1) To the best of our knowledge, we are first to provide an in depth analysis of the effects of application layer data transfer protocol parameters on the energy consumption of mobile phones. (2) We show that significant energy savings can be achieved with application-layer solutions at the mobile systems during data transfer with no or minimal performance penalty. (3) We also show that, in many cases, performance increase and energy savings can be achieved simultaneously.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {159},
numpages = {1},
keywords = {energy efficiency on smartphones, protocol tuning, energy-aware mobile data transfers, mobile throughput optimization, big-data},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089304,
author = {Liu, Rui and Cornelius, Cory and Rawassizadeh, Reza and Peterson, Ron and Kotz, David},
title = {Poster: Vocal Resonance as a Passive Biometric},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089304},
doi = {10.1145/3081333.3089304},
abstract = {With continuing advances in the development of low-power electronics, including sensors and actuators, we anticipate a rapid expansion of pervasive computing. Wearable devices, in particular, require new modes for interaction -- many have no keyboard or touchscreen. In this work, we focus on user authentication on wearable devices. For an entertainment device, such as a VR headset, it can recognize the user and load the right game profile or music playlist. For a house climate-control system, it can adjust the environment to the wearer's preference. Most compellingly, for a health-monitoring device, it can label the sensor data with the correct identity so that the data can be stored in the correct health record. (A mix-up of sensor data could lead to incorrect decisions, with harm to the patient.) Because not all devices are personal devices -- my phone, your fitness sensor -- many devices will need to automatically recognize their wearer. They may have no interface for user identification (or PIN or password for authentication). Thus, we need a simple, wearable biometric technique to identify the user -- which could be embedded in one authentication device that shares the identity with a body-area network of other devices (earlier confirmed to be on the same body). This device should be trained once, for each user that might wear it, but thenceforth be completely automatic. Although a wristband could use a physiological biometric to recognize its wearer; we seek an alternative biometric, notably, one that might work for devices mounted on the head, neck, or chest.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {160},
numpages = {1},
keywords = {biometrics, authentication},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089305,
author = {Soltanaghaei, Elahe and Kalyanaraman, Avinash and Whitehouse, Kamin},
title = {Poster: Occupancy State Detection Using WiFi Signals},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089305},
doi = {10.1145/3081333.3089305},
abstract = {A large amount of energy could be saved by detecting home occupancy and automatically controlling the lights, HVAC, water heating, and other mechanical systems. Existing systems rely on motion information, which usually fail to detect occupied rooms with stationary people. In this project, we study the possibility of converting commodity WiFi access points to occupancy sensors by exploiting multipath reflections as individual spatial sensors. The proposed method measures fine-grained distortions caused by human body on phase and amplitude of WiFi signals. Our initial results suggest that formulating WiFi parameters into angle of arrival provides a more sensitive metric to measure occupancy.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {161},
numpages = {1},
keywords = {CSI, WiFi, occupancy detection, multipath propagation},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089306,
author = {Hamatani, Takashi and Elhamshary, Moustafa and Uchiyama, Akira and Higashino, Teruo},
title = {Poster: Smartwatch Knows How Much You Drink},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089306},
doi = {10.1145/3081333.3089306},
abstract = {Water accounts for about 60% of the human body, and when the body loses it (e.g., through urine, sweat, etc.) in higher rate than its intake rate (through drinking), dehydration symptoms occur. The dehydration causes many severe health problems like organ and cognitive impairment. Therefore, it is critical for the human to drink water in a sustained manner to avoid dehydration. To prevent humans from dehydration, continuous day-scale tracking of the water intake is needed. In this paper, we propose an unobtrusive method to recognize the drinking activity as well as estimate the water intake amount in milliliter scale by leveraging smartwatches. Our basic idea is to track the arm motion and discriminate the drinking activities from the similar hand-based motions like food intake, phone calls, etc. Thereafter, we estimate the water intake amount from the drinking duration.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {162},
numpages = {1},
keywords = {water intake, activity recognition, wearable sensor, hand gesture},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089307,
author = {Hao, Pengzhan and Bai, Yongshu and Zhang, Xin and Zhang, Yifan},
title = {Poster: EPS: Edge-Hosted Personal Services for Mobile Users},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089307},
doi = {10.1145/3081333.3089307},
abstract = {Being powered by battery and the reliance on expensive cellular data while users are on the move are holding smart mobile devices from being widely used in those long-lasted, computation-intensive, or highly network-reliant usage scenarios. In the meantime, more and more mobile workloads and optimizations now rely on the cloud, such as mobile cloud offloading, cloud-based mobile web optimization, and cloud-based network traffic redundancy reduction. However, it is hard to perform large-scale and personalized support or optimization for mobile workloads without significant computation resource increase on the cloud, as well as higher bandwidth requirement on the networks. We target solving the above two problems by enabling edge-hosed personalized services (EPS for short). The idea of EPS is twofold. One is enabling developer-customizable and power-and-traffic-efficient network communication on the "last-hop" communication between mobile devices and the network edge. The other is distributing cloud services for mobile workloads to network edge, so that they can be done on a personalized basis, while enjoying much lower communication latency to/from mobile devices.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {163},
numpages = {1},
keywords = {mobile devices, network bandwdith, edge computing},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089308,
author = {Afroze, Syeda Farzia and Shezan, Faysal Hossain and Sharmin, Sadia},
title = {Poster: HeartFit: An Intuitive Smartphone Application for Well-Being of Hypertensive Patients},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089308},
doi = {10.1145/3081333.3089308},
abstract = {Hypertension is the single most significant risk factor for heart disease, stroke and kidney disease. The key causes of hypertension can be directly linked to the lifestyle of the patient, including age, family history, smoking, obesity etc. Our work consists of an interactive mobile application that acquires these lifestyle information and use several recommendation techniques to warn and guide the user towards well-being. So far, this is one of the earliest approaches in this domain for a developing country like Bangladesh.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {164},
numpages = {1},
keywords = {m-Health, human computer interaction, hypertension, recommendation system},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089309,
author = {Nair, Bhavana B. and Rao, Sethuraman N.},
title = {Poster: Flood Monitoring Using Computer Vision},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089309},
doi = {10.1145/3081333.3089309},
abstract = {Urban floods have become a constant threat to human life and property. Also, high resolution cameras in smart phones have become ubiquitous. This work involves using Computer Vision algorithms to estimate the depth of flooding based on images taken by the general public which are geo-tagged and time-stamped. This approach will help in the implementation of effective and timely urban flood relief and management. This data can also be used to assess the effectiveness of preventive measures taken in the past and to plan remedial measures in the future.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {165},
numpages = {1},
keywords = {computer vision, flood monitoring, human segmentation, face detection, gender classification, deep learning},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089310,
author = {Popleteev, Andrei},
title = {Poster: Impact of Ground Truth Errors on Wi-Fi Localization Accuracy},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089310},
doi = {10.1145/3081333.3089310},
abstract = {This study investigates the impact of small ground truth (GT) errors on indoor positioning systems based on Wi-Fi fingerprinting. The results demonstrate that even centimeter-scale GT deviations cause severe degradation of measured localization accuracy.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {166},
numpages = {1},
keywords = {small-scale fading, indoor localization, fingerprinting, RSS, ground truth, performance evaluation, WLAN},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089311,
author = {Moravapalle, Uma Parthavi and Sanadhya, Shruti and Tsao, Cheng-Lin and Sivakumar, Raghupathy},
title = {Poster: <i>Observe. Patternize. Mimic.</i>: Leveraging Patterns in Mobile-User Behavior for Enterprise Applications},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089311},
doi = {10.1145/3081333.3089311},
abstract = {Application Mobilization, or the ability of an enterprise employee to rely on mobile devices such as smartphones and tablets, to continue to perform business workflows even when mobile, is seen as a game changer to improve productivity. However, the practical adoption of enterprise mobility is very much in its in fancy, and seemingly has barriers. We posit that these barriers include heavy user-burden in accomplishing tasks (e.g. number of actions required to execute a workflow), high cost of mobile access (e.g. latency for content fetching), and irrelevance of available mobile functions (e.g. mobile app defeaturization done inappropriately).The novelty of our research is in a unified observe-patternize-mimic paradigm we explore to address these barriers, based on a simple question: could patterns in user-behavior be learned, and leveraged for reducing user-burden? If patterns are discovered, then we show that intelligent mimicking of these patterns at appropriate junctures can considerably relieve the mobile user burden. We motivate this paradigm through three application scenarios representing read, write, and act usage modalities.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {167},
numpages = {1},
keywords = {patterns, user-behavior, enterprise applications, redundancy},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089312,
author = {Yan, Yin and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
title = {Poster: RTDroid: A Real-Time Solution with Android},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089312},
doi = {10.1145/3081333.3089312},
abstract = {Since the introduction of the smartphone, mobile computing has become pervasive in our society. Meanwhile, Mobile devices have evolved far beyond the stereotypical personal devices and been employed in various traditional real-time embedded domains. Of the currently available mobile systems, Android has seen the most widespread deployment outside of the consumer electronics market. Its open source nature has prompted its ubiquitous adoption in sensing, medical, robotics, and autopilot applications. However, it is not surprising that Android does not provide any real-time guarantee since it is designed as a mobile system and optimised for mobility, user experience, and energy efficiency. Although there has been much interest in adopting Android in real-time contexts, surprisingly little work has been done to examine the suitability of Android for real-time systems. Existing work only provides solutions to traditional problems, including real-time garbage collection at the virtual machine layer, real-time OS scheduling and resource management. While it is critical to address these issues, it is by no means sufficient. After all, Android is a vast system that is more than a Java virtual machine and a kernel.Our work examines the internals of Android, the Android programming model, libraries and core systems services. We discuss the implications and challenges of adapting Android constructs and core system services for real-time and present a solution for each, name RTDroid, as a whole system. It is unique in that it redesigns Android's internal components, replaces Android's Dalvik/ART with a real-time Java virtual machine, FijiVM, and leverages off-the-shelf real-time OSes.RTDroid also provides an event-driven programming model for the development of real-time applications. To retain a familiar style of Android application, we make a number of changes to the Android abstractions and how they interact with the underlying system as well as each other. We aim to leave legacy Android code unaffected and expose real-time features to components which have timeliness requirements. More specifically, Our programming model consist of four parts: 1) real-time constructs for real-time expressiveness, 2) a real-time extension to Android's application manifest for the real-time configuration, 3) real-time communication channels that enable construct interactions with real-time semantics, 4) pause-less memory management with scoped memory.To validate the predictability of RTDroid's implementation, we firstly report a number of micro-benchmark results with RTDroid basic constructs. Then, we demonstrate three real-world applications implemented in RTDroid and provide statistic results. Our results illustrate that, at least in these use-cases, the modified platform delivers significantly better time predictability than stock Android and reduces the code complexity as compared to the traditional real-time programming paradigm, RTSJ.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {168},
numpages = {1},
keywords = {RTDroid, android},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089313,
author = {Zhang, Xin and Bai, Yongshu and Hao, Pengzhan and Zhang, Yifan},
title = {Poster: Securing Device Inputs for Smartphones Using Hypervisor Based Approach},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089313},
doi = {10.1145/3081333.3089313},
abstract = {Smartphone device inputs, such as inputs from touchscreen, sensors, and GPS, carry sensitive user information, but are vulnerable to passive and active attacks. We present our ongoing design and implementation of SDIF, a Secure Device Input Framework for smartphones. The core components of SDIF are a small and dedicated bare-metal hypervisor built using ARM hardware virtualization support and a user-space sandbox framework. They collectively ensures SDIF's support for unmodified OSes and apps. SDIF guarantees the secure device inputs from hardware to target applications with two key designs. The first is a design of a secure path for input data to be delivered from input device drivers to target applications. The second is a design of trusted device data reading, which ensures input data generated by hardware is faithfully put to device driver memory.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {169},
numpages = {1},
keywords = {device inputs, hypervisor, mobile device, virtualization},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089314,
author = {Hardin, Taylor and Hester, Josiah and Proctor, Patrick and Sorber, Jacob and Kotz, David},
title = {Poster: Memory Protection in Ultra-Low-Power Multi-Application Wearables},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089314},
doi = {10.1145/3081333.3089314},
abstract = {An increasing number of wearable devices support the execution of multiple third-party applications, increasing the functionality and flexibility of these devices. These multi-application, multi-tenant devices provide users with more options, and application developers with a standard platform. Typical ultra-low-power wearable devices, however, lack the type of hardware memory protection mechanisms~-- such as Memory Management Units (MMU)~-- needed to safely separate applications. At best, they provide a Memory Protection Unit (MPU), which allows the user to configure read/write/execute permissions for a few distinct regions of memory. At worst, no hardware memory protection is provided. MPU capabilities vary across hardware platforms, with many shortcomings: (1)~the MPU may only support a few distinct memory regions (fewer than one per application), (2)~the MPU may not protect all regions of memory, like hardware registers, and (3)~MPU protection boundary rules can be arcane, because they depend on opaque hardware implementations. Our key observation is that by supplementing a limited segment MPU with runtime checks, and using compile-time static analysis to explicitly layout applications in memory, we can guarantee application isolation (sandboxing) even on these limited MPUs, with lower overhead than software-only solutions.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {170},
numpages = {1},
keywords = {memory protection, wearables},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089315,
author = {Shen, Feng and Del Vecchio, Justin and Mohaisen, Aziz and Ko, Steven Y. and Ziarek, Lukasz},
title = {Poster: Android Malware Detection Using Multi-Flows and API Patterns},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089315},
doi = {10.1145/3081333.3089315},
abstract = {This paper proposes a new technique for detecting mobile malware based on information flow analysis. Our approach focuses on the structure of information flows we gather in our analysis, and the patterns of behavior present in information flows. Our analysis not only gathers simple flows that have a single source and a single sink, but also Multi-Flows that either start from a single source and flow to multiple sinks, or start from multiple sources and flow to a single sink. This analysis captures more complex behavior that both recent malware and recent benign applications exhibit. We leverage N-gram analysis to understand both unique and common behavioral patterns present in Multi-Flows. Our tool leverages N-gram analysis over sequences of API calls that occur along control flow paths in Multi-Flows to precisely analyze Multi-Flows with respect to app behavior.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {171},
numpages = {1},
keywords = {information flow analysis, malware detection, multi-flow, security},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089316,
author = {Xiong, Wei and Zheleva, Mariya},
title = {Poster: Camera Images Offloading in Low-Resource Wireless Networks},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089316},
doi = {10.1145/3081333.3089316},
abstract = {Camera snapshot images are widely used in IoT applications. However, when the applications are deployed in rural areas or poorly-performing networks, the images offloading usually exhausts the limited network resources. While we can certainly revamp the network links, we can also optimize the payload at the same time. In this paper, we propose a middlebox system design that exploits the patterns of similarity between consecutive camera snapshots to alleviate the network load. Our preliminary results show that despite of small errors introduced in the images, the amount of reduced payloads could be a valuable choice to alleviate poorly performing networks.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {172},
numpages = {1},
keywords = {camera, wireless networks},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089317,
author = {Lee, HyunJong and Flinn, Jason},
title = {Poster: Redundancy Aided Vehicular Networking},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089317},
doi = {10.1145/3081333.3089317},
abstract = {Vehicular applications are increasingly connected to cloud services. For example, route planning, gas price applications, and Siri-like personal assistants all respond to user queries based in part on cloud processing. Network communication thus is often a substantial component of user-perceived latency in vehicular applications. Current vehicular computing platforms typically connect to the cloud using a single cellular network provider. Network conditions can change rapidly as a vehicle moves due to geographical variation in coverage, radio shadows, and differing traffic density. Such variation is often exacerbated by connection re-establishment after an interface has entered a sleep state. Thus, vehicular applications can often appear unresponsive due to high wireless network latency. Even worse, the responsiveness is unpredictable; high tail latency makes some user interactions take longer, even when most interactions complete in an acceptable amount of time. This unpredictability is especially worrisome in a vehicular environment, in which occasional unexpected performance anomalies distract the driver of the vehicle.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {173},
numpages = {1},
keywords = {vehicular networking, connected vehicle, redundancy, autonomous vehicle, raven},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089318,
author = {Jian, Yubing and Lall, Shruti and Sivakumar, Raghupathy},
title = {Poster: <i>Twirl:</i>: On the Benefits of Adapting Orientation of a WiFi Access-Point},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089318},
doi = {10.1145/3081333.3089318},
abstract = {The position of a wireless access point (AP) in wireless networks has been found to have a considerable impact on the overall network performance in indoor scenarios. Recent work has investigated the impact of the AP's location on the received signal strength of clients [1], and has shown that a 1:7x throughput improvement can be achieved by simply moving the AP in a 2ft. x 2ft. region. The benefits of small scale AP mobility is chiefly caused by mitigating multipath effects. In fact, the multipath effect has a significant impact on network performance and can be dramatically altered even with mere centimeter level movement of a Tx or a Rx. In this work, we investigate how network throughput performance can be improved if the AP is able to adapt its orientation. We consider two types of orientation changes - that of the AP's base platform (base orientation), and that of its antennas (antenna orientation). We show using experimental analysis that network throughput performance can be improved 1:8x by simply adapting AP's orientation.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {174},
numpages = {1},
keywords = {self-positioning AP, antenna orientation, base orientation},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089319,
author = {Tran, Huy and Pandey, Santosh and Bulusu, Nirupama},
title = {Poster: Online Map Matching for Passive Indoor Positioning Systems},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089319},
doi = {10.1145/3081333.3089319},
abstract = {Passive indoor positioning systems (PIPS) enable non-invasive tracking of mobile devices (e.g., smartphones, Wi-Fi tags) using enterprise network infrastructure. This empowers operators of large airports and retail facilities to optimize cost-intensive resource allocation as well as to provide location-based services to their customers such as geo-fencing and proximity marketing. However, existing PIPS often generate noisy location estimates due to unpredictable interference and attenuation of wireless signals in indoor environments. To address this problem, we propose a novel map matching approach that uses a floor map to constrain location estimates to possible paths a mobile user can take.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {175},
numpages = {1},
keywords = {map matching, passive indoor positioning system, hidden Markov model},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089320,
author = {Bi, Shengjie and Davernport, Ellen and Gong, Jun and Peterson, Ronald and Skinner, Joseph and Storer, Kevin and Wang, Tao and Caine, Kelly and Halter, Ryan and Kotz, David and Odame, Kofi and Sorber, Jacob and Yang, Xing-Dong},
title = {Poster: Auracle: A Wearable Device for Detecting and Monitoring Eating Behavior},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089320},
doi = {10.1145/3081333.3089320},
abstract = {Chronic disease is one of the most pressing health challenges facing the United States (and an increasing set of other countries). The onset or progression of diseases like obesity, diabetes, and metabolic disorder are strongly related to eating behavior, and scientists are still trying to fully understand the complex mixture of diet, exercise, genetics, sociocultural context, and physical environment that lead to these diseases. Health science, however, has no effective means for automatically measuring eating behavior in free-living conditions. The Auracle aims to be a wearable earpiece that detects eating behavior, to be fielded by health-science researchers in their efforts to study eating behavior and ultimately to develop interventions useful to individuals striving to address chronic disease related to eating.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {176},
numpages = {1},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089321,
author = {Agarwal, Mohit and Sivakumar, Raghupathy},
title = {Poster: <i>Characters vs. Words</i>: Observations on Command Design for Brain-Computer Interfaces},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089321},
doi = {10.1145/3081333.3089321},
abstract = {Brain-computer interfaces (BCIs) allow users to communicate to a nearby computing device (computer, smartphone, etc.) using thoughts or other covert actions that result in a detectable change in brain-waves. Consider a BCI command to be a word consisting of a sequence of characters. Each character is a thought or action that can be reliably detected through brain waves. For this work, we specifically consider eye-blinks as the user action of interest. Eye-blinks are an interesting modality for BCI commands because of their easy detectability and naturalness (and hence covertness). It turns out that there is an interesting trade-off between the complexity of characters and the length of words. In this work, we perform a user-study to answer a simple, but important, question pertaining to eye-blinks based BCI command design: do users prefer shorter characters (and hence longer words) or shorter words (and hence longer characters) when performing commands?. We present a simple eye-blink language consisting of words and characters and use real user-experiments to study the aforementioned trade-off.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {177},
numpages = {1},
keywords = {brain-computer interfaces (BCIS), eye-blinks},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089322,
author = {Klingler, Florian and Pannu, Gurjashan Singh and Sommer, Christoph and Bloessl, Bastian and Dressler, Falko},
title = {Poster: Field Testing Vehicular Networks Using OpenC2X},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089322},
doi = {10.1145/3081333.3089322},
abstract = {We present OpenC2X, an Open Source approach to field testing of vehicular networking solutions. Field Operational Test (FOT) and real-world experimentation are becoming more relevant to our research community as well as to industry and regulation. Unfortunately, available commercial solutions make experimental modifications to the protocol stack time consuming or prohibit it completely. To overcome this limitation, we implemented the ETSI ITS-G5 stack on a standard embedded PC hardware and running Linux system. OpenC2X is the first complete Open Source experimentation and prototyping platform. Our system is fully interoperable to commercial solutions, yet easily extensible with new protocols and applications for vehicular networks.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {178},
numpages = {1},
keywords = {prototype, vehicular networking, field testing},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089323,
author = {Menuka, Nisal and Zhong, Lin},
title = {Poster: ARM Errata and Their Software Workarounds},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089323},
doi = {10.1145/3081333.3089323},
abstract = {Like software, hardware also has bugs. These bugs, or errata, can cause unexpected behaviors, reducing performance and causing malfunctions in the entire system. As there is no way to fix an erratum after hardware is deployed, its harmful effects are often mitigated by software workarounds, usually in low-level software such as operating system. The goal of our work is to ensure system correctness and security against the harmful effects of errata and their workarounds. The first step is to systematically understand them in the wild.In this poster, we present our early results from analyzing errata in the ARM Cortex-A family of microarchitecture, introduced by ARM itself, and their workarounds. We studied publicly available ARM errata documentations and examined source code of low-level software, namely Linux kernel, U-Boot and ARM Trusted firmware.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {179},
numpages = {1},
keywords = {software workarounds, ARM errata, types of errata fixes},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089324,
author = {Sasaki, Wataru and Obuchi, Mikio and Egashira, Kazuki and Isokawa, Naohiro and Furukawa, Yuki and Nishiyama, Yuuki and Okoshi, Tadashi and Nakazawa, Jin},
title = {Poster: Extensive Evaluation of Emotional Contagion on Smiling Selfies over Social Network},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089324},
doi = {10.1145/3081333.3089324},
abstract = {We propose "SmileWave", the first selfie social networking service to reveal the existence of emotional cognation through smiling selfies on the social network. We conducted multiple rounds of in-the-wild user studies with 86 cumulative total users for total duration of 5 weeks. Throughout the entire study, we confirmed the occurrence of smile-based emotional contagion over social network, not only in the momentary duration but in longer term period.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {180},
numpages = {1},
keywords = {emotional contagion, mobile sensing, social network},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089326,
author = {Lee, Jung-Hyun and Jun, So-Young and Park, So-Jung and Kim, Kang-Min and Lee, SangKeun},
title = {Demo: Mobile Contextual Advertising Platform Based on Tiny Text Intelligence},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089326},
doi = {10.1145/3081333.3089326},
abstract = {In-app advertising has become a significant source of revenue for mobile app. In order to improve the effectiveness of in-app ads, most ad networks focus on targeting a user based on the user's personal information collected from their ad library inside mobile apps and the global knowledge built from big data on ad servers. However, sharing user's sensitive information with the ad servers may raise privacy concerns. As opposed to targeting users, mobile contextual advertising seeks to target the app page a user is viewing. In this demo, we present a novel mobile contextual advertising platform, called MoCA, which is designed to improve the semantic relevance of in-app ads in a stand-alone, privacy-protecting manner on mobile devices. MoCA understands the semantics of app page and ads, and then matches semantically relevant ads to the page inside mobile devices. To the best of our knowledge, this is the first work to implement the mobile contextual advertising platform based on the semantic approach without resort to ad servers.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {181},
numpages = {1},
keywords = {in-app advertising, tiny text intelligence, mobile contextual advertising},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089327,
author = {Chandrashekhara, Sharath and Ki, Taeyeon and Jeon, Kyungho and Dantu, Karthik and Ko, Steven Y.},
title = {Demo: BlueMountain: An Architecture to Customize Data Management on Mobile Systems},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089327},
doi = {10.1145/3081333.3089327},
abstract = {BlueMountain is a system that enables building pluggable data management solutions which can be linked with any Android app at runtime, without requiring any modifications to the Android platform. BlueMountain simplifies the app development, provides flexibility to end users, and works with existing apps.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {182},
numpages = {1},
keywords = {mobile systems, bytecode instrumentation, data management},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089328,
author = {Nguyen, Anh and Nguyen, Duy and Nguyen, Nhan and Ashok, Ashwin and Nguyen, Binh and Pham, Bao and Vu, Tam},
title = {Demo: Fusing Mobile Sensors for Paper Keyboard On-the-Go},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089328},
doi = {10.1145/3081333.3089328},
abstract = {Using touchscreens has largely limited user inputs to small form-factor devices. To address this constraint, we explore a novel input mechanism, dubbed PaperKey, that enables users to interact with mobile devices by performing multi-finger typing gestures on a surface where the device is placed. Using acceleration signals on the device, PaperKey infers the user's type events and then leverages a vision based technique for detecting the exact typing locations on a paper keyboard layout. Compared to single audio, image, or vibration sensing, this work accurately localizes keystrokes with faster processing speed. Additionally, this mechanism keeps the mobility of devices by working without external sensors.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {183},
numpages = {1},
keywords = {vision-based localization, multi-finger typing, touching vibration, paper keyboard},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089329,
author = {Bang, Hyunwoong and Kim, Hyunsub and Lee, SangKeun},
title = {Demo: SigSocial: A Novel Social Media Aggregation Service Using a Tiny Text Intelligence},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089329},
doi = {10.1145/3081333.3089329},
abstract = {We present an entirely novel concept of retrieving social media data, called sigSocial. It integrates social media data of various sources, using a semantic classifier. Nowadays, people use multiple social media simultaneously, acquiring information with ease. However, accessing numerous services to reach different channels is bothersome. Also, the volume of information one can process is limited. Our aim is to reduce this burden, providing easiness and efficiency. In other words, we attempt to build a single service that integrates information from various platforms. The application has three main features. First, it enables users to explore multiple social media without accessing them separately. Second, it organizes information retrieved from social medias into well-defined classes. Finally, it works as a stand-alone application, the mechanism of which is internal to the device, not relying on any external servers or networks. This method respects user privacy, which has recently gained much attention.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {184},
numpages = {1},
keywords = {social media, semantic classification, tiny text intelligence},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089330,
author = {Ki, Taeyeon and Simeonov, Alexander and Park, Chang Min and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
title = {Demo: Fully Automated UI Testing System for Large-Scale Android Apps Using Multiple Devices},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089330},
doi = {10.1145/3081333.3089330},
abstract = {We demonstrate AutoClicker, a fully automated UI testing system for large-scale Android apps using multiple devices. It provides a way to quickly and easily verify that a large number of Android apps behave correctly at runtime in a repeatable manner.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {185},
numpages = {1},
keywords = {UI testing, autoclicker, test automation},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089331,
author = {Huynh, Loc N. and Balan, Rajesh Krishna and Lee, Youngki},
title = {Demo: DeepMon: Building Mobile GPU Deep Learning Models for Continuous Vision Applications},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089331},
doi = {10.1145/3081333.3089331},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {186},
numpages = {1},
keywords = {continuous vision, mobile GPU, deep learning, mobile sensing},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089332,
author = {Yoo, Chungkuk and Hwang, Inseok and Kang, Seungwoo and Kim, Myung-Chul and Kim, Seonghoon and Won, Daeyoung and Gu, Yu and Song, Junehwa},
title = {Demo: Card-Stunt as a Service: Empowering a Massively Packed Crowd for Instant Collective Expressiveness},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089332},
doi = {10.1145/3081333.3089332},
abstract = {Consider a massive crowd who gathered together to convey their common voice to public, e.g., supporters of a team sitting together in a stadium, people doing a candlelight vigil in a public square, and so on. Imagine that they hold up their smartphone displays which collectively compose a huge public screen; the crowd's messages are now shown big on the top of them. We present CaaS [3], a mobile service to realize such an instant, massive, collective visualization with commodity smartphones and cloud services. In this demo, we demonstrate the collective localization feature of CaaS so that the audience can watch a given pattern or symbol collectively displayed on top of arbitrarily positioned phones (See the video demo, https://goo.gl/GfsORc).},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {187},
numpages = {1},
keywords = {visible light communication, mobile-crowd service, relative localization, collective visualization, optimization, card stunt},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089333,
author = {H\"{a}nsel, Katrin and Haddadi, Hamed and Alomainy, Akram},
title = {Demo: AWSense: A Framework for Collecting Sensing Data from the Apple Watch},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089333},
doi = {10.1145/3081333.3089333},
abstract = {We present a framework - AWSense - for eased sensing data collection from an Apple Watch wearable device. The framework eases the access, transmission and export of sensing data from the device. This data comprises: heart rate, raw acceleration, and computed device motion. In our demo, we present sample applications built on top of this framework to show its capabilities, of real-time presentation and recording of the sensing data.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {188},
numpages = {1},
keywords = {wearable computing, sensing libraries},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089334,
author = {Roy, Nirupam and Hassanieh, Haitham and Roy Choudhury, Romit},
title = {Demo: Riding the Non-Linearities to Record Ultrasound with Smartphones},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089334},
doi = {10.1145/3081333.3089334},
abstract = {We demonstrate that high frequency ultrasonic sounds can be designed to become recordable by unmodified smartphone microphones, while remaining inaudible to humans. The core idea lies in exploiting nonlinearities in microphone hardware with a combination of ultrasound frequencies. These frequencies can be regulated to carry data bits, thereby enabling an acoustic (but inaudible) communication channel to today's microphones. Other applications include jamming spy microphones in the environment, live watermarking of music in a concert, and even acoustic Denial-of-Service (DoS) attacks.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {189},
numpages = {1},
keywords = {inaudible sound, acoustic denial of service, nonlinear acoustic, security, privacy, nonlinearity, acoustic, smartphone},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089335,
author = {Katevas, Kleomenis and Tokarchuk, Laurissa and Haddadi, Hamed and Clegg, Richard G. and Irfan, Muhammad},
title = {Demo: Detecting Group Formations Using IBeacon Technology},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089335},
doi = {10.1145/3081333.3089335},
abstract = {Researchers from different disciplines have examined crowd behavior in the past by employing a variety of methods including ethnographic studies, computer vision techniques and manual annotation based data analysis. However, because of the inherent difficulties in collecting, processing and analyzing the data, it is difficult to obtain large data sets for study. In this work we present a system for detecting stationary interactions inside crowds, depending entirely on the sensors available in a modern smartphone device such as Bluetooth Smart (BLE) and Accelerometer. By utilizing Apple's iBeaconTM implementation of Bluetooth Smart using SensingKit1, our open-source multi-platform mobile sensing framework [1], we are able to detect the proximity of users carrying a smartphone in their pocket. We then use an algorithm based on graph theory to predict group interactions inside the crowd. Previous work in this area has been limited to the detection of interactions between only two people and therefore our approach goes beyond current state of the art in its ability to detect group formations with more than two people involved. Our approach is particularly beneficial to the design and implementation of crowd behavior analytics, design of influence strategies, and algorithms for crowd reconfiguration.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {190},
numpages = {1},
keywords = {social network analysis, ble, rssi, social interactions, crowd sensing, group formations, ibeacon, mobile sensing},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089336,
author = {Park, Chang Min and Ki, Taeyeon and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
title = {Demo: Enabling Dynamic Gesture Mapping with UI Events},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089336},
doi = {10.1145/3081333.3089336},
abstract = {We demonstrate Gesto, a dynamic gesture mapping tool. It provides users to map any gesture to a certain UI event that the users need. Also, the mapping can be easily changed by users.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {191},
numpages = {1},
keywords = {dynamic gesture mapping, API, UI events},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089337,
author = {Xiong, Sijie and Zhu, Sujie and Ji, Yisheng and Jiang, Binyao and Tian, Xiaohua and Zheng, Xuesheng and Wang, Xinbing},
title = {Demo: IBlink: Smart Glasses for Facial Paralysis Patients},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089337},
doi = {10.1145/3081333.3089337},
abstract = {Facial paralysis is a disease caused by nerve damage, which can make patients lose facial movements. Facial paralysis patients usually have muscles on one side of the face noticeably droop, which seriously impacts the person's quality of life as shown in Fig. [skull]. Worse still, the eye on the affected side is unable to blink and will become dry and infected by debries, which can incur eye damage even blindness. To the best of scientists' knowledge, the paralysis is due to the pressure incurred by infection in the tunnel containing main trunk of facial nerves, where the tunnel is inside of the people's head termed as the Facial canal. In this demo, we present iBlink [1], a novel system to help paralysis patients to blink. Paralysis usually occurs in just one side of the face, and clinical trials show that electrical stimulation could trigger blink. Based on such observations, the basic idea of iBlink is to monitor the normal side of the face with a camera and stimulate the paralysed side, so that eye-movements of the both sides become symmetric.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {192},
numpages = {1},
keywords = {smart glasses, facial paralysis},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089338,
author = {Ki, Taeyeon and Simeonov, Alexander and Park, Chang Min and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
title = {Demo: Reptor: Enabling API Virtualization on Android for Platform Openness},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089338},
doi = {10.1145/3081333.3089338},
abstract = {We demonstrate Reptor, a bytecode instrumentation tool enabling API virtualization on Android. It provides a general way to alter functionality of platform APIs on Android. With Reptor, third-party developers can modify the behavior of platform APIs according to their needs. All modifications are completely at the app layer without modifying the underlying platform. This allows practical openness---third-party developers can easily distribute their modifications for a platform without the need to update the entire platform.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {193},
numpages = {1},
keywords = {API virtualization, android platform instrumentation, android app instrumentation, platform openness},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089339,
author = {Wei, Yu-Lin and Huang, Chang-Jung and Tsai, Hsin-Mu and Lin, Kate Ching-Ju},
title = {Demo: CELLI: Indoor Positioning Using Polarized Sweeping Light Beams},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089339},
doi = {10.1145/3081333.3089339},
abstract = {Indoor positioning enables location-based services for a wide range of commercial applications [4]. Existing visible light positioning (VLP) systems [5, 7] leverage the high image resolution of a receiving camera to support high positioning accuracy. However, power-hungry cameras are not desirable in many scenarios, e.g., smart factories, where small objects need to be accurately located and tracked. In this demo, we introduce CELLI, an indoor VLP system that only uses a single luminary as the transmitter and requires only a simple light sensor to achieve high accuracy with centimeter-level error. The key idea is to provide the spatial resolution capability from the transmitter instead of the receiver, so that the complexity of the receiver can be minimized. In particular, a small Liquid Crystal Display (LCD) is installed at the transmitter to project a large number of narrow and interference-free polarized light beams to different spatial cells. A receiving light sensor identifies its located cell by detecting the unique polarization-modulated signals projected to that cell, as shown in Fig. 1. CELLI further incorporates several novel designs to overcome the technical challenges such as reducing the positioning latency, which is typically limited by the long optical response time of an LCD, and transforming a cell coordinate to the global 3D position using only a single light. We have prototyped our design using off-the-shelf optical and electronic components, and experimentally shown that CELLI achieves a median 3D positioning error less than 12 cm and a median 2D error less than 2.7 cm.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {194},
numpages = {1},
keywords = {visible light positioning},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3089340,
author = {Ravindranath, Lenin and Philipose, Matthai and Bodik, Peter and Bahl, Paramvir},
title = {Demo: Live Video Stream Triggers},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3089340},
doi = {10.1145/3081333.3089340},
abstract = {Live streaming is an increasingly popular way to broadcast videos ranging from formal news channels to kitten cams to home security camera feeds. Live streaming marries the rich detail of video with the timeliness of live transmission and the ease of use of consumer cameras, thus promising to vastly increase the amount of detailed, up-to-the minute information available about the real world. The volume of potentially interesting footage brings up the question of how end-users can avoid being glued to one (or worse, many) streams of videos waiting for events of interest. In this demo, we present Lookout, a system that allows users to register standing queries, called triggers over live video streams. Lookout then notifies the user when events of interest to them occur in their streams of interest. For example, a user could point to a cat cam and write a trigger that sends a notification when the cat wakes up and starts moving. Users can also write triggers to look for certain news being covered in a live new channel, a gamer moving to a certain level in a Twitch stream, a stranger showing up in a outdoor surveillance camera, etc.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {195},
numpages = {1},
keywords = {video triggers, video queries, video indexing},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081475,
author = {Abramson, Norman},
title = {ALOHA to the Web},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081475},
doi = {10.1145/3081333.3081475},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {196},
numpages = {1},
keywords = {wireless, random access, networks, ALOHA},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3257286,
author = {Jamieson, Kyle},
title = {Session Details: PAPER SESSION 4: Security and Privacy I},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257286},
doi = {10.1145/3257286},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081346,
author = {Amiri Sani, Ardalan},
title = {SchrodinText: Strong Protection of Sensitive Textual Content of Mobile Applications},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081346},
doi = {10.1145/3081333.3081346},
abstract = {Many mobile applications deliver and show sensitive and private textual content to users including messages, social network posts, account information, and verification codes. All such textual content must only be displayed to the user but must be strongly protected from unauthorized access in the device. Unfortunately, this is not the case in mobile devices today: malware that can compromise the operating system, e.g., gain root or kernel privileges, can easily access textual content of other applications. In this paper, we present SchrodinText, a system solution for strongly protecting the confidentiality of application's selected UI textual content from a fully compromised operating system. SchrodinText leverages a novel security monitor based on two hardware features on modern ARM processors: virtualization hardware and TrustZone. Our key contribution is a set of novel techniques that allow the operating system to perform the text rendering without needing access to the text itself, hence minimizing the Trusted Computing Base (TCB). These techniques, collectively called oblivious rendering, enable the operating system to rasterize and lay out all the characters without access to the text; the monitor only resolves the right character glyphs onto the framebuffer observed by the user and protects them from the operating system, e.g., against DMA attacks. We present our prototype using an ARM Juno development board and Android operating system. We show that SchrodinText incurs noticeable overhead but that its performance is usable.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {197–210},
numpages = {14},
keywords = {virtualization, trustzone, mobile devices, text protection, UI safety},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081354,
author = {Nguyen, Phuc and Truong, Hoang and Ravindranathan, Mahesh and Nguyen, Anh and Han, Richard and Vu, Tam},
title = {Matthan: Drone Presence Detection by Identifying Physical Signatures in the Drone's RF Communication},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081354},
doi = {10.1145/3081333.3081354},
abstract = {Drones are increasingly flying in sensitive airspace where their presence may cause harm, such as near airports, forest fires, large crowded events, secure buildings, and even jails. This problem is likely to expand given the rapid proliferation of drones for commerce, monitoring, recreation, and other applications. A cost-effective detection system is needed to warn of the presence of drones in such cases. In this paper, we explore the feasibility of inexpensive RF-based detection of the presence of drones. We examine whether physical characteristics of the drone, such as body vibration and body shifting, can be detected in the wireless signal transmitted by drones during communication. We consider whether the received drone signals are uniquely differentiated from other mobile wireless phenomena such as cars equipped with Wi- Fi or humans carrying a mobile phone. The sensitivity of detection at distances of hundreds of meters as well as the accuracy of the overall detection system are evaluated using software defined radio (SDR) implementation.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {211–224},
numpages = {14},
keywords = {drone body shifting, drone body vibration, drone detection, RF sensing},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081361,
author = {Luo, Lannan and Zeng, Qiang and Cao, Chen and Chen, Kai and Liu, Jian and Liu, Limin and Gao, Neng and Yang, Min and Xing, Xinyu and Liu, Peng},
title = {System Service Call-Oriented Symbolic Execution of Android Framework with Applications to Vulnerability Discovery and Exploit Generation},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081361},
doi = {10.1145/3081333.3081361},
abstract = {Android Application Framework is an integral and foundational part of the Android system. Each of the 1.4 billion Android devices relies on the system services of Android Framework to manage applications and system resources. Given its critical role, a vulnerability in the framework can be exploited to launch large-scale cyber attacks and cause severe harms to user security and privacy. Recently, many vulnerabilities in Android Framework were exposed, showing that it is vulnerable and exploitable. However, most of the existing research has been limited to analyzing Android applications, while there are very few techniques and tools developed for analyzing Android Framework. In particular, to our knowledge, there is no previous work that analyzes the framework through symbolic execution, an approach that has proven to be very powerful for vulnerability discovery and exploit generation. We design and build the first system, Centaur, that enables symbolic execution of Android Framework. Due to some unique characteristics of the framework, such as its middleware nature and extraordinary complexity, many new challenges arise and are tackled in Centaur. In addition, we demonstrate how the system can be applied to discovering new vulnerability instances, which can be exploited by several recently uncovered attacks against the framework, and to generating PoC exploits.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {225–238},
numpages = {14},
keywords = {concolic execution, exploit generation, vulnerability discovery, symbolic execution, android framework},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3257287,
author = {Zhong, Lin},
title = {Session Details: PAPER SESSION 5: RF Sensing},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257287},
doi = {10.1145/3257287},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081364,
author = {Shangguan, Longfei and Zhou, Zimu and Jamieson, Kyle},
title = {Enabling Gesture-Based Interactions with Objects},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081364},
doi = {10.1145/3081333.3081364},
abstract = {Increasing numbers of everyday objects in libraries, stores and warehouses are instrumented with passive RFID tags, resulting in a ripe opportunity for gesture-based interactions with people. By a simple act of picking up and gesturing with an RFID-tagged object, users can send their opinions and sentiments about that object to the cloud. Prior work in RFID-based gesture tracking relies on multiple bulky and expensive antennas and readers to function, which incurs unacceptable infrastructure costs for large-scale ubiquitous deployment (over an entire warehouse or mall, for example) thus hindering practical adoption. In this paper, we propose Pantomime, the first RFID-based gesture recognition system that uses just a single antenna per geographical area of coverage. Our key insight is to replace the conventional multiple antenna single tag tracking framework with an equivalent multiple tag single antenna system. Through a novel tag coordination protocol and a lightweight tracking algorithm, Pantomime enables accurate gesture tracking that works for objects tagged with just two RFID tags. We implement a real-time prototype of Pantomime with commercial off-the-shelf (COTS) RFID readers and antennas. Extensive evaluations and real-world case studies in a classroom and a retail store demonstrate that Pantomime achieves comparable gesture tracking accuracy (87%) to state-of-the-art multi-antenna schemes (88%) at a minimal deployment cost.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {239–251},
numpages = {13},
keywords = {human-object interaction, tracking, rfid},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081340,
author = {Virmani, Aditya and Shahzad, Muhammad},
title = {Position and Orientation Agnostic Gesture Recognition Using WiFi},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081340},
doi = {10.1145/3081333.3081340},
abstract = {WiFi based gesture recognition systems have recently proliferated due to the ubiquitous availability of WiFi in almost every modern building. The key limitation of existing WiFi based gesture recognition systems is that they require the user to be in the same configuration (i.e., at the same position and in same orientation) when performing gestures at runtime as when providing training samples, which significantly restricts their practical usability. In this paper, we propose a WiFi based gesture recognition system, namely WiAG, which recognizes the gestures of the user irrespective of his/her configuration. The key idea behind WiAG is that it first requests the user to provide training samples for all gestures in only one configuration and then automatically generates virtual samples for all gestures in all possible configurations by applying our novel translation function on the training samples. Next, for each configuration, it generates a classification model using virtual samples corresponding to that configuration. To recognize gestures of a user at runtime, as soon as the user performs a gesture, WiAG first automatically estimates the configuration of the user and then evaluates the gesture against the classification model corresponding to that estimated configuration. Our evaluation results show that when user's configuration is not the same at runtime as at the time of providing training samples, WiAG significantly improves the gesture recognition accuracy from just 51.4% to 91.4%.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {252–264},
numpages = {13},
keywords = {orientation, position, WiFi, agnostic, gesture recognition},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081339,
author = {Zhu, Yanzi and Yao, Yuanshun and Zhao, Ben Y. and Zheng, Haitao},
title = {Object Recognition and Navigation Using a Single Networking Device},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081339},
doi = {10.1145/3081333.3081339},
abstract = {Tomorrow's autonomous mobile devices need accurate, robust and real-time sensing of their operating environment. Today's solutions fall short. Vision or acoustic-based techniques are vulnerable against challenging lighting conditions or background noise, while more robust laser or RF solutions require either bulky expensive hardware or tight coordination between multiple devices. This paper describes the design, implementation and evaluation of Ulysses, a practical environmental imaging system using colocated 60GHz radios on a single mobile device. Unlike alternatives that require specialized hardware, Ulysses reuses low-cost commodity networking chipsets available today. Ulysses' new imaging approach leverages RF beamforming, operates on specular (direct) reflection, and integrates the device's movement trajectory with sensing. Ulysses also includes a navigation component that uses the same 60GHz radios to compute "safety regions" where devices can move freely without collision, and to compute optimal paths for imaging within safety regions. Using our implementation of a small robotic car prototype, our experimental results show that Ulysses images objects meters away with cm-level precision, and provides accurate estimates of objects' surface materials.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {265–277},
numpages = {13},
keywords = {mobile system, imaging, 60GHz wireless},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081355,
author = {Chauhan, Jagmohan and Hu, Yining and Seneviratne, Suranga and Misra, Archan and Seneviratne, Aruna and Lee, Youngki},
title = {BreathPrint: Breathing Acoustics-Based User Authentication},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081355},
doi = {10.1145/3081333.3081355},
abstract = {We propose BreathPrint, a new behavioural biometric signature based on audio features derived from an individual's commonplace breathing gestures. Specifically, BreathPrint uses the audio signatures associated with the three individual gestures: sniff, normal, and deep breathing, which are sufficiently different across individuals. Using these three breathing gestures, we develop the processing pipeline that identifies users via the microphone sensor on smartphones and wearable devices. In BreathPrint, a user performs breathing gestures while holding the device very close to their nose. Using off-the-shelf hardware, we experimentally evaluate the BreathPrint prototype with 10 users, observed over seven days. We show that users can be authenticated reliably with an accuracy of over 94% for all the three breathing gestures in intra-sessions and deep breathing gesture provides the best overall balance between true positives (successful authentication) and false positives (resiliency to directed impersonation and replay attacks). Moreover, we show that this breathing sound based biometric is also robust to some typical changes in both physiological and environmental context, and that it can be applied on multiple smartphone platforms. Early results suggest that breathing based biometrics show promise as either to be used as a secondary authentication modality in a multimodal biometric authentication system or as a user disambiguation technique for some daily lifestyle scenarios.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {278–291},
numpages = {14},
keywords = {authentication, breathing gestures, usability, security},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3257288,
author = {Kravets, Robin},
title = {Session Details: PAPER SESSION 6: Offloading and Sharing},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257288},
doi = {10.1145/3257288},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081347,
author = {Naderiparizi, Saman and Zhang, Pengyu and Philipose, Matthai and Priyantha, Bodhi and Liu, Jie and Ganesan, Deepak},
title = {Glimpse: A Programmable Early-Discard Camera Architecture for Continuous Mobile Vision},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081347},
doi = {10.1145/3081333.3081347},
abstract = {We consider the problem of continuous computer-vision based analysis of video streams from mobile cameras over extended periods. Given high computational demands, general visual processing must currently be offloaded to the cloud. To reduce mobile battery and bandwidth consumption, recent proposals offload only "interesting" video frames, discarding the rest. However, determining what to discard is itself typically a power-hungry computer vision calculation, very often well beyond what most mobile devices can afford on a continuous basis. We present the Glimpse system, a re-design of the conventional mobile video processing pipeline to support such "early discard" flexibly, efficiently and accurately. Glimpse is a novel architecture that gates wearable vision using low-power vision modalities. Our proposed architecture adds novel sensing, processing, algorithmic and programming-system components to the camera pipeline to this end. We present a complete implementation and evaluation of our design. In common settings, Glimpse reduces mobile power and data usage by more than one order of magnitude relative to earlier designs, and moves continuous vision on lightweight wearables to the realm of the practical.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {292–305},
numpages = {14},
keywords = {continuous mobile vision, energy efficient wearable vision system, low-power early discard, low-power vision modalities},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081358,
author = {Georgiev, Petko and Lane, Nicholas D. and Mascolo, Cecilia and Chu, David},
title = {Accelerating Mobile Audio Sensing Algorithms through On-Chip GPU Offloading},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081358},
doi = {10.1145/3081333.3081358},
abstract = {GPUs have recently enjoyed increased popularity as general purpose software accelerators in multiple application domains including computer vision and natural language processing. However, there has been little exploration into the performance and energy trade-offs mobile GPUs can deliver for the increasingly popular workload of deep-inference audio sensing tasks, such as, spoken keyword spotting in energy-constrained smartphones and wearables. In this paper, we study these trade-offs and introduce an optimization engine that leverages a series of structural and memory access optimization techniques that allow audio algorithm performance to be automatically tuned as a function of GPU device specifications and model semantics. We find that parameter optimized audio routines obtain inferences an order of magnitude faster than sequential CPU implementations, and up to 6.5x times faster than cloud offloading with good connectivity, while critically consuming 3-4x less energy than the CPU. Under our optimized GPU, conventional wisdom about how to use the cloud and low power chips is broken. Unless the network has a throughput of at least 20Mbps (and a RTT of 25 ms or less), with only about 10 to 20 seconds of buffering audio data for batched execution, the optimized GPU audio sensing apps begin to consume less energy than cloud offloading. Under such conditions we find the optimized GPU can provide energy benefits comparable to low-power reference DSP implementations with some preliminary level of optimization; in addition to the GPU always winning with lower latency.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {306–318},
numpages = {13},
keywords = {mobile GPU offloading, audio sensing},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081337,
author = {Wang, Wenwen and Yew, Pen-Chung and Zhai, Antonia and McCamant, Stephen and Wu, Youfeng and Bobba, Jayaram},
title = {Enabling Cross-ISA Offloading for COTS Binaries},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081337},
doi = {10.1145/3081333.3081337},
abstract = {Work offloading allows a mobile device, i.e., the client, to execute its computation-intensive code remotely on a more powerful server to improve its performance and to extend its battery life. However, the difference in instruction set architectures (ISAs) between the client and the server poses a great challenge to work offloading. Most of the existing solutions rely on language-level virtual machines to hide such differences. Therefore, they have to tie closely to the specific programming languages. Other approaches try to recompile the mobile applications to achieve the specific goal of offloading, so their applicability is limited to the availability of the source code. To overcome the above limitations, we propose to extend the capability of dynamic binary translation across clients and servers to offload the identified computation-intensive binary code regions automatically to the server at runtime. With this approach, the native binaries on the client can be offloaded to the server seamlessly without the limitations mentioned above. A prototype has been implemented using an existing retargetable dynamic binary translator. Experimental results show that our system achieves 1.93X speedup with 48.66% reduction in energy consumption for six real-world applications, and 1.62X speedup with 42.4% reduction in energy consumption for SPEC CINT2006 benchmarks.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {319–331},
numpages = {13},
keywords = {offloading target selection, computation offloading, dynamic binary translation, dynamic binary optimization},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081348,
author = {Oh, Sangeun and Yoo, Hyuck and Jeong, Dae R. and Bui, Duc Hoang and Shin, Insik},
title = {Mobile Plus: Multi-Device Mobile Platform for Cross-Device Functionality Sharing},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081348},
doi = {10.1145/3081333.3081348},
abstract = {In recent years, the explosion of diverse smart devices such as mobile phones, TVs, watches, and even cars, has completely changed our lives. We communicate with friends through social network services (SNSs) whenever we want, buy stuff without visiting shops, and enjoy multimedia wherever we are, thanks to these devices. However, these smart devices cannot simply interact with each other even though they are right next to each other. For example, when you want to read a PDF stored on a smartphone on a larger TV screen, you need to do complicated work or plug in a bunch of cables. In this paper, we introduce M+, an extension of Android that supports cross-device functionality sharing in a transparent manner. As a platform-level solution, M+ enables unmodified Android applications to utilize not only application functionalities but also system functionalities across devices, as if they were to utilize them inside the same device. In addition to secure connection setup, M+ also allows performing of permission checks for remote applications in the same way as for local. Our experimental results show that M+ enables transparent cross-device sharing for various functionalities and achieves performance close to that of within-device sharing unless a large amount of data is transferred.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {332–344},
numpages = {13},
keywords = {inter-process communication, functionality sharing, remote procedure call, multi-device mobile platform},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3257289,
author = {Balasubramanian, Aruna},
title = {Session Details: PAPER SESSION 7: Wearables and CPS},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257289},
doi = {10.1145/3257289},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081362,
author = {Mao, Wenguang and Zhang, Zaiwei and Qiu, Lili and He, Jian and Cui, Yuchen and Yun, Sangki},
title = {Indoor Follow Me Drone},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081362},
doi = {10.1145/3081333.3081362},
abstract = {With the availability of inexpensive and powerful drones, it is possible to let drones automatically follow a user for video taping. This can not only reduce cost, but also support video taping in situations where otherwise not possible (e.g., during private moments or at inconvenient locations like indoor rock climbing). While there have been many follow-me drones on the market for outdoors, which rely on GPS, enabling indoor follow-me function is more challenging due to the lack of an effective approach to track users in indoor environments. To this end, we develop a holistic system that lets a mobile phone carried by a user accurately track the drone's relative location and control it to maintain a specified distance and orientation for automatic video taping. We develop a series of techniques to (i) track a drone's location using acoustic signals with sub-centimeter errors even under strong propeller noise from the drone and complicated multipath in indoor environments, and (ii) solve practical challenges in applying model predictive control (MPC) framework to control the drone. The latter consists of developing measurement-based flight models, designing measurement techniques to provide feedback to the controller, and predicting the user's movement. We implement our system on AR Drone 2.0 and Samsung S7. The extensive evaluation shows that our drone can follow a user effectively and maintain a specified following distance and orientation within 2-3 cm and 1-3 degree errors, respectively. The videos taped by the drone during flight are smooth according to the jerk metric.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {345–358},
numpages = {14},
keywords = {acoustic signals, MPC, music, drone, tracking, FMCW},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081343,
author = {Xiong, Sijie and Zhu, Sujie and Ji, Yisheng and Jiang, Binyao and Tian, Xiaohua and Zheng, Xuesheng and Wang, Xinbing},
title = {IBlink: Smart Glasses for Facial Paralysis Patients},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081343},
doi = {10.1145/3081333.3081343},
abstract = {Facial paralysis makes patients lose their facial movements, which can incur eye damage even blindness since patients are incapable of blinking. The paralysis usually occurs on just one side of the face, and clinical trials show that electrical stimulation could trigger blink. Based on such observations, we design and implement a pair of smart glasses iBlink to assist facial paralysis patients to blink. The basic idea is to monitor the normal side of the face with a camera and stimulate the paralysed side, so that the blink of the both eyes become symmetric. To the best of our knowledge, this is the first piece of wearable device for facial paralysis therapy. Our contributions are: First, we propose an eye-blink detection mechanism based on deep convolutional neural network (CNN), which can detect asymmetric blinks of patients under various illumination conditions with an accuracy above 99%. Our eye-image library for training CNN models is published online for further related studies, which contains more than $30,000$ eye images. Second, we design and implement an automatic stimulation circuits to generate electrical impulse for stimulating the patient's facial nerve branches, which can configure operational parameters in a self-adaptive manner for different patients. Third, we implement the entire iBlink system, which integrates the two functions above and a communication function module for tele-medicine applications. Moreover, we conduct clinical trials in a hospital, in order to obtain the design basis and verify effectiveness of our device.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {359–370},
numpages = {12},
keywords = {smart glasses, facial paralysis},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081344,
author = {Liu, Luyang and Li, Hongyu and Liu, Jian and Karatas, Cagdas and Wang, Yan and Gruteser, Marco and Chen, Yingying and Martin, Richard P.},
title = {BigRoad: Scaling Road Data Acquisition for Dependable Self-Driving},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081344},
doi = {10.1145/3081333.3081344},
abstract = {Advanced driver assistance systems and, in particular automated driving offers an unprecedented opportunity to transform the safety, efficiency, and comfort of road travel. Developing such safety technologies requires an understanding of not just common highway and city traffic situations but also a plethora of widely different unusual events (e.g., object on the road way and pedestrian crossing highway, etc.). While each such event may be rare, in aggregate they represent a significant risk that technology must address to develop truly dependable automated driving and traffic safety technologies. By developing technology to scale road data acquisition to a large number of vehicles, this paper introduces a low-cost yet reliable solution, BigRoad, that can derive internal driver inputs (i.e., steering wheel angles, driving speed and acceleration) and external perceptions of road environments (i.e., road conditions and front-view video) using a smartphone and an IMU mounted in a vehicle. We evaluate the accuracy of collected internal and external data using over 140 real-driving trips collected in a 3-month time period. Results show that BigRoad can accurately estimate the steering wheel angle with 0.69 degree median error, and derive the vehicle speed with 0.65 km/h deviation. The system is also able to determine binary road conditions with 95% accuracy by capturing a small number of brakes. We further validate the usability of BigRoad by pushing the collected video feed and steering wheel angle to a deep neural network steering wheel angle predictor, showing the potential of massive data acquisition for training self-driving system using BigRoad.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {371–384},
numpages = {14},
keywords = {road data acquisition, IMU, smartphone, self-driving},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081351,
author = {Liu, Xing and Chen, Tianyu and Qian, Feng and Guo, Zhixiu and Lin, Felix Xiaozhu and Wang, Xiaofeng and Chen, Kai},
title = {Characterizing Smartwatch Usage in the Wild},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081351},
doi = {10.1145/3081333.3081351},
abstract = {Smartwatch has become one of the most popular wearable computers on the market. We conduct an IRB-approved measurement study involving 27 Android smartwatch users. Using a 106-day dataset collected from our participants, we perform in-depth characterization of three key aspects of smartwatch usage "in the wild": usage patterns, energy consumption, and network traffic. Based on our findings, we identify key aspects of the smartwatch ecosystem that can be further improved, propose recommendations, and point out future research directions.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {385–398},
numpages = {14},
keywords = {smartwatch, wearable devices, power model},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3257290,
author = {Balan, Rajesh Krishna},
title = {Session Details: PAPER SESSION 8: Mobile Performance},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257290},
doi = {10.1145/3257290},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081341,
author = {Ki, Taeyeon and Simeonov, Alexander and Jain, Bhavika Pravin and Park, Chang Min and Sharma, Keshav and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
title = {Reptor: Enabling API Virtualization on Android for Platform Openness},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081341},
doi = {10.1145/3081333.3081341},
abstract = {This paper proposes a new technique that enables open innovation in mobile platforms. Our technique allows third-party developers to modify, instrument, or extend platform API calls and deploy their modifications seamlessly. The uniqueness of our technique is that it enables modifications completely at the app layer without requiring any platform-level changes. This allows practical openness---third parties can easily distribute their modifications for a platform without the need to update the entire platform. To demonstrate the benefits of our technique, we have developed a prototype on Android called Reptor and used it to instrument real-world apps with novel functionality. Our evaluation in realistic scenarios shows that Reptor has little overhead in performance and energy, and only modest overhead in memory usage that ranges from 0.6% to 10% for the observed worst cases.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {399–412},
numpages = {14},
keywords = {android app instrumentation, android platform instrumentation, platform openness, API virtualization},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081350,
author = {He, Liang and Tung, Yu-Chih and Shin, Kang G.},
title = {ICharge: User-Interactive Charging of Mobile Devices},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081350},
doi = {10.1145/3081333.3081350},
abstract = {Charging mobile devices "fast" has been the focus of both industry and academia, leading to the deployment of various fast charging technologies. However, existing fast charging solutions are agnostic of users' available time for charging their devices, causing early termination of the intended/planned charging. This, in turn, accelerates the capacity fading of device battery and thus shortens the device operation. In this paper, we propose a novel user-interactive charging paradigm, called iCharge, that tailors the device charging to the user's real-time availability and need. The core of iCharge is a relaxation-aware (R-Aware) charging algorithm that maximizes the charged capacity within the user's available time and slows down the battery's capacity fading. iCharge also integrates R-Aware with existing fast charging algorithms via a user-interactive interface, allowing users to choose a charging method based on their availability and need. We evaluate iCharge via extensive laboratory experiments and field-tests on Android phones, as well as user studies. R-Aware is shown to slow down the battery fading by more than 36% on average, and up to 60% in extreme cases, when compared to existing fast charging algorithms. This slowdown of capacity fading translates to, for instance, an up to 2-hour extension of the LTE time for a Nexus 5X phone after its use for 2 years, according to our trace-driven analysis of 976 device charging cases of 7 users over 3 months.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {413–426},
numpages = {14},
keywords = {battery relaxation, user-interactive charging, battery fading, mobile devices},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081367,
author = {Xie, Xiufeng and Zhang, Xinyu and Zhu, Shilin},
title = {Accelerating Mobile Web Loading Using Cellular Link Information},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081367},
doi = {10.1145/3081333.3081367},
abstract = {Despite the 4G LTE's 10X capacity improvement over 3G, mobile Web loading latency remains a major issue that hampers user experience. The root cause lies in the inefficient transport-layer that underutilizes LTE capacity, due to high channel dynamics, wireless link losses, and insufficient application traffic to propel the bandwidth probing. In this paper, we propose Cellular Link-Aware Web loading (CLAW), which boosts mobile Web loading using a physical-layer informed transport protocol. CLAW harnesses the limited PHY-layer statistics available on LTE phones to quantitatively model the LTE channel resource utilization, which is then translated into a transport window that best fits the bandwidth. Consequently, CLAW can estimate and fully utilize the available bandwidth almost within one RTT. In addition, CLAW can precisely differentiate LTE wireless loss from congestion loss, and identify the rare cases when the wireline backhaul becomes the bottleneck. We have prototyped CLAW on commodity LTE phones. Across a wide range of experimental settings, CLAW consistently reduces Web loading latency by more than 30%, compared to classical TCP variants and state-of-the-art congestion controls for cellular networks.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {427–439},
numpages = {13},
keywords = {LTE, TCP, cross-layer protocol, mobile web, physical-layer},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081365,
author = {Brunette, Waylon and Sudar, Samuel and Sundt, Mitchell and Larson, Clarice and Beorse, Jeffrey and Anderson, Richard},
title = {Open Data Kit 2.0: A Services-Based Application Framework for Disconnected Data Management},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081365},
doi = {10.1145/3081333.3081365},
abstract = {In resource-constrained communities, organizations often use information and communication technologies to amplify their limited resources to improve education, health, and economic opportunity. Over two-thirds of the world's population have mobile phones, yet less than half are connected to the Internet [23]. Organizations helping disadvantaged populations often rely on mobile devices as their primary computing resource because of their availability in resource-constrained contexts. However, to reach under-served populations, mobile applications often operate in areas with no connectivity or challenged network environments. Unfortunately, many mobile application frameworks are generally not well-suited for long periods of disconnected data collection and management. Furthermore, mobile application frameworks are generally aimed at users with significant technical skills and resources. In this paper, we discuss our experiences building, deploying, and refining the Open Data Kit (ODK) 2.0 tool suite. ODK 2.0 is a modular application framework that facilitates organizations with limited technical capacity to build application-specific information services for use in disconnected environments. We discuss ODK 2.0's flexible abstractions that enable users of varying technical skill levels to create customizable mobile data management solutions. We present ODK 2.0 case studies involving multiple organizations and discuss lessons learned from building a service-based mobile application framework for disconnected data management.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {440–452},
numpages = {13},
keywords = {mobile application framework, disconnected operation, open data kit, ICTD, mobile data management, mobile databases},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3257291,
author = {Sani, Ardalan Amiri},
title = {Session Details: PAPER SESSION 9: Security and Privacy II},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257291},
doi = {10.1145/3257291},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081334,
author = {Rahmati, Amir and Fernandes, Earlence and Eykholt, Kevin and Chen, Xinheng and Prakash, Atul},
title = {Heimdall: A Privacy-Respecting Implicit Preference Collection Framework},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081334},
doi = {10.1145/3081333.3081334},
abstract = {Many of the everyday decisions a user makes rely on the suggestions of online recommendation systems. These systems amass implicit (e.g.,location, purchase history, browsing history) and explicit (e.g.,reviews, ratings) feedback from multiple users, produce a general consensus, and provide suggestions based on that consensus. However, due to privacy concerns, users are uncomfortable with implicit data collection, thus requiring recommendation systems to be overly dependent on explicit feedback. Unfortunately, users do not frequently provide explicit feedback. This hampers the ability of recommendation systems to provide high-quality suggestions. We introduce Heimdall, the first privacy-respecting implicit preference collection framework that enables recommendation systems to extract user preferences from their activities in a privacy respecting manner. The key insight is to enable recommendation systems to run a collector on a user's device and precisely control the information a collector transmits to the recommendation system back-end. Heimdall introduces immutable blobs as a mechanism to guarantee this property. We implemented Heimdall on the Android platform and wrote three example collectors to enhance recommendation systems with implicit feedback. Our performance results suggest that the overhead of immutable blobs is minimal, and a user study of 166 participants indicates that privacy concerns are significantly less when collectors record only specific information--a property that Heimdall enables.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {453–463},
numpages = {11},
keywords = {privacy, internet of things, implicit feedback, recommendation systems},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081342,
author = {Wilson, Judson and Wahby, Riad S. and Corrigan-Gibbs, Henry and Boneh, Dan and Levis, Philip and Winstein, Keith},
title = {Trust but Verify: Auditing the Secure Internet of Things},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081342},
doi = {10.1145/3081333.3081342},
abstract = {Internet-of-Things devices often collect and transmit sensitive information like camera footage, health monitoring data, or whether someone is home. These devices protect data in transit with end-to-end encryption, typically using TLS connections between devices and associated cloud services. But these TLS connections also prevent device owners from observing what their own devices are saying about them. Unlike in traditional Internet applications, where the end user controls one end of a connection (e.g., their web browser) and can observe its communication, Internet-of-Things vendors typically control the software in both the device and the cloud. As a result, owners have no way to audit the behavior of their own devices, leaving them little choice but to hope that these devices are transmitting only what they should.This paper presents TLS--Rotate and Release (TLS-RaR), a system that allows device owners (e.g., consumers, security researchers, and consumer watchdogs) to authorize devices, called auditors, to decrypt and verify recent TLS traffic without compromising future traffic. Unlike prior work, TLS-RaR requires no changes to TLS's wire format or cipher suites, and it allows the device's owner to conduct a surprise inspection of recent traffic, without prior notice to the device that its communications will be audited.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {464–474},
numpages = {11},
keywords = {decrypt, TLS-rotate and release, TLS-RAR, transport layer security, middlebox, TLS 1.3, TLS, IoT, proxy, internet of things, auditing},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081345,
author = {Agadakos, Ioannis and Polakis, Jason and Portokalidis, Georgios},
title = {Techu: Open and Privacy-Preserving Crowdsourced GPS for the Masses},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081345},
doi = {10.1145/3081333.3081345},
abstract = {The proliferation of mobile devices, equipped with numerous sensors and Internet connectivity, has laid the foundation for the emergence of a diverse set of crowdsourcing services. By leveraging the multitude, geographical dispersion, and technical abilities of smartphones, these services tackle challenging tasks by harnessing the power of the crowd. One such service, Crowd GPS, has gained traction in the industry and research community alike, materializing as a class of systems that track lost objects or individuals (e.g., children or elders). While these systems can have significant impact, they suffer from major privacy threats.In this paper, we highlight the inherent risks to users from the centralized designs adopted by such services and demonstrate how adversaries can trivially misuse one of the most popular crowd GPS services to track their users. As an alternative, we present Techu, a privacy-preserving crowd GPS service for tracking Bluetooth tags. Our architecture follows a hybrid decentralized approach, where an untrusted server acts as a bulletin board that collects reports of tags observed by the crowd, while observers store the location information locally and only disclose it upon proof of ownership of the tag. Techu does not require user authentication, allowing users to remain anonymous. As no user authentication is required and cloud messaging queues are leveraged for communication between users, users remain anonymous. Our security analysis highlights the privacy offered by Techu, and details how our design prevents adversaries from tracking or identifying users. Finally, our experimental evaluation demonstrates that Techu has negligible impact on power consumption, and achieves superior effectiveness to previously proposed systems while offering stronger privacy guarantees.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {475–487},
numpages = {13},
keywords = {privacy-preserving protocol, crowd gps, location privacy, ble tags, location-based services, user tracking},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.1145/3081333.3081349,
author = {Guan, Le and Liu, Peng and Xing, Xinyu and Ge, Xinyang and Zhang, Shengzhi and Yu, Meng and Jaeger, Trent},
title = {TrustShadow: Secure Execution of Unmodified Applications with ARM TrustZone},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081349},
doi = {10.1145/3081333.3081349},
abstract = {The rapid evolution of Internet-of-Things (IoT) technologies has led to an emerging need to make them smarter. A variety of applications now run simultaneously on an ARM-based processor. For example, devices on the edge of the Internet are provided with higher horsepower to be entrusted with storing, processing and analyzing data collected from IoT devices. This significantly improves efficiency and reduces the amount of data that needs to be transported to the cloud for data processing, analysis and storage. However, commodity OSes are prone to compromise. Once they are exploited, attackers can access the data on these devices. Since the data stored and processed on the devices can be sensitive, left untackled, this is particularly disconcerting. In this paper, we propose a new system, TrustShadow that shields legacy applications from untrusted OSes. TrustShadow takes advantage of ARM TrustZone technology and partitions resources into the secure and normal worlds. In the secure world, TrustShadow constructs a trusted execution environment for security-critical applications. This trusted environment is maintained by a lightweight runtime system that coordinates the communication between applications and the ordinary OS running in the normal world. The runtime system does not provide system services itself. Rather, it forwards requests for system services to the ordinary OS, and verifies the correctness of the responses. To demonstrate the efficiency of this design, we prototyped TrustShadow on a real chip board with ARM TrustZone support, and evaluated its performance using both microbenchmarks and real-world applications. We showed TrustShadow introduces only negligible overhead to real-world applications.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {488–501},
numpages = {14},
keywords = {arm trustzone, trusted execution, IoT, malicious operating systems},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}
