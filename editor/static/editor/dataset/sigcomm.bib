@inproceedings{10.1145/3452296.3472912,
author = {Arun, Venkat and Arashloo, Mina Tahmasbi and Saeed, Ahmed and Alizadeh, Mohammad and Balakrishnan, Hari},
title = {Toward Formally Verifying Congestion Control Behavior},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472912},
doi = {10.1145/3452296.3472912},
abstract = {The diversity of paths on the Internet makes it difficult for designers and operators to confidently deploy new congestion control algorithms (CCAs) without extensive real-world experiments, but such capabilities are not available to most of the networking community. And even when they are available, understanding why a CCA underperforms by trawling through massive amounts of statistical data from network connections is challenging. The history of congestion control is replete with many examples of surprising and unanticipated behaviors unseen in simulation but observed on real-world paths. In this paper, we propose initial steps toward modeling and improving our confidence in a CCA's behavior. We have developed CCAC, a tool that uses formal verification to establish certain properties of CCAs. It is able to prove hypotheses about CCAs or generate counterexamples for invalid hypotheses. With CCAC, a designer can not only gain greater confidence prior to deployment to avoid unpleasant surprises, but can also use the counterexamples to iteratively improvetheir algorithm. We have modeled additive-increase/multiplicative-decrease (AIMD), Copa, and BBR with CCAC, and describe some surprising results from the exercise.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {1–16},
numpages = {16},
keywords = {formal verification, congestion control, WAN transport},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472937,
author = {Tian, Bingchuan and Gao, Jiaqi and Liu, Mengqi and Zhai, Ennan and Chen, Yanqing and Zhou, Yu and Dai, Li and Yan, Feng and Ma, Mengjing and Tang, Ming and Lu, Jie and Wei, Xionglie and Liu, Hongqiang Harry and Zhang, Ming and Tian, Chen and Yu, Minlan},
title = {Aquila: A Practically Usable Verification System for Production-Scale Programmable Data Planes},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472937},
doi = {10.1145/3452296.3472937},
abstract = {This paper presents Aquila, the first practically usable verification system for Alibaba's production-scale programmable data planes. Aquila addresses four challenges in building a practically usable verification: (1) specification complexity; (2) verification scalability; (3) bug localization; and (4) verifier self validation. Specifically, first, Aquila proposes a high-level language that facilitates easy expression of specifications, reducing lines of specification codes by tenfold compared to the state-of-the-art. Second, Aquila constructs a sequential encoding algorithm to circumvent the exponential growth of states associated with the upscaling of data plane programs to production level. Third, Aquila adopts an automatic and accurate bug localization approach that can narrow down suspects based on reported violations and pinpoint the culprit by simulating a fix for each suspect. Fourth and finally, Aquila can perform self validation based on refinement proof, which involves the construction of an alternative representation and subsequent equivalence checking. To this date, Aquila has been used in the verification of our production-scale programmable edge networks for over half a year, and it has successfully prevented many potential failures resulting from data plane bugs.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {17–32},
numpages = {16},
keywords = {programmable switches, formal methods, P4 verification},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472915,
author = {Schneider, Tibor and Birkner, R\"{u}diger and Vanbever, Laurent},
title = {Snowcap: Synthesizing Network-Wide Configuration Updates},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472915},
doi = {10.1145/3452296.3472915},
abstract = {Large-scale reconfiguration campaigns tend to be nerve-racking for network operators as they can lead to significant network downtimes, decreased performance, and policy violations. Unfortunately, existing reconfiguration frameworks often fall short in practice as they either only support a small set of reconfiguration scenarios or simply do not scale.We address these problems with Snowcap, the first network reconfiguration framework which can synthesize configuration updates that comply with arbitrary hard and soft specifications, and involve arbitrary routing protocols. Our key contribution is an efficient search procedure which leverages counter-examples to efficiently navigate the space of configuration updates. Given a reconfiguration ordering which violates the desired specifications, our algorithm automatically identifies the problematic commands so that it can avoid this particular order in the next iteration.We fully implemented Snowcap and extensively evaluated its scalability and effectiveness on real-world topologies and typical, large-scale reconfiguration scenarios. Even for large topologies, Snowcap finds a valid reconfiguration ordering with minimal side-effects (i.e., traffic shifts) within a few seconds at most.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {33–49},
numpages = {17},
keywords = {configuration, network analysis, migration},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472929,
author = {Xu, Qiongwen and Wong, Michael D. and Wagle, Tanvi and Narayana, Srinivas and Sivaraman, Anirudh},
title = {Synthesizing Safe and Efficient Kernel Extensions for Packet Processing},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472929},
doi = {10.1145/3452296.3472929},
abstract = {Extended Berkeley Packet Filter (BPF) has emerged as a powerful method to extend packet-processing functionality in the Linux operating system. BPF allows users to write code in high-level languages (like C or Rust) and execute them at specific hooks in the kernel, such as the network device driver. To ensure safe execution of a user-developed BPF program in kernel context, Linux uses an in-kernel static checker. The checker allows a program to execute only if it can prove that the program is crash-free, always accesses memory within safe bounds, and avoids leaking kernel data.BPF programming is not easy. One, even modest-sized BPF programs are deemed too large to analyze and rejected by the kernel checker. Two, the kernel checker may incorrectly determine that a BPF program exhibits unsafe behaviors. Three, even small performance optimizations to BPF code (e.g., 5% gains) must be meticulously hand-crafted by expert developers. Traditional optimizing compilers for BPF are often inadequate since the kernel checker's safety constraints are incompatible with rule-based optimizations.We present K2, a program-synthesis-based compiler that automatically optimizes BPF bytecode with formal correctness and safety guarantees. K2 produces code with 6--26% reduced size, 1.36%--55.03% lower average packet-processing latency, and 0--4.75% higher throughput (packets per second per core) relative to the best clang-compiled program, across benchmarks drawn from Cilium, Facebook, and the Linux kernel. K2 incorporates several domain-specific techniques to make synthesis practical by accelerating equivalence-checking of BPF programs by 6 orders of magnitude.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {50–64},
numpages = {15},
keywords = {BPF, synthesis, stochastic optimization, endpoint packet processing},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472888,
author = {Cai, Qizhe and Chaudhary, Shubham and Vuppalapati, Midhul and Hwang, Jaehyun and Agarwal, Rachit},
title = {Understanding Host Network Stack Overheads},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472888},
doi = {10.1145/3452296.3472888},
abstract = {Traditional end-host network stacks are struggling to keep up with rapidly increasing datacenter access link bandwidths due to their unsustainable CPU overheads. Motivated by this, our community is exploring a multitude of solutions for future network stacks: from Linux kernel optimizations to partial hardware offload to clean-slate userspace stacks to specialized host network hardware. The design space explored by these solutions would benefit from a detailed understanding of CPU inefficiencies in existing network stacks.This paper presents measurement and insights for Linux kernel network stack performance for 100Gbps access link bandwidths. Our study reveals that such high bandwidth links, coupled with relatively stagnant technology trends for other host resources (e.g., CPU speeds and capacity, cache sizes, NIC buffer sizes, etc.), mark a fundamental shift in host network stack bottlenecks. For instance, we find that a single core is no longer able to process packets at line rate, with data copy from kernel to application buffers at the receiver becoming the core performance bottleneck. In addition, increase in bandwidth-delay products have outpaced the increase in cache sizes, resulting in inefficient DMA pipeline between the NIC and the CPU. Finally, we find that traditional loosely-coupled design of network stack and CPU schedulers in existing operating systems becomes a limiting factor in scaling network stack performance across cores. Based on insights from our study, we discuss implications to design of future operating systems, network protocols, and host hardware.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {65–77},
numpages = {13},
keywords = {network hardware, datacenter networks, host network stacks},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472909,
author = {Li, Bojie and Zuo, Gefei and Bai, Wei and Zhang, Lintao},
title = {1Pipe: Scalable Total Order Communication in Data Center Networks},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472909},
doi = {10.1145/3452296.3472909},
abstract = {This paper proposes 1Pipe, a novel communication abstraction that enables different receivers to process messages from senders in a consistent total order. More precisely, 1Pipe provides both unicast and scattering (i.e., a group of messages to different destinations) in a causally and totally ordered manner. 1Pipe provides a best effort service that delivers each message at most once, as well as a reliable service that guarantees delivery and provides restricted atomic delivery for each scattering. 1Pipe can simplify and accelerate many distributed applications, e.g., transactional key-value stores, log replication, and distributed data structures.We propose a scalable and efficient method to implement 1Pipe inside data centers. To achieve total order delivery in a scalable manner, 1Pipe separates the bookkeeping of order information from message forwarding, and distributes the work to each switch and host. 1Pipe aggregates order information using in-network computation at switches. This forms the “control plane” of the system. On the “data plane”, 1Pipe forwards messages in the network as usual and reorders them at the receiver based on the order information.Evaluation on a 32-server testbed shows that 1Pipe achieves scalable throughput (80M messages per second per host) and low latency (10𝜇s) with little CPU and network overhead. 1Pipe achieves linearly scalable throughput and low latency in transactional key-value store, TPC-C, remote data structures, and replication that outperforms traditional designs by 2∼20x.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {78–92},
numpages = {15},
keywords = {CATOCS, total order communication, in-network processing, data center networks},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472934,
author = {Singhvi, Arjun and Akella, Aditya and Anderson, Maggie and Cauble, Rob and Deshmukh, Harshad and Gibson, Dan and Martin, Milo M. K. and Strominger, Amanda and Wenisch, Thomas F. and Vahdat, Amin},
title = {CliqueMap: Productionizing an RMA-Based Distributed Caching System},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472934},
doi = {10.1145/3452296.3472934},
abstract = {Distributed in-memory caching is a key component of modern Internet services. Such caches are often accessed via remote procedure call (RPC), as RPC frameworks provide rich support for productionization, including protocol versioning, memory efficiency, auto-scaling, and hitless upgrades. However, full-featured RPC limits performance and scalability as it incurs high latencies and CPU overheads. Remote Memory Access (RMA) offers a promising alternative, but meeting productionization requirements can be a significant challenge with RMA-based systems due to limited programmability and narrow RMA primitives.This paper describes the design, implementation, and experience derived from CliqueMap, a hybrid RMA/RPC caching system. CliqueMap has been in production use in Google's datacenters for over three years, currently serves more than 1PB of DRAM, and underlies several end-user visible services. CliqueMap makes use of performant and efficient RMAs on the critical serving path and judiciously applies RPCs toward other functionality. The design embraces lightweight replication, client-based quoruming, self-validating server responses, per-operation client-side retries, and co-design with the network layers. These foci lead to a system resilient to the rigors of production and frequent post deployment evolution.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {93–105},
numpages = {13},
keywords = {remote memory access, key-value caching system, remote procedure call},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472940,
author = {Min, Jaehong and Liu, Ming and Chugh, Tapan and Zhao, Chenxingyu and Wei, Andrew and Doh, In Hwan and Krishnamurthy, Arvind},
title = {Gimbal: Enabling Multi-Tenant Storage Disaggregation on SmartNIC JBOFs},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472940},
doi = {10.1145/3452296.3472940},
abstract = {Emerging SmartNIC-based disaggregated NVMe storage has become a promising storage infrastructure due to its competitive IO performance and low cost. These SmartNIC JBOFs are shared among multiple co-resident applications, and there is a need for the platform to ensure fairness, QoS, and high utilization. Unfortunately, given the limited computing capability of the SmartNICs and the non-deterministic nature of NVMe drives, it is challenging to provide such support on today's SmartNIC JBOFs.This paper presents Gimbal, a software storage switch that orchestrates IO traffic between Ethernet ports and NVMe drives for co-located tenants. It enables efficient multi-tenancy on SmartNIC JBOFs using the following techniques: a delay-based SSD congestion control algorithm, dynamic estimation of SSD write costs, a fair scheduler that operates at the granularity of a virtual slot, and an end-to-end credit-based flow control channel. Our prototyped system not only achieves up to x6.6 better utilization and 62.6% less tail latency but also improves the fairness for complex workloads. It also improves a commercial key-value store performance in a multi-tenant environment with x1.7 better throughput and 35.0% less tail latency on average.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {106–122},
numpages = {17},
keywords = {SSD, disaggregated storage, congestion control, fairness},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472890,
author = {Zelaya, R. Ivan and Sussman, William and Gummeson, Jeremy and Jamieson, Kyle and Hu, Wenjun},
title = {LAVA: Fine-Grained 3D Indoor Wireless Coverage for Small IoT Devices},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472890},
doi = {10.1145/3452296.3472890},
abstract = {Small IoT devices deployed in challenging locations suffer from uneven 3D coverage in complex environments. This work optimizes indoor coverage with LAVA, a Large Array of Vanilla Amplifiers. LAVA is a standard-agnostic cooperative mesh of elements, i.e., RF devices each consisting of several switched input and output antennas connected to fixed-gain amplifiers. Each LAVA element is further equipped with rudimentary power sensing to detect nearby transmissions. The elements report power readings to the LAVA control plane, which then infers active link sessions without explicitly interacting with the endpoint transmitter or receiver. With simple on-off control of amplifiers and antenna switching, LAVA boosts passing signals via multi hop amplify-and-forward. LAVA explores a middle ground between smart surfaces and physical-layer relays. Multi-hopping over short inter-hop distances exerts more control over the end-to-end trajectory, supporting fine-grained coverage and spatial reuse. Ceiling testbed results show throughput improvements to individual Wi-Fi links by 50% on average and up to 100% at 15 dBm transmit power (193% on average, up to 8x at 0 dBm). ZigBee links see up to 17 dB power gain. For pairs of co-channel concurrent links, LAVA provides average per-link throughput improvements of 517% at 0 dBm and 80% at 15 dBm.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {123–136},
numpages = {14},
keywords = {programmable radio environments, smart surfaces, multi-hop amplify-and-forward, non-uniform 3D coverage},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472907,
author = {Yang, Zhijian and Choudhury, Romit Roy},
title = {Personalizing Head Related Transfer Functions for Earables},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472907},
doi = {10.1145/3452296.3472907},
abstract = {Head related transfer functions (HRTF) describe how sound signals bounce, scatter, and diffract when they arrive at the head, and travel towards the ears. HRTFs produce distinct sound patterns that ultimately help the brain infer the spatial properties of the sound, such as its direction of arrival, 𝜃. If an earphone can learn the HRTF, it could apply the HRTF to any sound and make that sound appear directional to the user. For instance, a directional voice guide could help a tourist navigate a new city. While past works have estimated human HRTFs, an important gap lies in personalization. Today's HRTFs are global templates that are used in all products; since human HRTFs are unique, a global HRTF only offers a coarse-grained experience. This paper shows that by moving a smartphone around the head, combined with mobile acoustic communications between the phone and the earbuds, it is possible to estimate a user's personal HRTF. Our personalization system, UNIQ, combines techniques from channel estimation, motion tracking, and signal processing, with a focus on modeling signal diffraction on the curvature of the face. The results are promising and could open new doors into the rapidly growing space of immersive AR/VR, earables, smart hearing aids, etc.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {137–150},
numpages = {14},
keywords = {spatial audio, head related transfer function (HRTF), earables, HRTF personalization, VR, virtual acoustics, AR},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472932,
author = {Vasisht, Deepak and Shenoy, Jayanth and Chandra, Ranveer},
title = {L2D2: Low Latency Distributed Downlink for LEO Satellites},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472932},
doi = {10.1145/3452296.3472932},
abstract = {Large constellations of Low Earth Orbit satellites promise to provide near real-time high-resolution Earth imagery. Yet, getting this large amount of data back to Earth is challenging because of their low orbits and fast motion through space. Centralized architectures with few multi-million dollar ground stations incur large hour-level data download latency and are hard to scale. We propose a geographically distributed ground station design, L2D2, that uses low-cost commodity hardware to offer low latency robust downlink. L2D2 is the first system to use a hybrid ground station model, where only a subset of ground stations are uplink-capable. We design new algorithms for scheduling and rate adaptation that enable low latency and high robustness despite the limitations of the receive-only ground stations. We evaluate L2D2 through a combination of trace-driven simulations and real-world satellite-ground station measurements. Our results demonstrate that L2D2's geographically distributed design can reduce data downlink latency from 90 minutes to 21 minutes.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {151–164},
numpages = {14},
keywords = {earth observation, satellite networking, distributed ground station, ground station architecture},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472896,
author = {Nolan, John and Qian, Kun and Zhang, Xinyu},
title = {RoS: Passive Smart Surface for Roadside-to-Vehicle Communication},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472896},
doi = {10.1145/3452296.3472896},
abstract = {Modern autonomous vehicles are commonly instrumented with radars for all-weather perception. Yet the radar functionality is limited to identifying the positions of reflectors in the environment. In this paper, we investigate the feasibility of smartening transportation infrastructure for the purpose of conveying richer information to automotive radars. We propose RoS, a passive PCB-fabricated smart surface which can be reconfigured to embed digital bits, and inform the radar much like visual road signs do to cameras. We design the RoS signage to act as a retrodirective reflector which can reflect signals back to the radar from wide viewing angles. We further introduce a spatial encoding scheme, which piggybacks information in the reflected analog signals based on the geometrical layout of the retroreflective elements. Our prototype fabrication and experimentation verifies the effectiveness of RoS as an RF ''barcode'' which is readable by radar in practical transportation environment.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {165–178},
numpages = {14},
keywords = {intelligent reflecting surface, V2X, Van Atta array, millimeter wave radar, smart surface},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472887,
author = {Yu, Zhuolong and Hu, Chuheng and Wu, Jingfeng and Sun, Xiao and Braverman, Vladimir and Chowdhury, Mosharaf and Liu, Zhenhua and Jin, Xin},
title = {Programmable Packet Scheduling with a Single Queue},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472887},
doi = {10.1145/3452296.3472887},
abstract = {Programmable packet scheduling enables scheduling algorithms to be programmed into the data plane without changing the hardware. Existing proposals either have no hardware implementations for switch ASICs or require multiple strict-priority queues.We present Admission-In First-Out (AIFO) queues, a new solution for programmable packet scheduling that uses only a emph{single} first-in first-out queue. AIFO is motivated by the confluence of two recent trends: emph{shallow} buffers in switches and emph{fast-converging} congestion control in end hosts, that together leads to a simple observation: the decisive factor in a flow's completion time (FCT) in modern datacenter networks is often emph{which} packets are enqueued or dropped, not the emph{ordering} they leave the switch. The core idea of AIFO is to maintain a sliding window to track the ranks of recent packets and compute the relative rank of an arriving packet in the window for admission control. Theoretically, we prove that AIFO provides bounded performance to Push-In First-Out (PIFO). Empirically, we fully implement AIFO and evaluate AIFO with a range of real workloads, demonstrating AIFO closely approximates PIFO. Importantly, unlike PIFO, AIFO can run at line rate on existing hardware and use minimal switch resources---as few as a single queue.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {179–193},
numpages = {15},
keywords = {in-network processing, programmable networks, data center networks, packet scheduling},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472889,
author = {Pan, Tian and Yu, Nianbing and Jia, Chenhao and Pi, Jianwen and Xu, Liang and Qiao, Yisong and Li, Zhiguo and Liu, Kun and Lu, Jie and Lu, Jianyuan and Song, Enge and Zhang, Jiao and Huang, Tao and Zhu, Shunmin},
title = {Sailfish: Accelerating Cloud-Scale Multi-Tenant Multi-Service Gateways with Programmable Switches},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472889},
doi = {10.1145/3452296.3472889},
abstract = {The cloud gateway is essential in the public cloud as the central hub of cloud traffic. We show that horizontal scaling of software gateways, once sustainable for years, is no longer future-proof facing the massive scale and rapid growth of today's cloud. The root cause is the stagnant performance of the CPU core, which is prone to be overloaded by heavy hitters as traffic growth goes far beyond Moore's law. To address this, we propose emph{Sailfish}, a cloud-scale multi-tenant multi-service gateway accelerated by programmable switches. The new challenge is that large forwarding tables due to multi-tenancy cannot be fit into the limited on-chip memories. To this end, we devise a multi-pronged approach with (1) hardware/software co-design for table sharing, (2) horizontal table splitting among gateway clusters, (3) pipeline-aware table compression for a single node. Compared with the x86 gateway of a similar price, Sailfish reduces latency by 95% (2μs), improves throughput by more than 20x in bps (3.2Tbps) and 71x in pps (1.8Gpps) with packet length &lt; 256B. Sailfish has been deployed in Alibaba Cloud for more than two years. It is the first P4-based cloud gateway in the industry, of which a single cluster carries dozens of Tbps traffic, withstanding peak-hour traffic in large online shopping festivals.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {194–206},
numpages = {13},
keywords = {cloud gateways, programmable data plane, virtual private cloud, forwarding table compression},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472892,
author = {Zhang, Yinda and Liu, Zaoxing and Wang, Ruixin and Yang, Tong and Li, Jizhou and Miao, Ruijie and Liu, Peng and Zhang, Ruwen and Jiang, Junchen},
title = {CocoSketch: High-Performance Sketch-Based Measurement over Arbitrary Partial Key Query},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472892},
doi = {10.1145/3452296.3472892},
abstract = {Sketch-based measurement has emerged as a promising alternative to the traditional sampling-based network measurement approaches due to its high accuracy and resource efficiency. While there have been various designs around sketches, they focus on measuring one particular flow key, and it is infeasible to support many keys based on these sketches. In this work, we take a significant step towards supporting arbitrary partial key queries, where we only need to specify a full range of possible flow keys that are of interest before measurement starts, and in query time, we can extract the information of any key in that range. We design CocoSketch, which casts arbitrary partial key queries to the subset sum estimation problem and makes the theoretical tools for subset sum estimation practical. To realize desirable resource-accuracy tradeoffs in software and hardware platforms, we propose two techniques: (1) stochastic variance minimization to significantly reduce per-packet update delay, and (2) removing circular dependencies in the per-packet update logic to make the implementation hardware-friendly. We implement CocoSketch on four popular platforms (CPU, Open vSwitch, P4, and FPGA) and show that compared to baselines that use traditional single-key sketches, CocoSketch improves average packet processing throughput by 27.2x and accuracy by 10.4x when measuring six flow keys.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {207–222},
numpages = {16},
keywords = {P4, FPGA, sketch, arbitrary partial key query},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472905,
author = {Kim, Daehyeok and Nelson, Jacob and Ports, Dan R. K. and Sekar, Vyas and Seshan, Srinivasan},
title = {RedPlane: Enabling Fault-Tolerant Stateful in-Switch Applications},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472905},
doi = {10.1145/3452296.3472905},
abstract = {Many recent efforts have demonstrated the performance benefits of running datacenter functions (emph{e.g.,} NATs, load balancers, monitoring) on programmable switches. However, a key missing piece remains: fault tolerance. This is especially critical as the network is no longer stateless and pure endpoint recovery does not suffice. In this paper, we design and implement RedPlane, a fault-tolerant state store for stateful in-switch applications. This provides in-switch applications consistent access to their state, even if the switch they run on fails or traffic is rerouted to an alternative switch. We address key challenges in devising a practical, provably correct replication protocol and implementing it in the switch data plane. Our evaluations show that RedPlane incurs negligible overhead and enables end-to-end applications to rapidly recover from switch failures.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {223–244},
numpages = {22},
keywords = {state replication, programmable networks, programmable switches, fault tolerance},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472914,
author = {Tu, William and Wei, Yi-Hung and Antichi, Gianni and Pfaff, Ben},
title = {Revisiting the Open VSwitch Dataplane Ten Years Later},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472914},
doi = {10.1145/3452296.3472914},
abstract = {This paper shares our experience in supporting and running the Open vSwitch (OVS) software switch, as part of the NSX product for enterprise data center virtualization used by thousands of VMware customers. Starting in 2009, the OVS design split its code between tightly coupled kernel and userspace components. This split was necessary at the time for performance, but it caused maintainability problems that persist today. In addition, in-kernel packet processing is now much slower than newer options.To solve the problems caused by the user/kernel split, OVS must adopt a new architecture. We describe two possibilities that we explored, but did not adopt, one because it gives up compatibility with drivers and tools that are important to virtual data center operators, the other because it performs poorly. Instead, we endorse a third approach, based on a new Linux socket type called AF_XDP, which solves the maintainability problem in a compatible, performant way. The new code is already merged into the mainstream OVS repository. We include a thorough performance evaluation and a collection of lessons learned.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {245–257},
numpages = {13},
keywords = {OVS, eBPF, XDP, virtual switch},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472902,
author = {Zhu, Hang and Gupta, Varun and Ahuja, Satyajeet Singh and Tian, Yuandong and Zhang, Ying and Jin, Xin},
title = {Network Planning with Deep Reinforcement Learning},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472902},
doi = {10.1145/3452296.3472902},
abstract = {Network planning is critical to the performance, reliability and cost of web services. This problem is typically formulated as an Integer Linear Programming (ILP) problem. Today's practice relies on hand-tuned heuristics from human experts to address the scalability challenge of ILP solvers.In this paper, we propose NeuroPlan, a deep reinforcement learning (RL) approach to solve the network planning problem. This problem involves multi-step decision making and cost minimization, which can be naturally cast as a deep RL problem. We develop two important domain-specific techniques. First, we use a graph neural network (GNN) and a novel domain-specific node-link transformation for state encoding, in order to handle the dynamic nature of the evolving network topology during planning decision making. Second, we leverage a two-stage hybrid approach that first uses deep RL to prune the search space and then uses an ILP solver to find the optimal solution. This approach resembles today's practice, but avoids human experts with an RL agent in the first stage. Evaluation on real topologies and setups from large production networks demonstrates that NeuroPlan scales to large topologies beyond the capability of ILP solvers, and reduces the cost by up to 17% compared to hand-tuned heuristics.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {258–271},
numpages = {14},
keywords = {reinforcement learning, network planning, graph neural network},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472910,
author = {Yen, Jane and L\'{e}vai, Tam\'{a}s and Ye, Qinyuan and Ren, Xiang and Govindan, Ramesh and Raghavan, Barath},
title = {Semi-Automated Protocol Disambiguation and Code Generation},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472910},
doi = {10.1145/3452296.3472910},
abstract = {For decades, Internet protocols have been specified using natural language. Given the ambiguity inherent in such text, it is not surprising that protocol implementations have long exhibited bugs. In this paper, we apply natural language processing (NLP) to effect semi-automated generation of protocol implementations from specification text. Our system, Sage, can uncover ambiguous or under-specified sentences in specifications; once these are clarified by the author of the protocol specification, Sage can generate protocol code automatically.Using Sage, we discover 5 instances of ambiguity and 6 instances of under-specification in the ICMP RFC; after fixing these, Sage is able to automatically generate code that interoperates perfectly with Linux implementations. We show that Sage generalizes to sections of BFD, IGMP, and NTP and identify additional conceptual components that Sage needs to support to generalize to complete, complex protocols like BGP and TCP.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {272–286},
numpages = {15},
keywords = {natural language, protocol specifications},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472926,
author = {Zhang, Qizhen and Ng, Kelvin K. W. and Kazer, Charles and Yan, Shen and Sedoc, Jo\~{a}o and Liu, Vincent},
title = {MimicNet: Fast Performance Estimates for Data Center Networks with Machine Learning},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472926},
doi = {10.1145/3452296.3472926},
abstract = {At-scale evaluation of new data center network innovations is becoming increasingly intractable. This is true for testbeds, where few, if any, can afford a dedicated, full-scale replica of a data center. It is also true for simulations, which while originally designed for precisely this purpose, have struggled to cope with the size of today's networks. This paper presents an approach for quickly obtaining accurate performance estimates for large data center networks. Our system,MimicNet, provides users with the familiar abstraction of a packet-level simulation for a portion of the network while leveraging redundancy and recent advances in machine learning to quickly and accurately approximate portions of the network that are not directly visible. MimicNet can provide over two orders of magnitude speedup compared to regular simulation for a data center with thousands of servers. Even at this scale, MimicNet estimates of the tail FCT, throughput, and RTT are within 5% of the true results.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {287–304},
numpages = {18},
keywords = {machine learning, network modeling, approximation, network simulation, data center networks},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472936,
author = {Eliyahu, Tomer and Kazak, Yafim and Katz, Guy and Schapira, Michael},
title = {Verifying Learning-Augmented Systems},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472936},
doi = {10.1145/3452296.3472936},
abstract = {The application of deep reinforcement learning (DRL) to computer and networked systems has recently gained significant popularity. However, the obscurity of decisions by DRL policies renders it hard to ascertain that learning-augmented systems are safe to deploy, posing a significant obstacle to their real-world adoption. We observe that specific characteristics of recent applications of DRL to systems contexts give rise to an exciting opportunity: applying formal verification to establish that a given system provably satisfies designer/user-specified requirements, or to expose concrete counter-examples. We present whiRL, a platform for verifying DRL policies for systems, which combines recent advances in the verification of deep neural networks with scalable model checking techniques. To exemplify its usefulness, we employ whiRL to verify natural equirements from recently introduced learning-augmented systems for three real-world environments: Internet congestion control, adaptive video streaming, and job scheduling in compute clusters. Our evaluation shows that whiRL is capable of guaranteeing that natural requirements from these systems are satisfied, and of exposing specific scenarios in which other basic requirements are not.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {305–318},
numpages = {14},
keywords = {formal verification, deep reinforcement learning, deep learning, resource scheduling, congestion control, adaptive bitrate algorithms, networked systems, neural networks},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472898,
author = {Ros-Giralt, Jordi and Amsel, Noah and Yellamraju, Sruthi and Ezick, James and Lethin, Richard and Jiang, Yuang and Feng, Aosong and Tassiulas, Leandros and Wu, Zhenguo and Teh, Min Yee and Bergman, Keren},
title = {Designing Data Center Networks Using Bottleneck Structures},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472898},
doi = {10.1145/3452296.3472898},
abstract = {This paper provides a mathematical model of data center performance based on the recently introduced Quantitative Theory of Bottleneck Structures (QTBS). Using the model, we prove that if the traffic pattern is textit{interference-free}, there exists a unique optimal design that both minimizes maximum flow completion time and yields maximal system-wide throughput. We show that interference-free patterns correspond to the important set of patterns that display data locality properties and use these theoretical insights to study three widely used interconnects---fat-trees, folded-Clos and dragonfly topologies. We derive equations that describe the optimal design for each interconnect as a function of the traffic pattern. Our model predicts, for example, that a 3-level folded-Clos interconnect with radix 24 that routes 10% of the traffic through the spine links can reduce the number of switches and cabling at the core layer by 25% without any performance penalty. We present experiments using production TCP/IP code to empirically validate the results and provide tables for network designers to identify optimal designs as a function of the size of the interconnect and traffic pattern.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {319–348},
numpages = {30},
keywords = {design, max-min, bottleneck structure, data center, model},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472913,
author = {Namyar, Pooria and Supittayapornpong, Sucha and Zhang, Mingyang and Yu, Minlan and Govindan, Ramesh},
title = {A Throughput-Centric View of the Performance of Datacenter Topologies},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472913},
doi = {10.1145/3452296.3472913},
abstract = {While prior work has explored many proposed datacenter designs, only two designs, Clos-based and expander-based, are generally considered practical because they can scale using commodity switching chips. Prior work has used two different metrics, bisection bandwidth and throughput, for evaluating these topologies at scale. Little is known, theoretically or practically, how these metrics relate to each other. Exploiting characteristics of these topologies, we prove an upper bound on their throughput, then show that this upper bound better estimates worst-case throughput than all previously proposed throughput estimators and scales better than most of them. Using this upper bound, we show that for expander-based topologies, unlike Clos, beyond a certain size of the network, no topology can have full throughput, even if it has full bisection bandwidth; in fact, even relatively small expander-based topologies fail to achieve full throughput. We conclude by showing that using throughput to evaluate datacenter performance instead of bisection bandwidth can alter conclusions in prior work about datacenter cost, manageability, and reliability.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {349–369},
numpages = {21},
keywords = {throughput, data centers, network management, Clos topologies},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472899,
author = {Zhang, Yiran and Liu, Yifan and Meng, Qingkai and Ren, Fengyuan},
title = {Congestion Detection in Lossless Networks},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472899},
doi = {10.1145/3452296.3472899},
abstract = {Congestion detection is the cornerstone of end-to-end congestion control. Through in-depth observations and understandings, we reveal that existing congestion detection mechanisms in mainstream lossless networks (i.e., Converged Enhanced Ethernet and InfiniBand) are improper, due to failing to cognize the interaction between hop-by-hop flow controls and congestion detection behaviors in switches. We define ternary states of switch ports and present Ternary Congestion Detection (TCD) for mainstream lossless networks. Testbed and extensive simulations demonstrate that TCD can detect congestion ports accurately and identify flows contributing to congestion as well as flows only affected by hop-by-hop flow controls. Meanwhile, we shed light on how to incorporate TCD with rate control. Case studies show that existing congestion control algorithms can achieve 3.3x and 2.0x better median and 99th-percentile FCT slowdown by combining with TCD.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {370–383},
numpages = {14},
keywords = {flow control, congestion detection, lossless networks},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472927,
author = {Yan, Siyu and Wang, Xiaoliang and Zheng, Xiaolong and Xia, Yinben and Liu, Derui and Deng, Weishan},
title = {ACC: Automatic ECN Tuning for High-Speed Datacenter Networks},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472927},
doi = {10.1145/3452296.3472927},
abstract = {For the widely deployed ECN-based congestion control schemes, the marking threshold is the key to deliver high bandwidth and low latency. However, due to traffic dynamics in the high-speed production networks, it is difficult to maintain persistent performance by using the static ECN setting. To meet the operational challenge, in this paper we report the design and implementation of an automatic run-time optimization scheme, ACC, which leverages the multi-agent reinforcement learning technique to dynamically adjust the marking threshold at each switch. The proposed approach works in a distributed fashion and combines offline and online training to adapt to dynamic traffic patterns. It can be easily deployed based on the common features supported by major commodity switching chips. Both testbed experiments and large-scale simulations have shown that ACC achieves low flow completion time (FCT) for both mice flows and elephant flows at line-rate. Under heterogeneous production environments with 300 machines, compared with the well-tuned static ECN settings, ACC achieves up to 20% improvement on IOPS and 30% lower FCT for storage service. ACC has been applied in high-speed datacenter networks and significantly simplifies the network operations.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {384–397},
numpages = {14},
keywords = {ECN, congestion control, datacenter network, AQM},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472891,
author = {Koch, Thomas and Katz-Bassett, Ethan and Heidemann, John and Calder, Matt and Ardi, Calvin and Li, Ke},
title = {Anycast In Context: A Tale of Two Systems},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472891},
doi = {10.1145/3452296.3472891},
abstract = {Anycast is used to serve content including web pages and DNS, and anycast deployments are growing. However, prior work examining root DNS suggests anycast deployments incur significant inflation, with users often routed to suboptimal sites. We reassess anycast performance, first extending prior analysis on inflation in the root DNS. We show that inflation is very common in root DNS, affecting more than 95% of users. However, we then show root DNS latency emph{hardly matters} to users because caching is so effective. These findings lead us to question: is inflation inherent to anycast, or can inflation be limited when it matters? To answer this question, we consider Microsoft's anycast CDN serving latency-sensitive content. Here, latency matters orders of magnitude more than for root DNS. Perhaps because of this need, only 35% of CDN users experience any inflation, and the amount they experience is smaller than root DNS. We show that CDN anycast latency has little inflation due to extensive peering and engineering. These results suggest prior claims of anycast inefficiency reflect experiments on a single application rather than anycast's technical potential, and they demonstrate the importance of context when measuring system performance.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {398–417},
numpages = {20},
keywords = {Anycast, routing, root DNS, latency, CDN},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472893,
author = {Zheng, Zhilong and Ma, Yunfei and Liu, Yanmei and Yang, Furong and Li, Zhenyu and Zhang, Yuanbo and Zhang, Jiuhai and Shi, Wei and Chen, Wentao and Li, Ding and An, Qing and Hong, Hai and Liu, Hongqiang Harry and Zhang, Ming},
title = {XLINK: QoE-Driven Multi-Path QUIC Transport in Large-Scale Video Services},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472893},
doi = {10.1145/3452296.3472893},
abstract = {We report XLINK, a multi-path QUIC video transport solution with experiments in Taobao short videos. XLINK is designed to meet two operational challenges at the same time: (1) Optimized user-perceived quality of experience (QoE) in terms of robustness, smoothness, responsiveness, and mobility and (2) Minimized cost overhead for service providers (typically CDNs). The core of XLINK is to take the opportunity of QUIC as a user-space protocol and directly capture user-perceived video QoE intent to control multi-path scheduling and management. We overcome major hurdles such as multi-path head-of-line blocking, network heterogeneity, and rapid link variations and balance cost and performance.To the best of our knowledge, XLINK is the first large-scale experimental study of multi-path QUIC video services in production environments. We present the results of over 3 million e-commerce product short-video plays from consumers who upgraded to Taobao android app with XLINK. Our study shows that compared to single-path QUIC, XLINK achieved 19 to 50% improvement in the 99-th percentile video-chunk request completion time, 32% improvement in the 99-th percentile first-video-frame latency, 23 to 67% improvement in the re-buffering rate at the expense of 2.1% redundant traffic.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {418–432},
numpages = {15},
keywords = {scheduling, video, QUIC, QoE, wireless transport, multi-path},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472922,
author = {Fayed, Marwan and Bauer, Lorenz and Giotsas, Vasileios and Kerola, Sami and Majkowski, Marek and Odintsov, Pavel and Sitnicki, Jakub and Chung, Taejoong and Levin, Dave and Mislove, Alan and Wood, Christopher A. and Sullivan, Nick},
title = {The Ties That Un-Bind: Decoupling IP from Web Services and Sockets for Robust Addressing Agility at CDN-Scale},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472922},
doi = {10.1145/3452296.3472922},
abstract = {The couplings between IP addresses, names of content or services, and socket interfaces, are too tight. This impedes system manageability, growth, and overall provisioning. In turn, large-scale content providers are forced to use staggering numbers of addresses, ultimately leading to address exhaustion (IPv4) and inefficiency (IPv6).In this paper, we revisit IP bindings, entirely. We attempt to evolve addressing conventions by decoupling IP in DNS and from network sockets. Alongside technologies such as SNI and ECMP, a new architecture emerges that ``unbinds'' IP from services and servers, thereby returning IP's role to merely that of reachability. The architecture is under evaluation at a major CDN in multiple datacenters. We show that addresses can be generated randomly emph{per-query}, for 20M+ domains and services, from as few as ~4K addresses, 256 addresses, and even emph{one} IP address. We explain why this approach is transparent to routing, L4/L7 load-balancers, distributed caching, and all surrounding systems -- and is emph{highly desirable}. Our experience suggests that many network-oriented systems and services (e.g., route leak mitigation, denial of service, measurement) could be improved, and new ones designed, if built with addressing agility.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {433–446},
numpages = {14},
keywords = {provisioning, content distribution, addressing, programmable sockets},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472935,
author = {Zhang, Xiao and Sen, Tanmoy and Zhang, Zheyuan and April, Tim and Chandrasekaran, Balakrishnan and Choffnes, David and Maggs, Bruce M. and Shen, Haiying and Sitaraman, Ramesh K. and Yang, Xiaowei},
title = {AnyOpt: Predicting and Optimizing IP Anycast Performance},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472935},
doi = {10.1145/3452296.3472935},
abstract = {The key to optimizing the performance of an anycast-based system (e.g., the root DNS or a CDN) is choosing the right set of sites to announce the anycast prefix. One challenge here is predicting catchments. A na\"{\i}ve approach is to advertise the prefix from all subsets of available sites and choose the best-performing subset, but this does not scale well. We demonstrate that by conducting pairwise experiments between sites peering with tier-1 networks, we can predict the catchments that would result if we announce to any subset of the sites. We prove that our method is effective in a simplified model of BGP, consistent with common BGP routing policies, and evaluate it in a real-world testbed. We then present AnyOpt, a system that predicts anycast catchments. Using AnyOpt, a network operator can find a subset of anycast sites that minimizes client latency without using the na\"{\i}ve approach. In an experiment using 15 sites, each peering with one of six transit providers, AnyOpt predicted site catchments of 15,300 clients with 94.7% accuracy and client RTTs with a mean error of 4.6%. AnyOpt identified a subset of 12 sites, announcing to which lowers the mean RTT to clients by 33ms compared to a greedy approach that enables the same number of sites with the lowest average unicast latency.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {447–462},
numpages = {16},
keywords = {routing, performance optimization, Anycast, BGP},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472917,
author = {Mazaheri, Mohammad Hossein and Chen, Alex and Abari, Omid},
title = {MmTag: A Millimeter Wave Backscatter Network},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472917},
doi = {10.1145/3452296.3472917},
abstract = {Recent advances in IoT, machine learning and cloud computing have placed a huge strain on wireless networks. In particular, many emerging applications require streaming rich content (such as videos) in real time, while they are constrained by energy sources. A wireless network which supports high data-rate while consuming low-power would be very attractive for these applications. Unfortunately, existing wireless networks do not satisfy this requirement. For example, WiFi backscatter and Bluetooth networks have very low power consumption, but their data-rate is very limited (less than a Mbps). On the other hand, modern WiFi and mmWave networks support high throughput, but have a high power consumption (more than a watt).To address this problem, we present mmTag, a novel mmWave backscatter network which enables low-power high-throughput wireless links for emerging applications. mmTag is a backscatter system which operates in the mmWave frequency bands. mmTag addresses the key challenges that prevent existing backscatter networks from operating at mmWave bands. We implemented mmTag and evaluated its performance empirically. Our results show that mmTag is capable of achieving 1 Gbps and 100 Mbps at 4.6 m and 8 m, respectively, while consuming only 2.4 nJ/bit.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {463–474},
numpages = {12},
keywords = {wireless, mmWave, internet of things, low power, IoT, backscatter},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472920,
author = {Cho, Hsun-Wei and Shin, Kang G.},
title = {BlueFi: Bluetooth over WiFi},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472920},
doi = {10.1145/3452296.3472920},
abstract = {Bluetooth and WiFi are the two dominant technologies enabling the communication of mobile and IoT devices. Built with specific design goals and principles, they are vastly different, each using its own hardware and software. Thus, they are not interoperable and require different hardware.One may, therefore, ask a simple, yet seemingly impossible question: “Can we transmit Bluetooth packets on commercial off-the-shelf (COTS) WiFi hardware?” We answer this question positively by designing, implementing and demonstrating a novel system called BlueFi. It can readily run on existing, widely-deployed WiFi devices without modifying NIC firmware/hardware. BlueFi works by reversing the signal processing of WiFi hardware and finds special 802.11n packets that are decodable by unmodified Bluetooth devices. With BlueFi, every 802.11n device can be used simultaneously as a Bluetooth device, which instantly increases the coverage of Bluetooth, thanks to the omnipresence of WiFi devices. BlueFi is particularly useful for WiFi-only devices or environments.We implement and evaluate BlueFi on devices with widely-adopted WiFi chips. We also construct two prevalent end-to-end apps — Bluetooth beacon and audio — to showcase the practical use of BlueFi. The former allows ordinary APs to send location beacons; the latter enables WiFi chips to stream Bluetooth audio in real time.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {475–487},
numpages = {13},
keywords = {cross-technology communication, Bluetooth, WiFi},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472924,
author = {Jain, Ish Kumar and Subbaraman, Raghav and Bharadia, Dinesh},
title = {Two Beams Are Better than One: Towards Reliable and High Throughput MmWave Links},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472924},
doi = {10.1145/3452296.3472924},
abstract = {Millimeter-wave communication with high throughput and high reliability is poised to be a gamechanger for V2X and VR applications. However, mmWave links are notorious for low reliability since they suffer from frequent outages due to blockage and user mobility. We build mmReliable, a reliable mmWave system that implements multi-beamforming and user tracking to handle environmental vulnerabilities. It creates constructive multi-beam patterns and optimizes their angle, phase, and amplitude to maximize the signal strength at the receiver. Multi-beam links are reliable since they are resilient to occasional blockages of few constituent beams compared to a single-beam system. We implement mmReliable on a 28 GHz testbed with 400 MHz bandwidth, and a 64 element phased array supporting 5G NR waveforms. Rigorous indoor and outdoor experiments demonstrate that mmReliable achieves close to 100% reliability providing 2.3x improvement in the throughput-reliability product than single-beam systems.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {488–502},
numpages = {15},
keywords = {reliability, phased arrays, 5G NR, throughput, analog beamforming, millimeter-wave, multi-beam, tracking, blockage, mobility},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472931,
author = {Shahid, Muhammad Osama and Philipose, Millan and Chintalapudi, Krishna and Banerjee, Suman and Krishnaswamy, Bhuvana},
title = {Concurrent Interference Cancellation: Decoding Multi-Packet Collisions in LoRa},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472931},
doi = {10.1145/3452296.3472931},
abstract = {LoRa has seen widespread adoption as a long range IoT technology. As the number of LoRa deployments grow, packet collisions undermine its overall network throughput. In this paper, we propose a novel interference cancellation technique -- Concurrent Interference Cancellation (CIC), that enables concurrent decoding of multiple collided LoRa packets. CIC fundamentally differs from existing approaches as it demodulates symbols by canceling out all other interfering symbols. It achieves this cancellation by carefully selecting a set of sub-symbols -- pieces of the original symbol such that no interfering symbol is common across all sub-symbols in this set. Thus, after demodulating each sub-symbol, an intersection across their spectra cancels out all the interfering symbols. Through LoRa deployments using COTS devices, we demonstrate that CIC can increase the network capacity of standard LoRa by up to 10x and up to 4x over the state-of-the-art research. While beneficial across all scenarios, CIC has even more significant benefits under low SNR conditions that are common to LoRa deployments, in which prior approaches appear to perform quite poorly.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {503–515},
numpages = {13},
keywords = {interference cancellation, LoRa, multi-packet collisions},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472928,
author = {Gigis, Petros and Calder, Matt and Manassakis, Lefteris and Nomikos, George and Kotronis, Vasileios and Dimitropoulos, Xenofontas and Katz-Bassett, Ethan and Smaragdakis, Georgios},
title = {Seven Years in the Life of Hypergiants' off-Nets},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472928},
doi = {10.1145/3452296.3472928},
abstract = {Content Hypergiants deliver the vast majority of Internet traffic to end users. In recent years, some have invested heavily in deploying services and servers inside end-user networks. With several dozen Hypergiants and thousands of servers deployed inside networks, these off-net (meaning outside the Hypergiant networks) deployments change the structure of the Internet. Previous efforts to study them have relied on proprietary data or specialized per-Hypergiant measurement techniques that neither scale nor generalize, providing a limited view of content delivery on today's Internet.In this paper, we develop a generic and easy to implement methodology to measure the expansion of Hypergiants' off-nets. Our key observation is that Hypergiants increasingly encrypt their traffic to protect their customers' privacy. Thus, we can analyze publicly available Internet-wide scans of port 443 and retrieve TLS certificates to discover which IP addresses host Hypergiant certificates in order to infer the networks hosting off-nets for the corresponding Hypergiants. Our results show that the number of networks hosting Hypergiant off-nets has tripled from 2013 to 2021, reaching 4.5k networks. The largest Hypergiants dominate these deployments, with almost all of these networks hosting an off-net for at least one -- and increasingly two or more -- of Google, Netflix, Facebook, or Akamai. These four Hypergiants have off-nets within networks that provide access to a significant fraction of end user population.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {516–533},
numpages = {18},
keywords = {content delivery networks, server deployment, Hypergiants, TLS},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472895,
author = {Singh, Rachee and Bjorner, Nikolaj and Shoham, Sharon and Yin, Yawei and Arnold, John and Gaudette, Jamie},
title = {Cost-Effective Capacity Provisioning in Wide Area Networks with Shoofly},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472895},
doi = {10.1145/3452296.3472895},
abstract = {In this work we propose Shoofly, a network design tool that minimizes hardware costs of provisioning long-haul capacity by optically bypassing network hops where conversion of signals from optical to electrical domain is unnecessary and uneconomical. Shoofly leverages optical signal quality and traffic demand telemetry from a large commercial cloud provider to identify optical bypasses in the cloud WAN that reduce the hardware cost of long-haul capacity by 40%. A key challenge is that optical bypasses cause signals to travel longer distances on fiber before re-generation, potentially reducing link capacities and resilience to optical link failures. Despite these challenges, Shoofly provisions bypass-enabled topologies that meet 8X the present-day demands using existing network hardware. Even under aggressive stochastic and deterministic link failure scenarios, these topologies save 32% of the cost of long-haul capacity.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {534–546},
numpages = {13},
keywords = {optical bypass, traffic engineering, backbone design},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472918,
author = {Ahuja, Satyajeet Singh and Gupta, Varun and Dangui, Vinayak and Bali, Soshant and Gopalan, Abishek and Zhong, Hao and Lapukhov, Petr and Xia, Yiting and Zhang, Ying},
title = {Capacity-Efficient and Uncertainty-Resilient Backbone Network Planning with Hose},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472918},
doi = {10.1145/3452296.3472918},
abstract = {This paper presents Facebook's design and operational experience of a Hose-based backbone network planning system. This initial adoption of the Hose model in network planning is driven by the capacity and demand uncertainty pressure of backbone expansion. Since the Hose model abstracts the aggregated traffic demand per site, peak traffic flows at different times can be multiplexed to save capacity and buffer traffic spikes. Our core design involves heuristic algorithms to select Hose-compliant traffic matrices and cross-layer optimization between the optical and IP networks. We evaluate the system performance in production and share insights from years of production experience. Hose-based network planning can save 17.4% capacity and drops 75% less traffic under fiber cuts. As the first study of Hose in network planning, our work has the potential to inspire follow-up research.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {547–559},
numpages = {13},
keywords = {network modeling, wide-area networks, network planning, network optimization},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472921,
author = {Zhong, Zhizhen and Ghobadi, Manya and Khaddaj, Alaa and Leach, Jonathan and Xia, Yiting and Zhang, Ying},
title = {ARROW: Restoration-Aware Traffic Engineering},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472921},
doi = {10.1145/3452296.3472921},
abstract = {Fiber cut events reduce the capacity of wide-area networks (WANs) by several Tbps. In this paper, we revive the lost capacity by reconfiguring the wavelengths from cut fibers into healthy fibers. We highlight two challenges that made prior solutions impractical and propose a system called Arrow to address them. First, our measurements show that contrary to common belief, in most cases, the lost capacity is only partially restorable. This poses a cross-layer challenge from the Traffic Engineering (TE) perspective that has not been considered before: “Which IP links should be restored and by how much to best match the TE objective?” To address this challenge, Arrow's restoration-aware TE system takes a set of partial restoration candidates (that we call LotteryTickets) as input and proactively finds the best restoration plan. Second, prior work has not considered the reconfiguration latency of amplifiers. However, in practical settings, amplifiers add tens of minutes of reconfiguration delay. To enable fast and practical restoration, Arrow leverages optical noise loading and bypasses amplifier reconfiguration altogether. We evaluate Arrow using large-scale simulations and a testbed. Our testbed demonstrates Arrow's end-to-end restoration latency is eight seconds. Our large-scale simulations compare Arrow to the state-of-the-art TE schemes and show it can support 2.0x--2.4x more demand without compromising 99.99% availability.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {560–579},
numpages = {20},
keywords = {wide-area networks, optical restoration, network optimization, traffic engineering, randomized rounding},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472894,
author = {Foukas, Xenofon and Radunovic, Bozidar},
title = {Concordia: Teaching the 5G VRAN to Share Compute},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472894},
doi = {10.1145/3452296.3472894},
abstract = {Virtualized Radio Access Network (vRAN) offers a cost-efficient solution for running the 5G RAN as a virtualized network function (VNF) on commodity hardware. The vRAN is more efficient than traditional RANs, as it multiplexes several base station workloads on the same compute hardware. Our measurements show that, whilst this multiplexing provides efficiency gains, more than 50% of the CPU cycles in typical vRAN settings still remain unused. A way to further improve CPU utilization is to collocate the vRAN with general-purpose workloads. However, to maintain performance, vRAN tasks have sub-millisecond latency requirements that have to be met 99.999% of times. We show that this is difficult to achieve with existing systems. We propose Concordia, a userspace deadline scheduling framework for the vRAN on Linux. Concordia builds prediction models using quantile decision trees to predict the worst case execution times of vRAN signal processing tasks. The Concordia scheduler is fast (runs every 20 us) and the prediction models are accurate, enabling the system to reserve a minimum number of cores required for vRAN tasks, leaving the rest for general-purpose workloads. We evaluate Concordia on a commercial-grade reference vRAN platform. We show that it meets the 99.999% reliability requirements and reclaims more than 70% of idle CPU cycles without affecting the RAN performance.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {580–596},
numpages = {17},
keywords = {edge computing, prediction model, 5G, machine learning, NFV, real-time scheduling, vRAN, mobile networks},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472908,
author = {Li, Yang and Lin, Hao and Li, Zhenhua and Liu, Yunhao and Qian, Feng and Gong, Liangyi and Xin, Xianlong and Xu, Tianyin},
title = {A Nationwide Study on Cellular Reliability: Measurement, Analysis, and Enhancements},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472908},
doi = {10.1145/3452296.3472908},
abstract = {With recent advances on cellular technologies (such as 5G) that push the boundary of cellular performance, cellular reliability has become a key concern of cellular technology adoption and deployment. However, this fundamental concern has never been addressed due to the challenges of measuring cellular reliability on mobile devices and the cost of conducting large-scale measurements. This paper closes the knowledge gap by presenting the first large-scale, in-depth study on cellular reliability with more than 70 million Android phones across 34 different hardware models. Our study identifies the critical factors that affect cellular reliability and clears up misleading intuitions indicated by common wisdom. In particular, our study pinpoints that software reliability defects are among the main root causes of cellular data connection failures. Our work provides actionable insights for improving cellular reliability at scale. More importantly, we have built on our insights to develop enhancements that effectively address cellular reliability issues with remarkable real-world impact---our optimizations on Android's cellular implementations have effectively reduced 40% cellular connection failures for 5G phones and 36% failure duration across all phones.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {597–609},
numpages = {13},
keywords = {reliability measurement, mobile operating system, cellular network, 5G network, cellular connection management},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472923,
author = {Narayanan, Arvind and Zhang, Xumiao and Zhu, Ruiyang and Hassan, Ahmad and Jin, Shuowei and Zhu, Xiao and Zhang, Xiaoxuan and Rybkin, Denis and Yang, Zhengxuan and Mao, Zhuoqing Morley and Qian, Feng and Zhang, Zhi-Li},
title = {A Variegated Look at 5G in the Wild: Performance, Power, and QoE Implications},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472923},
doi = {10.1145/3452296.3472923},
abstract = {Motivated by the rapid deployment of 5G, we carry out an in-depth measurement study of the performance, power consumption, and application quality-of-experience (QoE) of commercial 5G networks in the wild. We examine different 5G carriers, deployment schemes (Non-Standalone, NSA vs. Standalone, SA), radio bands (mmWave and sub 6-GHz), protocol configurations (_e.g._ Radio Resource Control state transitions), mobility patterns (stationary, walking, driving), client devices (_i.e._ User Equipment), and upper-layer applications (file download, video streaming, and web browsing). Our findings reveal key characteristics of commercial 5G in terms of throughput, latency, handover behaviors, radio state transitions, and radio power consumption under the above diverse scenarios, with detailed comparisons to 4G/LTE networks. Furthermore, our study provides key insights into how upper-layer applications should best utilize 5G by balancing the critical tradeoff between performance and energy consumption, as well as by taking into account the availability of both network and computation resources. We have released the datasets and tools of our study at https://github.com/SIGCOMM21-5G/artifact.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {610–625},
numpages = {16},
keywords = {video streaming, 5G, energy efficiency, mmWave, network measurement, dataset, power model, latency, power characteristics},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3473336,
author = {Luo, Zhihong and Fu, Silvery and Theis, Mark and Hasan, Shaddi and Ratnasamy, Sylvia and Shenker, Scott},
title = {Democratizing Cellular Access with CellBricks},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3473336},
doi = {10.1145/3452296.3473336},
abstract = {Markets in which competition thrives are good for both consumers and innovation but, unfortunately, competition is not thriving in the increasingly important cellular market. We propose CellBricks, a novel cellular architecture that lowers the barrier to entry for new operators by enabling users to consume access on-demand from any available cellular operator — small or large, trusted or untrusted. CellBricks achieves this by moving support for mobility and user management (authentication and billing) out of the network and into end hosts. These changes, we believe, bring valuable benefits beyond enabling competition: they lead to a cellular infrastructure that is simpler and more efficient.We design, build, and evaluate CellBricks, showing that its benefits come at little-to-no cost in performance, with application performance overhead between -1.6% to 3.1% of that achieved by current cellular infrastructure.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {626–640},
numpages = {15},
keywords = {democratization, host-driven mobility, cellular architecture},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472897,
author = {Zhuang, Siyuan and Li, Zhuohan and Zhuo, Danyang and Wang, Stephanie and Liang, Eric and Nishihara, Robert and Moritz, Philipp and Stoica, Ion},
title = {Hoplite: Efficient and Fault-Tolerant Collective Communication for Task-Based Distributed Systems},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472897},
doi = {10.1145/3452296.3472897},
abstract = {Task-based distributed frameworks (e.g., Ray, Dask, Hydro) have become increasingly popular for distributed applications that contain asynchronous and dynamic workloads, including asynchronous gradient descent, reinforcement learning, and model serving. As more data-intensive applications move to run on top of task-based systems, collective communication efficiency has become an important problem. Unfortunately, traditional collective communication libraries (e.g., MPI, Horovod, NCCL) are an ill fit, because they require the communication schedule to be known before runtime and they do not provide fault tolerance.We design and implement Hoplite, an efficient and fault-tolerant collective communication layer for task-based distributed systems. Our key technique is to compute data transfer schedules on the fly and execute the schedules efficiently through fine-grained pipelining. At the same time, when a task fails, the data transfer schedule adapts quickly to allow other tasks to keep making progress. We apply Hoplite to a popular task-based distributed framework, Ray. We show that Hoplite speeds up asynchronous stochastic gradient descent, reinforcement learning, and serving an ensemble of machine learning models that are difficult to execute efficiently with traditional collective communication by up to 7.8x, 3.9x, and 3.3x, respectively.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {641–656},
numpages = {16},
keywords = {distributed systems, collective communication},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472900,
author = {Khani, Mehrdad and Ghobadi, Manya and Alizadeh, Mohammad and Zhu, Ziyi and Glick, Madeleine and Bergman, Keren and Vahdat, Amin and Klenk, Benjamin and Ebrahimi, Eiman},
title = {SiP-ML: High-Bandwidth Optical Network Interconnects for Machine Learning Training},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472900},
doi = {10.1145/3452296.3472900},
abstract = {This paper proposes optical network interconnects as a key enabler for building high-bandwidth ML training clusters with strong scaling properties. Our design, called SiP-ML, accelerates the training time of popular DNN models using silicon photonics links capable of providing multiple terabits-per-second of bandwidth per GPU. SiP-ML partitions the training job across GPUs with hybrid data and model parallelism while ensuring the communication pattern can be supported efficiently on the network interconnect. We develop task partitioning and device placement methods that take the degree and reconfiguration latency of optical interconnects into account. Simulations using real DNN models show that, compared to the state-of-the-art electrical networks, our approach improves training time by 1.3--9.1x.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {657–675},
numpages = {19},
keywords = {distributed machine learning, reconfigurable networks, optical networks, silicon photonics},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472904,
author = {Fei, Jiawei and Ho, Chen-Yu and Sahu, Atal N. and Canini, Marco and Sapio, Amedeo},
title = {Efficient Sparse Collective Communication and Its Application to Accelerate Distributed Deep Learning},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472904},
doi = {10.1145/3452296.3472904},
abstract = {Efficient collective communication is crucial to parallel-computing applications such as distributed training of large-scale recommendation systems and natural language processing models. Existing collective communication libraries focus on optimizing operations for dense inputs, resulting in transmissions of many zeros when inputs are sparse. This counters current trends that see increasing data sparsity in large models.We propose OmniReduce, an efficient streaming aggregation system that exploits sparsity to maximize effective bandwidth use by sending only non-zero data blocks. We demonstrate that this idea is beneficial and accelerates distributed training by up to 8.2x. Even at 100 Gbps, OmniReduce delivers 1.4--2.9x better performance for network-bottlenecked DNNs.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {676–691},
numpages = {16},
keywords = {distributed training, deep learning},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472916,
author = {Jyothi, Sangeetha Abdu},
title = {Solar Superstorms: Planning for an Internet Apocalypse},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472916},
doi = {10.1145/3452296.3472916},
abstract = {Black swan events are hard-to-predict rare events that can significantly alter the course of our lives. The Internet has played a key role in helping us deal with the coronavirus pandemic, a recent black swan event. However, Internet researchers and operators are mostly blind to another black swan event that poses a direct threat to Internet infrastructure. In this paper, we investigate the impact of solar superstorms that can potentially cause large-scale Internet outages covering the entire globe and lasting several months. We discuss the challenges posed by such activity and currently available mitigation techniques. Using real-world datasets, we analyze the robustness of the current Internet infrastructure and show that submarine cables are at greater risk of failure compared to land cables. Moreover, the US has a higher risk for disconnection compared to Asia. Finally, we lay out steps for improving the Internet's resiliency.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {692–704},
numpages = {13},
keywords = {solar storms, internet topology, internet resilience},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472911,
author = {Ding, Yi and Yang, Yu and Jiang, Wenchao and Liu, Yunhuai and He, Tian and Zhang, Desheng},
title = {Nationwide Deployment and Operation of a Virtual Arrival Detection System in the Wild},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472911},
doi = {10.1145/3452296.3472911},
abstract = {We report a 30-month nationwide deployment and operation study of an indoor arrival detection system based on Bluetooth Low Energy called VALID in 364 Chinese cities. VALID is pilot-studied, deployed, and operated in the wild to infer real-time indoor arrival status of couriers, and improve their status reporting behavior based on the detection. During its full nationwide operation (2018/12- 2021/01), VALID consists of virtual devices at 3 million shops and restaurants, where 530,859 of them are in multi-story malls and markets to infer and influence 1 million couriers' behavior, and assist the scheduling of 3.9 billion orders for 186 million customers. Although indoor arrival detection is straightforward in controlled environments, the scale of our platform makes the cost prohibitively high. In this work, we explore to use merchants' smartphones under their consent as a virtual infrastructure to design, build, deploy, and operate VALID from in-lab conception to nationwide operation in three phases for 30 months. We consider metrics including system evolution, reliability, utility, participation, energy, privacy, monetary benefits, along with couriers' behavior changes. We share three lessons and their implications for similar wireless sensing or communication systems with large geospatial operations.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {705–717},
numpages = {13},
keywords = {operational system, nationwide deployment, Bluetooth sensing, arrival detection},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472930,
author = {Lutu, Andra and Perino, Diego and Bagnulo, Marcelo and Bustamante, Fabi\'{a}n E.},
title = {Insights from Operating an IP Exchange Provider},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472930},
doi = {10.1145/3452296.3472930},
abstract = {IP Exchange Providers (IPX-Ps) offer to their customers (e.g., mobile or IoT service providers) global data roaming and support for a variety of emerging services. They peer to other IPX-Ps and form the IPX network, which interconnects 800 MNOs worldwide offering their customers access to mobile services in any other country. Despite the importance of IPX-Ps, little is known about their operations and performance. In this paper, we shed light on these opaque providers by analyzing a large IPX-P with more than 100 PoPs in 40+ countries, with a particularly strong presence in America and Europe. Specifically, we characterize the traffic and performance of the main infrastructures of the IPX-P (i.e., 2-3-4G signaling and GTP tunneling), and provide implications for its operation, as well as for the IPX-P's customers. Our analysis is based on statistics we collected during two time periods (i.e., prior and during COVID-19 pandemic) and includes insights on the main service the platform supports (i.e., IoT and data roaming), traffic breakdown and geographical/temporal distribution, communication performance (e.g., tunnel setup time, RTTs). Our results constitute a step towards advancing the understanding of IPX-Ps at their core, and provide guidelines for their operations and customer satisfaction.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {718–730},
numpages = {13},
keywords = {mobile networks, IPX provider, measurements, performance analysis, international mobile roaming},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472903,
author = {Sonchack, John and Loehr, Devon and Rexford, Jennifer and Walker, David},
title = {Lucid: A Language for Control in the Data Plane},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472903},
doi = {10.1145/3452296.3472903},
abstract = {Programmable switch hardware makes it possible to move fine-grained control logic inside the network data plane, improving performance for a wide range of applications. However, applications with integrated control are inherently hard to write in existing data-plane programming languages such as P4. This paper presents Lucid, a language that raises the level of abstraction for putting control functionality in the data plane. Lucid introduces abstractions that make it easy to write sophisticated data-plane applications with interleaved packet-handling and control logic, specialized type and syntax systems that prevent programmer bugs related to data-plane state, and an open-sourced compiler that translates Lucid programs into P4 optimized for the Intel Tofino. These features make Lucid general and easy to use, as we demonstrate by writing a suite of ten different data-plane applications in Lucid. Working prototypes take well under an hour to write, even for a programmer without prior Tofino experience, have around 10x fewer lines of code compared to P4, and compile efficiently to real hardware. In a stateful firewall written in Lucid, we find that moving control from a switch's CPU to its data-plane processor using Lucid reduces the latency of performance-sensitive operations by over 300X.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {731–747},
numpages = {17},
keywords = {ordered type-and-effect-system, syntactic constraints, data plane programming abstractions, network control},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472925,
author = {Tang, Alan and Kakarla, Siva Kesava Reddy and Beckett, Ryan and Zhai, Ennan and Brown, Matt and Millstein, Todd and Tamir, Yuval and Varghese, George},
title = {Campion: Debugging Router Configuration Differences},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472925},
doi = {10.1145/3452296.3472925},
abstract = {We present a new approach for debugging two router configurations that are intended to be behaviorally equivalent. Existing router verification techniques cannot identify all differences or localize those differences to relevant configuration lines. Our approach addresses these limitations through a _modular_ analysis, which separately analyzes pairs of corresponding configuration components. It handles all router components that affect routing and forwarding, including configuration for BGP, OSPF, static routes, route maps and ACLs. Further, for many configuration components our modular approach enables simple _structural equivalence_ checks to be used without additional loss of precision versus modular semantic checks, aiding both efficiency and error localization. We implemented this approach in the tool Campion and applied it to debugging pairs of backup routers from different manufacturers and validating replacement of critical routers. Campion analyzed 30 proposed router replacements in a production cloud network and proactively detected four configuration bugs, including a route reflector bug that could have caused a severe outage. Campion also found multiple differences between backup routers from different vendors in a university network. These were undetected for three years, and depended on subtle semantic differences that the operators said they were "highly unlikely" to detect by "just eyeballing the configs."},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {748–761},
numpages = {14},
keywords = {modular reasoning, error localization, equivalence checking, network verification},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472938,
author = {Ferreira, Tiago and Brewton, Harrison and D'Antoni, Loris and Silva, Alexandra},
title = {Prognosis: Closed-Box Analysis of Network Protocol Implementations},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472938},
doi = {10.1145/3452296.3472938},
abstract = {We present Prognosis, a framework offering automated closed-box learning and analysis of models of network protocol implementations. Prognosis can learn models that vary in abstraction level from simple deterministic automata to models containing data operations, such as register updates, and can be used to unlock a variety of analysis techniques -- model checking temporal properties, computing differences between models of two implementations of the same protocol, or improving testing via model-based test generation. Prognosis is modular and easily adaptable to different protocols (e.g. TCP and QUIC) and their implementations. We use Prognosis to learn models of (parts of) three QUIC implementations -- Quiche (Cloudflare), Google QUIC, and Facebook mvfst -- and use these models to analyse the differences between the various implementations. Our analysis provides insights into different design choices and uncovers potential bugs. Concretely, we have found critical bugs in multiple QUIC implementations, which have been acknowledged by the developers.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {762–774},
numpages = {13},
keywords = {bug finding, model learning, protocol state machines, varied abstraction modelling, synthesis},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472941,
author = {Xu, Xieyang and Beckett, Ryan and Jayaraman, Karthick and Mahajan, Ratul and Walker, David},
title = {Test Coverage Metrics for the Network},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472941},
doi = {10.1145/3452296.3472941},
abstract = {Testing and verification have emerged as key tools in the battle to improve the reliability of networks and the services they provide. However, the success of even the best technology of this sort is limited by how effectively it is applied, and in today's enormously complex industrial networks, it is surprisingly easy to overlook particular interfaces, routes, or flows when creating a test suite. Moreover, network engineers, unlike their software counterparts, have no help to battle this problem—there are no metrics or systems to compute the quality of their test suites or the extent to which their networks have been verified.To address this gap, we develop a general framework to define and compute network coverage for stateless network data planes. It computes coverage for a range of network components (EG, interfaces, devices, paths) and supports many types of tests (e.g., concrete versus symbolic; local versus end-to-end; tests that check network state versus those that analyze behavior). Our framework is based on the observation that any network dataplane component can be decomposed into forwarding rules and all types of tests ultimately exercise these rules using one or more packets.We build a system called Yardstick based on this framework and deploy it in Microsoft Azure. Within the first month of its deployment inside one of the production networks, it uncovered several testing gaps and helped improve testing by covering 89% more forwarding rules and 17% more network interfaces.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {775–787},
numpages = {13},
keywords = {reliability, coverage metrics, network verification},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472901,
author = {Mahimkar, Ajay and de Andrade, Carlos Eduardo and Sinha, Rakesh and Rana, Giritharan},
title = {A Composition Framework for Change Management},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472901},
doi = {10.1145/3452296.3472901},
abstract = {Change management has been a long-standing challenge for network operations. The large scale and diversity of networks, their complex dependencies, and continuous evolution through technology and software updates combined with the risk of service impact create tremendous challenges to effectively manage changes. In this paper, we use data from a large service provider and experiences of their operations teams to highlight the need for quick and easy adaptation of change management capabilities and keep up with the continuous network changes. We propose a new framework CORNET (COmposition fRamework for chaNge managEmenT) with key ideas of modularization of changes into building blocks, flexible composition into change workflows, change plan optimization, change impact verification, and automated translation of high-level change management intent into low-level implementations and mathematical models. We demonstrate the effectiveness of CORNET using real-world data collected from 4G and 5G cellular networks and virtualized services such as VPN and SDWAN running in the cloud as well as experiments conducted on a testbed of virtualized network functions. We also share our operational experiences and lessons learned from successfully using CORNET within a large service provider network over the last three years.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {788–806},
numpages = {19},
keywords = {change plan optimization, network change management, composition framework, impact verification},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472906,
author = {Mahimkar, Ajay and Sivakumar, Ashiwan and Ge, Zihui and Pathak, Shomik and Biswas, Karunasish},
title = {Auric: Using Data-Driven Recommendation to Automatically Generate Cellular Configuration},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472906},
doi = {10.1145/3452296.3472906},
abstract = {Cellular service providers add carriers in the network in order to support the increasing demand in voice and data traffic and provide good quality of service to the users. Addition of new carriers requires the network operators to accurately configure their parameters for the desired behaviors. This is a challenging problem because of the large number of parameters related to various functions like user mobility, interference management and load balancing. Furthermore, the same parameters can have varying values across different locations to manage user and traffic behaviors as planned and respond appropriately to different signal propagation patterns and interference. Manual configuration is time-consuming, tedious and error-prone, which could result in poor quality of service. In this paper, we propose a new data-driven recommendation approach Auric to automatically and accurately generate configuration parameters for new carriers added in cellular networks. Our approach incorporates new algorithms based on collaborative filtering and geographical proximity to automatically determine similarity across existing carriers. We conduct a thorough evaluation using real-world LTE network data and observe a high accuracy (96%) across a large number of carriers and configuration parameters. We also share experiences from our deployment and use of Auric in production environments.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {807–820},
numpages = {14},
keywords = {cellular network configuration, collaborative filtering, recommendation algorithms, carrier addition},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472919,
author = {Reininger, Michael and Arora, Arushi and Herwig, Stephen and Francino, Nicholas and Hurst, Jayson and Garman, Christina and Levin, Dave},
title = {Bento: Safely Bringing Network Function Virtualization to Tor},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472919},
doi = {10.1145/3452296.3472919},
abstract = {Tor is a powerful and important tool for providing anonymity and censorship resistance to users around the world. Yet it is surprisingly difficult to deploy new services in Tor—it is largely relegated to proxies and hidden services—or to nimbly react to new forms of attack. Conversely, “non-anonymous” Internet services are thriving like never before because of recent advances in programmable networks, such as Network Function Virtualization (NFV) which provides programmable in-network middleboxes.This paper seeks to close this gap by introducing programmable middleboxes into the Tor network. In this architecture, users can install and run sophisticated “functions” on willing Tor routers. We demonstrate a wide range of functions that improve anonymity, resilience to attack, performance of hidden services, and more. We present the design and implementation of an architecture, Bento, that protects middlebox nodes from the functions they run—and protects the functions from the middleboxes they run on.We evaluate Bento by running it on the live Tor network. We show that, with just a few lines of Python, we can significantly extend the capabilities of Tor to meet users' anonymity needs and nimbly react to new threats. We will be making our code and data publicly available.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {821–835},
numpages = {15},
keywords = {Tor, network function virtualization (NFV), Intel SGX},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3452296.3472933,
author = {Dai, Tianxiang and Jeitner, Philipp and Shulman, Haya and Waidner, Michael},
title = {From IP to Transport and beyond: Cross-Layer Attacks against Applications},
year = {2021},
isbn = {9781450383837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452296.3472933},
doi = {10.1145/3452296.3472933},
abstract = {We perform the first analysis of methodologies for launching DNS cache poisoning: manipulation at the IP layer, hijack of the inter-domain routing and probing open ports via side channels. We evaluate these methodologies against DNS resolvers in the Internet and compare them with respect to effectiveness, applicability and stealth. Our study shows that DNS cache poisoning is a practical and pervasive threat.We then demonstrate cross-layer attacks that leverage DNS cache poisoning for attacking popular systems, ranging from security mechanisms, such as RPKI, to applications, such as VoIP. In addition to more traditional adversarial goals, most notably impersonation and Denial of Service, we show for the first time that DNS cache poisoning can even enable adversaries to bypass cryptographic defences: we demonstrate how DNS cache poisoning can facilitate BGP prefix hijacking of networks protected with RPKI even when all the other networks apply route origin validation to filter invalid BGP announcements. Our study shows that DNS plays a much more central role in the Internet security than previously assumed.We recommend mitigations for securing the applications and for preventing cache poisoning.},
booktitle = {Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
pages = {836–849},
numpages = {14},
keywords = {BGP hijacking, side channels, fragmentation, DNS cache poisoning},
location = {Virtual Event, USA},
series = {SIGCOMM '21}
}

@inproceedings{10.1145/3387514.3405849,
author = {He, Zhiqiang and Wang, Dongyang and Fu, Binzhang and Tan, Kun and Hua, Bei and Zhang, Zhi-Li and Zheng, Kai},
title = {MasQ: RDMA for Virtual Private Cloud},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405849},
doi = {10.1145/3387514.3405849},
abstract = {RDMA communication in virtual private cloud (VPC) networks is still a challenging job due to the difficulty in fulfilling all virtualization requirements without sacrificing RDMA communication performance. To address this problem, this paper proposes a software-defined solution, namely, MasQ, which is short for "queue masquerade". The core insight of MasQ is that all RDMA communications should associate with at least one queue pair (QP). Thus, the requirements of virtualization, such as network isolation and the application of security rules, can be easily fulfilled if QP's behavior is properly defined. In particular, MasQ exploits the virtio-based paravirtualization technique to realize the control path. Moreover, to avoid performance overhead, MasQ leaves all data path operations, such as sending and receiving, to the hardware. We have implemented MasQ in the OpenFabrics Enterprise Distribution (OFED) framework and proved its scalability and performance efficiency by evaluating it against typical applications. The results demonstrate that MasQ achieves almost the same performance as bare-metal RDMA for data communication.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {1–14},
numpages = {14},
keywords = {Datacenter network, Network virtualization, RDMA},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405850,
author = {Li, Tong and Zheng, Kai and Xu, Ke and Jadhav, Rahul Arvind and Xiong, Tao and Winstein, Keith and Tan, Kun},
title = {TACK: Improving Wireless Transport Performance by Taming Acknowledgments},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405850},
doi = {10.1145/3387514.3405850},
abstract = {The shared nature of the wireless medium induces contention between data transport and backward signaling, such as acknowledgement. The current way of TCP acknowledgment induces control overhead which is counter-productive for TCP performance especially in wireless local area network (WLAN) scenarios.In this paper, we present a new acknowledgement called TACK ("Tame ACK"), as well as its TCP implementation TCP-TACK. TCP-TACK works on top of commodity WLAN, delivering high wireless transport goodput with minimal control overhead in the form of ACKs, without any hardware modification. To minimize ACK frequency, TACK abandons the legacy received-packet-driven ACK. Instead, it balances byte-counting ACK and periodic ACK so as to achieve a controlled ACK frequency. Evaluation results show that TCP-TACK achieves significant advantages over legacy TCP in WLAN scenarios due to less contention between data packets and ACKs. Specifically, TCP-TACK reduces over 90% of ACKs and also obtains an improvement of ~ 28% on good-put. We further find it performs equally well as high-speed TCP variants in wide area network (WAN) scenarios, this is attributed to the advancements of the TACK-based protocol design in loss recovery, round-trip timing, and send rate control.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {15–30},
numpages = {16},
keywords = {ACK frequency, instant ACK, periodic ACK, acknowledgement mechanism},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405851,
author = {Fang, Chongrong and Liu, Haoyu and Miao, Mao and Ye, Jie and Wang, Lei and Zhang, Wansheng and Kang, Daxiang and Lyv, Biao and Cheng, Peng and Chen, Jiming},
title = {VTrace: Automatic Diagnostic System for Persistent Packet Loss in Cloud-Scale Overlay Network},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405851},
doi = {10.1145/3387514.3405851},
abstract = {Persistent packet loss in the cloud-scale overlay network severely compromises tenant experiences. Cloud providers are keen to automatically and quickly determine the root cause of such problems. However, existing work is either designed for the physical network or insufficient to present the concrete reason of packet loss. In this paper, we propose to record and analyze the on-site forwarding condition of packets during packet-level tracing. The cloud-scale overlay network presents great challenges to achieve this goal with its high network complexity, multi-tenant nature, and diversity of root causes. To address these challenges, we present VTrace, an automatic diagnostic system for persistent packet loss over the cloud-scale overlay network. Utilizing the "fast path-slow path" structure of virtual forwarding devices (VFDs), e.g., vSwitches, VTrace installs several "coloring, matching and logging" rules in VFDs to selectively track the packets of interest and inspect them in depth. The detailed forwarding situation at each hop is logged and then assembled to perform analysis with an efficient path reconstruction scheme. Experiments are conducted to demonstrate VTrace's low overhead and quick responsiveness. We share experiences of how VTrace efficiently resolves persistent packet loss issues after deploying it in Alibaba Cloud for over 20 months.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {31–43},
numpages = {13},
keywords = {Cloud-scale overlay network, Network diagnosis},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405852,
author = {Gao, Xiangyu and Kim, Taegyun and Wong, Michael D. and Raghunathan, Divya and Varma, Aatish Kishan and Kannan, Pravein Govindan and Sivaraman, Anirudh and Narayana, Srinivas and Gupta, Aarti},
title = {Switch Code Generation Using Program Synthesis},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405852},
doi = {10.1145/3387514.3405852},
abstract = {Writing packet-processing programs for programmable switch pipelines is challenging because of their all-or-nothing nature: a program either runs at line rate if it can fit within pipeline resources, or does not run at all. It is the compiler's responsibility to fit programs into pipeline resources. However, switch compilers, which use rewrite rules to generate switch machine code, often reject programs because the rules fail to transform programs into a form that can be mapped to a pipeline's limited resources---even if a mapping actually exists.This paper presents a compiler, Chipmunk, which formulates code generation as a program synthesis problem. Chipmunk uses a program synthesis engine, SKETCH, to transform high-level programs down to switch machine code. However, naively formulating code generation as program synthesis can lead to long compile times. Hence, we develop a new domain-specific synthesis technique, slicing, which reduces compile times by 1-387x and 51x on average.Using a switch hardware simulator, we show that Chipmunk compiles many programs that a previous rule-based compiler, Domino, rejects. Chipmunk also produces machine code with fewer pipeline stages than Domino. A Chipmunk backend for the Tofino programmable switch shows that program synthesis can produce machine code for high-speed switches.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {44–61},
numpages = {18},
keywords = {code generation, packet processing pipelines, program synthesis, slicing, Programmable switches},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405853,
author = {Shi, Shouqian and Qian, Chen},
title = {Concurrent Entanglement Routing for Quantum Networks: Model and Designs},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405853},
doi = {10.1145/3387514.3405853},
abstract = {Quantum entanglement enables important computing applications such as quantum key distribution. Based on quantum entanglement, quantum networks are built to provide long-distance secret sharing between two remote communication parties. Establishing a multi-hop quantum entanglement exhibits a high failure rate, and existing quantum networks rely on trusted repeater nodes to transmit quantum bits. However, when the scale of a quantum network increases, it requires end-to-end multi-hop quantum entanglements in order to deliver secret bits without letting the repeaters know the secret bits. This work focuses on the entanglement routing problem, whose objective is to build long-distance entanglements via untrusted repeaters for concurrent source-destination pairs through multiple hops. Different from existing work that analyzes the traditional routing techniques on special network topologies, we present a comprehensive entanglement routing model that reflects the differences between quantum networks and classical networks as well as a new entanglement routing algorithm that utilizes the unique properties of quantum networks. Evaluation results show that the proposed algorithm Q-CAST increases the number of successful long-distance entanglements by a big margin compared to other methods. The model and simulator developed by this work may encourage more network researchers to study the entanglement routing problem.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {62–75},
numpages = {14},
keywords = {Quantum Networks, Entanglement Routing, Network Modeling, Quantum Internet},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3406214,
author = {Zhou, Yu and Sun, Chen and Liu, Hongqiang Harry and Miao, Rui and Bai, Shi and Li, Bo and Zheng, Zhilong and Zhu, Lingjun and Shen, Zhen and Xi, Yongqing and Zhang, Pengcheng and Cai, Dennis and Zhang, Ming and Xu, Mingwei},
title = {Flow Event Telemetry on Programmable Data Plane},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3406214},
doi = {10.1145/3387514.3406214},
abstract = {Network performance anomalies (NPAs), e.g. long-tailed latency, bandwidth decline, etc., are increasingly crucial to cloud providers as applications are getting more sensitive to performance. The fundamental difficulty to quickly mitigate NPAs lies in the limitations of state-of-the-art network monitoring solutions --- coarse-grained counters, active probing, or packet telemetry either cannot provide enough insights on flows or incur too much overhead. This paper presents NetSeer, a flow event telemetry (FET) monitor which aims to discover and record all performance-critical data plane events, e.g. packet drops, congestion, path change, and packet pause. NetSeer is efficiently realized on the programmable data plane. It has a high coverage on flow events including inter-switch packet drop/corruption which is critical but also challenging to retrieve the original flow information, with novel intra- and inter-switch event detection algorithms running on data plane; NetSeer also achieves high scalability and accuracy with innovative designs of event aggregation, information compression, and message batching that mainly run on data plane, using switch CPU as complement. NetSeer has been implemented on commodity programmable switches and NICs. With real case studies and extensive experiments, we show NetSeer can reduce NPA mitigation time by 61%-99% with only 0.01% overhead of monitoring traffic.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {76–89},
numpages = {14},
keywords = {monitoring, Flow event telemetry, programmable data plane},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405855,
author = {Kim, Daehyeok and Liu, Zaoxing and Zhu, Yibo and Kim, Changhoon and Lee, Jeongkeun and Sekar, Vyas and Seshan, Srinivasan},
title = {TEA: Enabling State-Intensive Network Functions on Programmable Switches},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405855},
doi = {10.1145/3387514.3405855},
abstract = {Programmable switches have been touted as an attractive alternative for deploying network functions (NFs) such as network address translators (NATs), load balancers, and firewalls. However, their limited memory capacity has been a major stumbling block that has stymied their adoption for supporting state-intensive NFs such as cloud-scale NATs and load balancers that maintain millions of flow-table entries. In this paper, we explore a new approach that leverages DRAM on servers available in typical NFV clusters. Our new system architecture, called TEA (Table Extension Architecture), provides a virtual table abstraction that allows NFs on programmable switches to look up large virtual tables built on external DRAM. Our approach enables switch ASICs to access external DRAM purely in the data plane without involving CPUs on servers. We address key design and implementation challenges in realizing this idea. We demonstrate its feasibility and practicality with our implementation on a Tofino-based programmable switch. Our evaluation shows that NFs built with TEA can look up table entries on external DRAM with low and predictable latency (1.8-2.2 μs) and the lookup throughput can be linearly scaled with additional servers (138 million lookups per seconds with 8 servers).},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {90–106},
numpages = {17},
keywords = {Programmable switches, Programmable networks, Remote Direct Memory Access, Network Function Virtualization, Data centers},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405856,
author = {Kim, Jaehong and Jung, Youngmok and Yeo, Hyunho and Ye, Juncheol and Han, Dongsu},
title = {Neural-Enhanced Live Streaming: Improving Live Video Ingest via Online Learning},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405856},
doi = {10.1145/3387514.3405856},
abstract = {Live video accounts for a significant volume of today's Internet video. Despite a large number of efforts to enhance user quality of experience (QoE) both at the ingest and distribution side of live video, the fundamental limitations are that streamer's upstream bandwidth and computational capacity limit the quality of experience of thousands of viewers.To overcome this limitation, we design LiveNAS, a new live video ingest framework that enhances the origin stream's quality by leveraging computation at ingest servers. Our ingest server applies neural super-resolution on the original stream, while imposing minimal overhead on ingest clients. LiveNAS employs online learning to maximize the quality gain and dynamically adjusts the resource use to the real-time quality improvement. LiveNAS delivers high-quality live streams up to 4K resolution, outperforming WebRTC by 1.96 dB on average in Peak-Signal-to-Noise-Ratio on real video streams and network traces, which leads to 12%-69% QoE improvement for live stream viewers.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {107–125},
numpages = {19},
keywords = {online learning, video delivery, live streaming, super-resolution, deep neural networks},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405857,
author = {Yu, Zhuolong and Zhang, Yiwen and Braverman, Vladimir and Chowdhury, Mosharaf and Jin, Xin},
title = {NetLock: Fast, Centralized Lock Management Using Programmable Switches},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405857},
doi = {10.1145/3387514.3405857},
abstract = {Lock managers are widely used by distributed systems. Traditional centralized lock managers can easily support policies between multiple users using global knowledge, but they suffer from low performance. In contrast, emerging decentralized approaches are faster but cannot provide flexible policy support. Furthermore, performance in both cases is limited by the server capability.We present NetLock, a new centralized lock manager that co-designs servers and network switches to achieve high performance without sacrificing flexibility in policy support. The key idea of NetLock is to exploit the capability of emerging programmable switches to directly process lock requests in the switch data plane. Due to the limited switch memory, we design a memory management mechanism to seamlessly integrate the switch and server memory. To realize the locking functionality in the switch, we design a custom data plane module that efficiently pools multiple register arrays together to maximize memory utilization We have implemented a NetLock prototype with a Barefoot Tofino switch and a cluster of commodity servers. Evaluation results show that NetLock improves the throughput by 14.0-18.4x, and reduces the average and 99% latency by 4.7-20.3x and 10.4-18.7x over DSLR, a state-of-the-art RDMA-based solution, while providing flexible policy support.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {126–138},
numpages = {13},
keywords = {Lock Management, Centralized, Programmable Switches, Data plane},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405858,
author = {Jiang, Chuan and Rao, Sanjay and Tawarmalani, Mohit},
title = {PCF: Provably Resilient Flexible Routing},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405858},
doi = {10.1145/3387514.3405858},
abstract = {Recently, traffic engineering mechanisms have been developed that guarantee that a network (cloud provider WAN, or ISP) does not experience congestion under failures. In this paper, we show that existing congestion-free mechanisms, notably FFC, achieve performance far short of the network's intrinsic capability. We propose PCF, a set of novel congestion-free mechanisms to bridge this gap. PCF achieves these goals by better modeling network structure, and by carefully enhancing the flexibility of network response while ensuring that the performance under failures can be tractably modeled. All of PCF's schemes involve relatively light-weight operations on failures, and many of them can be realized using a local proportional routing scheme similar to FFC. We show PCF's effectiveness through formal theoretical results, and empirical experiments over 21 Internet topologies. PCF's schemes provably out-perform FFC, and in practice, can sustain higher throughput than FFC by a factor of 1.11X to 1.5X on average across the topologies, while providing a benefit of 2.6X in some cases.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {139–153},
numpages = {15},
keywords = {network resilience, network optimization},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405859,
author = {Meng, Zili and Wang, Minhu and Bai, Jiasong and Xu, Mingwei and Mao, Hongzi and Hu, Hongxin},
title = {Interpreting Deep Learning-Based Networking Systems},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405859},
doi = {10.1145/3387514.3405859},
abstract = {While many deep learning (DL)-based networking systems have demonstrated superior performance, the underlying Deep Neural Networks (DNNs) remain blackboxes and stay uninterpretable for network operators. The lack of interpretability makes DL-based networking systems prohibitive to deploy in practice. In this paper, we propose Metis, a framework that provides interpretability for two general categories of networking problems spanning local and global control. Accordingly, Metis introduces two different interpretation methods based on decision tree and hypergraph, where it converts DNN policies to interpretable rule-based controllers and highlight critical components based on analysis over hypergraph. We evaluate Metis over two categories of state-of-the-art DL-based networking systems and show that Metis provides human-readable interpretations while preserving nearly no degradation in performance. We further present four concrete use cases of Metis, showcasing how Metis helps network operators to design, debug, deploy, and ad-hoc adjust DL-based networking systems.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {154–171},
numpages = {18},
keywords = {Interpretability, hypergraph, DL-based networking systems, decision tree},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405861,
author = {Chi, Zicheng and Liu, Xin and Wang, Wei and Yao, Yao and Zhu, Ting},
title = {Leveraging Ambient LTE Traffic for Ubiquitous Passive Communication},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405861},
doi = {10.1145/3387514.3405861},
abstract = {To support ubiquitous computing for various applications (such as smart health, smart homes, and smart cities), the communication system requires to be ubiquitously available, ultra-low-power, high throughput, and low-latency. A passive communication system such as backscatter is desirable. However, existing backscatter systems cannot achieve all of the above requirements. In this paper, we present the first LTE backscatter (LScatter) system that leverages the continuous LTE ambient traffic for ubiquitous, high throughput and low latency backscatter communication. Our design is motivated by our observation that LTE ambient traffic is continuous (v.s. bursty and intermittent WiFi/LoRa traffic), which makes LTE ambient traffic a perfect signal source of a backscatter system. Our design addresses practical issues such as time synchronization, phase modulation, as well as phase offset elimination. We extensively evaluated our design using a testbed of backscatter hardware and USRPs in multiple real-world scenarios. Results show that our LScatter's performance is consistently orders of magnitude better than WiFi backscatter in all the above scenarios. For example, LScatter's throughput is 13.63Mbps, which is 368 times higher than the latest ambient WiFi backscatter system [54]. We also demonstrate the effectiveness of our system using two real-world applications.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {172–185},
numpages = {14},
keywords = {LTE, Internet of things, Backscatter},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3406229,
author = {Wu, Yue and Wang, Purui and Xu, Kenuo and Feng, Lilei and Xu, Chenren},
title = {Turboboosting Visible Light Backscatter Communication},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3406229},
doi = {10.1145/3387514.3406229},
abstract = {Visible light backscatter communication (VLBC) presents an emerging low power IoT connectivity solution with spatial reuse and interference immunity advantages over RF-based (backscatter) technologies. State-of-the-art VLBC systems employ COTS LCD shutter as optical modulator, whose slow response fundamentally throttles its data rate to sub-Kbps, and limits its deployment at scale for use cases where higher rate and/or low latency is a necessity.We design and implement RetroTurbo, a VLBC system dedicated for turboboosting data rate. At the heart of RetroTurbo design is a pair of novel modulation schemes, namely delayed superimposition modulation (DSM) and polarization-based QAM (PQAM), to push the rate limit by strategically coordinating the state of a liquid crystal modulator (LCM) pixel array in time and polarization domains. Specifically, DSM ensures we fully exploit the available SNR for high order modulation in the LCM-imposed nonlinear channel; PQAM is based on polarized light communication that creates a QAM design in polarization domain with flexible angular misalignment between two ends. A real-time near-optimal demodulation algorithm is designed to ensure system's robustness to heterogeneous signal distortion. Based on our prototyped system, RetroTurbo demonstrates 32x and 128x rate gain via experiments and emulation respectively in practical real-world indoor setting.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {186–197},
numpages = {12},
keywords = {Delayed Superimposed Modulation, Visible Light Backscatter Communication, Polarization-based QAM},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405863,
author = {Ghaznavi, Milad and Jalalpour, Elaheh and Wong, Bernard and Boutaba, Raouf and Mashtizadeh, Ali Jos\'{e}},
title = {Fault Tolerant Service Function Chaining},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405863},
doi = {10.1145/3387514.3405863},
abstract = {Network traffic typically traverses a sequence of middleboxes forming a service function chain, or simply a chain. Tolerating failures when they occur along chains is imperative to the availability and reliability of enterprise applications. Making a chain fault-tolerant is challenging since, in the event of failures, the state of faulty middleboxes must be correctly and quickly recovered while providing high throughput and low latency.In this paper, we introduce FTC, a system design and protocol for fault-tolerant service function chaining. FTC provides strong consistency with up to f middlebox failures for chains of length f + 1 or longer without requiring dedicated replica nodes. In FTC, state updates caused by packet processing at a middlebox are collected, piggybacked onto the packet, and sent along the chain to be replicated. Our evaluation shows that compared with the state of art [51], FTC improves throughput by 2-3.5X for a chain of two to five middleboxes.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {198–210},
numpages = {13},
keywords = {Middlebox Reliability, Service Function Chain Fault Tolerance},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405864,
author = {Sobrinho, Jo\~{a}o Lu\'{\i}s and Ferreira, Miguel Alves},
title = {Routing on Multiple Optimality Criteria},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405864},
doi = {10.1145/3387514.3405864},
abstract = {Standard vectoring protocols, such as EIGRP, BGP, DSDV, or Babel, only route on optimal paths when the total order on path attributes that substantiates optimality is consistent with the extension operation that calculates path attributes from link attributes, leaving out many optimality criteria of practical interest. We present a solution to this problem and, more generally, to the problem of routing on multiple optimality criteria. A key idea is the derivation of a partial order on path attributes that is consistent with the extension operation and respects every optimality criterion of a designated collection of such criteria. We design new vectoring protocols that compute on partial orders, with every node capable of electing multiple attributes per destination rather than a single attribute as in standard vectoring protocols. Our evaluation over publicly available network topologies and attributes shows that the proposed protocols converge fast and enable optimal path routing concurrently for many optimality criteria with only a few elected attributes at each node per destination. We further show how predicating computations on partial orders allows incorporation of service chain constraints on optimal path routing.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {211–225},
numpages = {15},
keywords = {routing protocols, optimality criteria, partial orders, Routing, routing algebras, optimal path routing},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405865,
author = {Chen, Xiaoqi and Landau-Feibish, Shir and Braverman, Mark and Rexford, Jennifer},
title = {BeauCoup: Answering Many Network Traffic Queries, One Memory Update at a Time},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405865},
doi = {10.1145/3387514.3405865},
abstract = {Network administrators constantly monitor network traffic for congestion and attacks. They need to perform a large number of measurements on the traffic simultaneously, to detect different types of anomalies such as heavy hitters or super-spreaders. Existing techniques often focus on a single statistic (e.g., traffic volume) or traffic attribute (e.g., destination IP). However, performing numerous heterogeneous measurements within the constrained memory architecture of modern network devices poses significant challenges, due to the limited number of memory accesses allowed per packet. We propose BeauCoup, a system based on the coupon collector problem, that supports multiple distinct counting queries simultaneously while making only a small constant number of memory accesses per packet. We implement BeauCoup on PISA commodity programmable switches, satisfying the strict memory size and access constraints while using a moderate portion of other data-plane hardware resources. Evaluations show BeauCoup achieves the same accuracy as other sketch-based or sampling-based solutions using 4x fewer memory access.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {226–239},
numpages = {14},
keywords = {Data Plane, Network Measurement, Streaming Algorithm, Distinct Counting, Programmable Switch, Sketching},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405866,
author = {Abedi, Ali and Dehbashi, Farzan and Mazaheri, Mohammad Hossein and Abari, Omid and Brecht, Tim},
title = {WiTAG: Seamless WiFi Backscatter Communication},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405866},
doi = {10.1145/3387514.3405866},
abstract = {WiFi backscatter communication has the potential to enable battery-free sensors which can transmit data using a WiFi network. In order for WiFi backscatter systems to be practical they should be compatible with existing WiFi networks without any hardware or software modifications. Moreover, they should work with networks that use encryption. In this paper, we present WiTAG which achieves these requirements, making the implementation and deployment of WiFi backscatter communication more practical. In contrast with existing systems which utilize the physical layer for backscatter communication, we take a different approach by leveraging features of the MAC layer to communicate. WiTAG is designed to send data by selectively interfering with subframes (MPDUs) in an aggregated frame (A-MPDU). This enables standard compliant communication using modern, open or encrypted 802.11n and 802.11ac networks without requiring hardware or software modifications to any devices. We implement WiTAG using off-the-shelf components and evaluate its performance in line-of-sight and non-line-of-sight scenarios. We show that WiTAG achieves a throughput of up to 4 Kbps without impacting other devices in the network.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {240–252},
numpages = {13},
keywords = {WiFi Backscatter, Internet of Things (IoT), Sensors, 802.11 Networks, Battery-free communication},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405867,
author = {Gao, Jiaqi and Yaseen, Nofel and MacDavid, Robert and Frujeri, Felipe Vieira and Liu, Vincent and Bianchini, Ricardo and Aditya, Ramaswamy and Wang, Xiaohang and Lee, Henry and Maltz, David and Yu, Minlan and Arzani, Behnaz},
title = {Scouts: Improving the Diagnosis Process Through Domain-Customized Incident Routing},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405867},
doi = {10.1145/3387514.3405867},
abstract = {Incident routing is critical for maintaining service level objectives in the cloud: the time-to-diagnosis can increase by 10x due to mis-routings. Properly routing incidents is challenging because of the complexity of today's data center (DC) applications and their dependencies. For instance, an application running on a VM might rely on a functioning host-server, remote-storage service, and virtual and physical network components. It is hard for any one team, rule-based system, or even machine learning solution to fully learn the complexity and solve the incident routing problem. We propose a different approach using per-team Scouts. Each teams' Scout acts as its gate-keeper --- it routes relevant incidents to the team and routes-away unrelated ones. We solve the problem through a collection of these Scouts. Our PhyNet Scout alone --- currently deployed in production --- reduces the time-to-mitigation of 65% of mis-routed incidents in our dataset.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {253–269},
numpages = {17},
keywords = {Diagnosis, Machine learning, Data center networks},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405868,
author = {Manousis, Antonis and Sharma, Rahul Anand and Sekar, Vyas and Sherry, Justine},
title = {Contention-Aware Performance Prediction For Virtualized Network Functions},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405868},
doi = {10.1145/3387514.3405868},
abstract = {At the core of Network Functions Virtualization lie Network Functions (NFs) that run co-resident on the same server, contend over its hardware resources and, thus, might suffer from reduced performance relative to running alone on the same hardware. Therefore, to efficiently manage resources and meet performance SLAs, NFV orchestrators need mechanisms to predict contention-induced performance degradation. In this work, we find that prior performance prediction frameworks suffer from poor accuracy on modern architectures and NFs because they treat memory as a monolithic whole. In addition, we show that, in practice, there exist multiple components of the memory subsystem that can separately induce contention. By precisely characterizing (1) the pressure each NF applies on the server's shared hardware resources (contentiousness) and (2) how susceptible each NF is to performance drop due to competing contentiousness (sensitivity), we develop SLOMO, a multivariable performance prediction framework for Network Functions. We show that relative to prior work SLOMO reduces prediction error by 2-5x and enables 6-14% more efficient cluster utilization. SLOMO's codebase can be found at https://github.com/cmu-snap/SLOMO.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {270–282},
numpages = {13},
keywords = {Packet Processing Software, Network Functions Performance},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405869,
author = {Zhang, Kaiyuan and Zhuo, Danyang and Krishnamurthy, Arvind},
title = {Gallium: Automated Software Middlebox Offloading to Programmable Switches},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405869},
doi = {10.1145/3387514.3405869},
abstract = {Researchers have shown that offloading software middleboxes (e.g., NAT, firewall, load balancer) to programmable switches can yield orders-of-magnitude performance gains. However, it requires manually selecting the middle-box components to offload and rewriting the offloaded code in P4, a domain-specific language for programmable switches. We design and implement Gallium, a compiler that transforms an input software middlebox into two parts---a P4 program that runs on a programmable switch and an x86 non-offloaded program that runs on a regular middlebox server. Gallium ensures that (1) the combined effect of the P4 program and the non-offloaded program is functionally equivalent to the input middlebox program, (2) the P4 program respects the resource constraints in the programmable switch, and (3) the run-to-completion semantics are met under concurrent execution. Our evaluations show that Gallium saves 21-79% of processing cycles and reduces latency by about 31% across various software middleboxes.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {283–295},
numpages = {13},
keywords = {Middleboxes, Protocol offload},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405870,
author = {Yu, Liangcheng and Sonchack, John and Liu, Vincent},
title = {Mantis: Reactive Programmable Switches},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405870},
doi = {10.1145/3387514.3405870},
abstract = {For modern data center switches, the ability to---with minimum latency and maximum flexibility--- react to current network conditions is important for managing increasingly dynamic networks. The traditional approach to implementing this type of behavior is through a control plane that is orders of magnitude slower than the speed at which typical data center congestion events occur. More recent alternatives like programmable switches can remember statistics about passing traffic and adjust behavior accordingly, but unfortunately, their capabilities severely limit what can be done.In this paper, we present Mantis, a framework for implementing fine-grained reactive behavior on today's programmable switches with the help of a specialized reactive control plane architecture. Mantis is, thus, a combination of language for specifying dynamic components of packet processing and an optimized, general, and safe control loop for implementing them. Mantis provides a simple-to-reason-about set of abstractions for users, and the Mantis control plane can react to changes in the network in 10s of μs.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {296–309},
numpages = {14},
keywords = {Reconfiguration, Programmable networks, P4, Control plane},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405871,
author = {Kakarla, Siva Kesava Reddy and Beckett, Ryan and Arzani, Behnaz and Millstein, Todd and Varghese, George},
title = {GRooT: Proactive Verification of DNS Configurations},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405871},
doi = {10.1145/3387514.3405871},
abstract = {The Domain Name System (DNS) plays a vital role in today's Internet but relies on complex distributed management of records. DNS misconfiguration related outages have rendered popular services like GitHub, HBO, LinkedIn, and Azure inaccessible for extended periods. This paper introduces GRoot, the first verifier that performs static analysis of DNS configuration files, enabling proactive and exhaustive checking for common DNS bugs; by contrast, existing solutions are reactive and incomplete. GRoot uses a new, fast verification algorithm based on generating and enumerating DNS query equivalence classes. GRoot symbolically executes the set of queries in each equivalence class to efficiently find (or prove the absence of) any bugs such as rewrite loops. To prove the correctness of our approach, we develop a formal semantic model of DNS resolution. Applied to the configuration files from a campus network with over a hundred thousand records, GRoot revealed 109 bugs within seconds. When applied to internal zone files consisting of over 3.5 million records from a large infrastructure service provider, GRoot revealed around 160k issues of blackholing, initiating a cleanup. Finally, on a synthetic dataset with over 65 million real records, we find GRoot can scale to networks with tens of millions of records.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {310–328},
numpages = {19},
keywords = {Static Analysis, Verification, DNS, Formal Methods},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405872,
author = {Soni, Hardik and Rifai, Myriana and Kumar, Praveen and Doenges, Ryan and Foster, Nate},
title = {Composing Dataplane Programs with μP4},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405872},
doi = {10.1145/3387514.3405872},
abstract = {Dataplane languages like P4 enable flexible and efficient packet-processing using domain-specific primitives such as programmable parsers and match-action tables. Unfortunately, P4 programs tend to be monolithic and tightly coupled to the hardware architecture, which makes it hard to write programs in a portable and modular way---e.g., by composing reusable libraries of standard protocols.To address this challenge, we present the design and implementation of a novel framework (μP4) comprising a lightweight logical architecture that abstracts away from the structure of the underlying hardware pipelines and naturally supports powerful forms of program composition. Using examples, we show how enables modular programming. We present a prototype of the compiler that generates code for multiple lower-level architectures, including Barefoot's Tofino Native Architecture. We evaluate the overheads induced by our compiler on realistic examples.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {329–343},
numpages = {15},
keywords = {Programmable dataplanes, Modularity, Composition, P4},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405873,
author = {Li, Yuanjie and Li, Qianru and Zhang, Zhehui and Baig, Ghufran and Qiu, Lili and Lu, Songwu},
title = {Beyond 5G: Reliable Extreme Mobility Management},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405873},
doi = {10.1145/3387514.3405873},
abstract = {Extreme mobility has become a norm rather than an exception. However, 4G/5G mobility management is not always reliable in extreme mobility, with non-negligible failures and policy conflicts. The root cause is that, existing mobility management is primarily based on wireless signal strength. While reasonable in static and low mobility, it is vulnerable to dramatic wireless dynamics from extreme mobility in triggering, decision, and execution. We devise REM, Reliable Extreme Mobility management for 4G, 5G, and beyond. REM shifts to movement-based mobility management in the delay-Doppler domain. Its signaling overlay relaxes feedback via cross-band estimation, simplifies policies with provable conflict freedom, and stabilizes signaling via scheduling-based OTFS modulation. Our evaluation with operational high-speed rail datasets shows that, REM reduces failures comparable to static and low mobility, with low signaling and latency cost.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {344–358},
numpages = {15},
keywords = {Mobile network, cross-band estimation, delay-Doppler domain, policy conflicts, reliability, extreme mobility management, beyond 5G},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405874,
author = {Li, Yuanqi and Padmanabhan, Arthi and Zhao, Pengzhan and Wang, Yufei and Xu, Guoqing Harry and Netravali, Ravi},
title = {Reducto: On-Camera Filtering for Resource-Efficient Real-Time Video Analytics},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405874},
doi = {10.1145/3387514.3405874},
abstract = {To cope with the high resource (network and compute) demands of real-time video analytics pipelines, recent systems have relied on frame filtering. However, filtering has typically been done with neural networks running on edge/backend servers that are expensive to operate. This paper investigates on-camera filtering, which moves filtering to the beginning of the pipeline. Unfortunately, we find that commodity cameras have limited compute resources that only permit filtering via frame differencing based on low-level video features. Used incorrectly, such techniques can lead to unacceptable drops in query accuracy. To overcome this, we built Reducto, a system that dynamically adapts filtering decisions according to the time-varying correlation between feature type, filtering threshold, query accuracy, and video content. Experiments with a variety of videos and queries show that Reducto achieves significant (51-97% of frames) filtering benefits, while consistently meeting the desired accuracy.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {359–376},
numpages = {18},
keywords = {video analytics, object detection, deep neural networks},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405875,
author = {Harchol, Yotam and Bergemann, Dirk and Feamster, Nick and Friedman, Eric and Krishnamurthy, Arvind and Panda, Aurojit and Ratnasamy, Sylvia and Schapira, Michael and Shenker, Scott},
title = {A Public Option for the Core},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405875},
doi = {10.1145/3387514.3405875},
abstract = {This paper is focused not on the Internet architecture - as defined by layering, the narrow waist of IP, and other core design principles - but on the Internet infrastructure, as embodied in the technologies and organizations that provide Internet service. In this paper we discuss both the challenges and the opportunities that make this an auspicious time to revisit how we might best structure the Internet's infrastructure. Currently, the tasks of transit-between-domains and last-mile-delivery are jointly handled by a set of ISPs who interconnect through BGP. In this paper we propose cleanly separating these two tasks. For transit, we propose the creation of a "public option" for the Internet's core backbone. This public option core, which complements rather than replaces the backbones used by large-scale ISPs, would (i) run an open market for backbone bandwidth so it could leverage links offered by third-parties, and (ii) structure its terms-of-service to enforce network neutrality so as to encourage competition and reduce the advantage of large incumbents.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {377–389},
numpages = {13},
keywords = {Internet transit, Internet infrastructure, Network neutrality},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405876,
author = {Gong, Junzhi and Li, Yuliang and Anwer, Bilal and Shaikh, Aman and Yu, Minlan},
title = {Microscope: Queue-Based Performance Diagnosis for Network Functions},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405876},
doi = {10.1145/3387514.3405876},
abstract = {By moving monolithic network appliances to software running on commodity hardware, network function virtualization allows flexible resource sharing among network functions and achieves scalability with low cost. However, due to resource contention, network functions can suffer from performance problems that are hard to diagnose. In particular, when many flows traverse a complex topology of NF instances, it is hard to pinpoint root causes for a flow experiencing performance issues such as low throughput or high latency. Simply maintaining resource counters at individual NFs is not sufficient since the effect of resource contention can propagate across NFs and over time. In this paper, we introduce Microscope, a performance diagnosis tool, for network functions that leverages queuing information at NFs to identify the root causes (i.e., resources, NFs, traffic patterns of flows etc.). Our evaluation on realistic NF chains and traffic shows that we can correctly capture root causes behind 89.7% of performance impairments, up to 2.5 times more than the state-of-the-art tools with low overhead.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {390–403},
numpages = {14},
keywords = {diagnosis, NFV, performance},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405877,
author = {Huang, Qun and Sun, Haifeng and Lee, Patrick P. C. and Bai, Wei and Zhu, Feng and Bao, Yungang},
title = {OmniMon: Re-Architecting Network Telemetry with Resource Efficiency and Full Accuracy},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405877},
doi = {10.1145/3387514.3405877},
abstract = {Network telemetry is essential for administrators to monitor massive data traffic in a network-wide manner. Existing telemetry solutions often face the dilemma between resource efficiency (i.e., low CPU, memory, and bandwidth overhead) and full accuracy (i.e., error-free and holistic measurement). We break this dilemma via a network-wide architectural design OmniMon, which simultaneously achieves resource efficiency and full accuracy in flow-level telemetry for large-scale data centers. OmniMon carefully coordinates the collaboration among different types of entities in the whole network to execute telemetry operations, such that the resource constraints of each entity are satisfied without compromising full accuracy. It further addresses consistency in network-wide epoch synchronization and accountability in error-free packet loss inference. We prototype OmniMon in DPDK and P4. Testbed experiments on commodity servers and Tofino switches demonstrate the effectiveness of OmniMon over state-of-the-art telemetry designs.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {404–421},
numpages = {18},
keywords = {Distributed systems, Network measurement},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405878,
author = {Hu, Shuihai and Bai, Wei and Zeng, Gaoxiong and Wang, Zilong and Qiao, Baochen and Chen, Kai and Tan, Kun and Wang, Yi},
title = {Aeolus: A Building Block for Proactive Transport in Datacenters},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405878},
doi = {10.1145/3387514.3405878},
abstract = {As datacenter network bandwidth keeps growing, proactive transport becomes attractive, where bandwidth is proactively allocated as "credits" to senders who then can send "scheduled packets" at a right rate to ensure high link utilization, low latency, and zero packet loss. While promising, a fundamental challenge is that proactive transport requires at least one-RTT for credits to be computed and delivered. In this paper, we show such one-RTT "pre-credit" phase could carry a substantial amount of flows at high link-speeds, but none of existing proactive solutions treats it appropriately. We present Aeolus, a solution focusing on "pre-credit" packet transmission as a building block for proactive transports. Aeolus contains unconventional design principles such as scheduled-packet-first (SPF) that de-prioritizes the first-RTT packets, instead of prioritizing them as prior work. It further exploits the preserved, deterministic nature of proactive transport as a means to recover lost first-RTT packets efficiently. We have integrated Aeolus into ExpressPass[14], NDP[18] and Homa[29], and shown, through both implementation and simulations, that the Aeolus-enhanced solutions deliver signiicant performance or deployability advantages. For example, it improves the average FCT of ExpressPass by 56%, cuts the tail FCT of Homa by 20x, while achieving similar performance as NDP without switch modifications.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {422–434},
numpages = {13},
keywords = {Selective Dropping, Data Center Networks, Proactive Transport, First RTT},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405879,
author = {Gao, Jiaqi and Zhai, Ennan and Liu, Hongqiang Harry and Miao, Rui and Zhou, Yu and Tian, Bingchuan and Sun, Chen and Cai, Dennis and Zhang, Ming and Yu, Minlan},
title = {Lyra: A Cross-Platform Language and Compiler for Data Plane Programming on Heterogeneous ASICs},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405879},
doi = {10.1145/3387514.3405879},
abstract = {Programmable data plane has been moving towards deployments in data centers as mainstream vendors of switching ASICs enable programmability in their newly launched products, such as Broadcom's Trident-4, Intel/Barefoot's Tofino, and Cisco's Silicon One. However, current data plane programs are written in low-level, chip-specific languages (e.g., P4 and NPL) and thus tightly coupled to the chip-specific architecture. As a result, it is arduous and error-prone to develop, maintain, and composite data plane programs in production networks. This paper presents Lyra, the first cross-platform, high-level language &amp; compiler system that aids the programmers in programming data planes efficiently. Lyra offers a one-big-pipeline abstraction that allows programmers to use simple statements to express their intent, without laboriously taking care of the details in hardware; Lyra also proposes a set of synthesis and optimization techniques to automatically compile this "big-pipeline" program into multiple pieces of runnable chip-specific code that can be launched directly on the individual programmable switches of the target network. We built and evaluated Lyra. Lyra not only generates runnable real-world programs (in both P4 and NPL), but also uses up to 87.5% fewer hardware resources and up to 78% fewer lines of code than human-written programs.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {435–450},
numpages = {16},
keywords = {Compiler, Programmable Networks, P4 Synthesis, Programming Language, Programmable switching ASIC},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405880,
author = {Xie, Yaxiong and Yi, Fan and Jamieson, Kyle},
title = {PBE-CC: Congestion Control via Endpoint-Centric, Physical-Layer Bandwidth Measurements},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405880},
doi = {10.1145/3387514.3405880},
abstract = {Cellular networks are becoming ever more sophisticated and overcrowded, imposing the most delay, jitter, and throughput damage to end-to-end network flows in today's internet. We therefore argue for fine-grained mobile endpoint-based wireless measurements to inform a precise congestion control algorithm through a well-defined API to the mobile's cellular physical layer. Our proposed congestion control algorithm is based on Physical-Layer Bandwidth measurements taken at the Endpoint (PBE-CC), and captures the latest 5G New Radio innovations that increase wireless capacity, yet create abrupt rises and falls in available wireless capacity that the PBE-CC sender can react to precisely and rapidly. We implement a proof-of-concept prototype of the PBE measurement module on software-defined radios and the PBE sender and receiver in C. An extensive performance evaluation compares PBE-CC head to head against the cellular-aware and wireless-oblivious congestion control protocols proposed in the research community and in deployment, in mobile and static mobile scenarios, and over busy and idle networks. Results show 6.3% higher average throughput than BBR, while simultaneously reducing 95th percentile delay by 1.8x.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {451–464},
numpages = {14},
keywords = {TCP congestion control, Capacity estimation, Physical control channel, Control information, Transport protocols, LTE, Cellular network},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405881,
author = {Schomp, Kyle and Bhardwaj, Onkar and Kurdoglu, Eymen and Muhaimen, Mashooq and Sitaraman, Ramesh K.},
title = {Akamai DNS: Providing Authoritative Answers to the World's Queries},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405881},
doi = {10.1145/3387514.3405881},
abstract = {We present Akamai DNS, one of the largest authoritative DNS infrastructures in the world, that supports the Akamai content delivery network (CDN) as well as authoritative DNS hosting and DNS-based load balancing services for many enterprises. As the starting point for a significant fraction of the world's Internet interactions, Akamai DNS serves millions of queries each second and must be resilient to avoid disrupting myriad online services, scalable to meet the ever increasing volume of DNS queries, performant to prevent user-perceivable performance degradation, and reconfigurable to react quickly to shifts in network conditions and attacks. We outline the design principles and architecture used to achieve Akamai DNS's goals, relating the design choices to the system workload and quantifying the effectiveness of those designs. Further, we convey insights from operating the production system that are of value to the broader research community.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {465–478},
numpages = {14},
keywords = {Distributed Systems, DNS},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405882,
author = {Xu, Dongzhu and Zhou, Anfu and Zhang, Xinyu and Wang, Guixian and Liu, Xi and An, Congkai and Shi, Yiming and Liu, Liang and Ma, Huadong},
title = {Understanding Operational 5G: A First Measurement Study on Its Coverage, Performance and Energy Consumption},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405882},
doi = {10.1145/3387514.3405882},
abstract = {5G, as a monumental shift in cellular communication technology, holds tremendous potential for spurring innovations across many vertical industries, with its promised multi-Gbps speed, sub-10 ms low latency, and massive connectivity. On the other hand, as 5G has been deployed for only a few months, it is unclear how well and whether 5G can eventually meet its prospects. In this paper, we demystify operational 5G networks through a first-of-its-kind cross-layer measurement study. Our measurement focuses on four major perspectives: (i) Physical layer signal quality, coverage and hand-off performance; (ii) End-to-end throughput and latency; (iii) Quality of experience of 5G's niche applications (e.g., 4K/5.7K panoramic video telephony); (iv) Energy consumption on smartphones. The results reveal that the 5G link itself can approach Gbps throughput, but legacy TCP leads to surprisingly low capacity utilization (&lt; 32%), latency remains too high to support tactile applications and power consumption escalates to 2 - 3x over 4G. Our analysis suggests that the wireline paths, upper-layer protocols, computing and radio hardware architecture need to co-evolve with 5G to form an ecosystem, in order to fully unleash its potential.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {479–494},
numpages = {16},
keywords = {Network Measurement, End-to-end Performance, TCP, Energy Efficiency, 5G, Network Coverage},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405883,
author = {Atre, Nirav and Sherry, Justine and Wang, Weina and Berger, Daniel S.},
title = {Caching with Delayed Hits},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405883},
doi = {10.1145/3387514.3405883},
abstract = {Caches are at the heart of latency-sensitive systems. In this paper, we identify a growing challenge for the design of latency-minimizing caches called delayed hits. Delayed hits occur at high throughput, when multiple requests to the same object queue up before an outstanding cache miss is resolved. This effect increases latencies beyond the predictions of traditional caching models and simulations; in fact, caching algorithms are designed as if delayed hits simply didn't exist. We show that traditional caching strategies -- even so called 'optimal' algorithms -- can fail to minimize latency in the presence of delayed hits. We design a new, latency-optimal offline caching algorithm called belatedly which reduces average latencies by up to 45% compared to the traditional, hit-rate optimal Belady's algorithm. Using belatedly as our guide, we show that incorporating an object's 'aggregate delay' into online caching heuristics can improve latencies for practical caching systems by up to 40%. We implement a prototype, Minimum-AggregateDelay (mad), within a CDN caching node. Using a CDN production trace and backends deployed in different geographic locations, we show that mad can reduce latencies by 12-18% depending on the backend RTTs.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {495–513},
numpages = {19},
keywords = {Caching, Delayed hits, Belatedly},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3406591,
author = {Kumar, Gautam and Dukkipati, Nandita and Jang, Keon and Wassel, Hassan M. G. and Wu, Xian and Montazeri, Behnam and Wang, Yaogong and Springborn, Kevin and Alfeld, Christopher and Ryan, Michael and Wetherall, David and Vahdat, Amin},
title = {Swift: Delay is Simple and Effective for Congestion Control in the Datacenter},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3406591},
doi = {10.1145/3387514.3406591},
abstract = {We report on experiences with Swift congestion control in Google datacenters. Swift targets an end-to-end delay by using AIMD control, with pacing under extreme congestion. With accurate RTT measurement and care in reasoning about delay targets, we find this design is a foundation for excellent performance when network distances are well-known. Importantly, its simplicity helps us to meet operational challenges. Delay is easy to decompose into fabric and host components to separate concerns, and effortless to deploy and maintain as a congestion signal while the datacenter evolves. In large-scale testbed experiments, Swift delivers a tail latency of &lt;50μs for short RPCs, with near-zero packet drops, while sustaining ~100Gbps throughput per server. This is a tail of &lt;3x the minimal latency at a load close to 100%. In production use in many different clusters, Swift achieves consistently low tail completion times for short RPCs, while providing high throughput for long RPCs. It has loss rates that are at least 10x lower than a DCTCP protocol, and handles O(10k) incasts that sharply degrade with DCTCP.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {514–528},
numpages = {15},
keywords = {Congestion Control, Performance Isolation, Datacenter Transport},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405885,
author = {Naseer, Usama and Niccolini, Luca and Pant, Udip and Frindell, Alan and Dasineni, Ranjeeth and Benson, Theophilus A.},
title = {Zero Downtime Release: Disruption-Free Load Balancing of a Multi-Billion User Website},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405885},
doi = {10.1145/3387514.3405885},
abstract = {Modern network infrastructure has evolved into a complex organism to satisfy the performance and availability requirements for the billions of users. Frequent releases such as code upgrades, bug fixes and security updates have become a norm. Millions of globally distributed infrastructure components including servers and load-balancers are restarted frequently from multiple times per-day to per-week. However, every release brings possibilities of disruptions as it can result in reduced cluster capacity, disturb intricate interaction of the components operating at large scales and disrupt the end-users by terminating their connections. The challenge is further complicated by the scale and heterogeneity of supported services and protocols.In this paper, we leverage different components of the end-to-end networking infrastructure to prevent or mask any disruptions in face of releases. Zero Downtime Release is a collection of mechanisms used at Facebook to shield the end-users from any disruptions, preserve the cluster capacity and robustness of the infrastructure when updates are released globally. Our evaluation shows that these mechanisms prevent any significant cluster capacity degradation when a considerable number of productions servers and proxies are restarted and minimizes the disruption for different services (notably TCP, HTTP and publish/subscribe).},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {529–541},
numpages = {13},
keywords = {Reliable networks, Update releases, Load-balancing},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405886,
author = {Rashelbach, Alon and Rottenstreich, Ori and Silberstein, Mark},
title = {A Computational Approach to Packet Classification},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405886},
doi = {10.1145/3387514.3405886},
abstract = {Multi-field packet classification is a crucial component in modern software-defined data center networks. To achieve high throughput and low latency, state-of-the-art algorithms strive to fit the rule lookup data structures into on-die caches; however, they do not scale well with the number of rules.We present a novel approach, NuevoMatch, which improves the memory scaling of existing methods. A new data structure, Range Query Recursive Model Index (RQ-RMI), is the key component that enables NuevoMatch to replace most of the accesses to main memory with model inference computations. We describe an efficient training algorithm that guarantees the correctness of the RQ-RMI-based classification. The use of RQ-RMI allows the rules to be compressed into model weights that fit into the hardware cache. Further, it takes advantage of the growing support for fast neural network processing in modern CPUs, such as wide vector instructions, achieving a rate of tens of nanoseconds per lookup.Our evaluation using 500K multi-field rules from the standard ClassBench benchmark shows a geometric mean compression factor of 4.9x, 8x, and 82x, and average performance improvement of 2.4x, 2.6x, and 1.6x in throughput compared to CutSplit, NeuroCuts, and TupleMerge, all state-of-the-art algorithms1.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {542–556},
numpages = {15},
keywords = {Packet Classification, Virtual Switches, Neural Networks},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405887,
author = {Du, Kuntai and Pervaiz, Ahsan and Yuan, Xin and Chowdhery, Aakanksha and Zhang, Qizheng and Hoffmann, Henry and Jiang, Junchen},
title = {Server-Driven Video Streaming for Deep Learning Inference},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405887},
doi = {10.1145/3387514.3405887},
abstract = {Video streaming is crucial for AI applications that gather videos from sources to servers for inference by deep neural nets (DNNs). Unlike traditional video streaming that optimizes visual quality, this new type of video streaming permits aggressive compression/pruning of pixels not relevant to achieving high DNN inference accuracy. However, much of this potential is left unrealized, because current video streaming protocols are driven by the video source (camera) where the compute is rather limited. We advocate that the video streaming protocol should be driven by real-time feedback from the server-side DNN. Our insight is two-fold: (1) server-side DNN has more context about the pixels that maximize its inference accuracy; and (2) the DNN's output contains rich information useful to guide video streaming. We present DDS (DNN-Driven Streaming), a concrete design of this approach. DDS continuously sends a low-quality video stream to the server; the server runs the DNN to determine where to re-send with higher quality to increase the inference accuracy. We find that compared to several recent baselines on multiple video genres and vision tasks, DDS maintains higher accuracy while reducing bandwidth usage by upto 59% or improves accuracy by upto 9% with no additional bandwidth usage.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {557–570},
numpages = {14},
keywords = {video analytics, feedback-driven, deep neural networks, video streaming},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405888,
author = {Dumitrescu, Dragos and Stoenescu, Radu and Negreanu, Lorina and Raiciu, Costin},
title = {Bf4: Towards Bug-Free P4 Programs},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405888},
doi = {10.1145/3387514.3405888},
abstract = {Recent verification work has made advances in finding bugs in P4 programs before deployment, but it requires that the programmer specifies table rules that are possible at runtime[32, 24, 27]. This imposes a specification burden on the programmer, while at the same time failing to guarantee that bugs will not be inserted at runtime by faulty controllers.We present bf4, a novel verification approach for P4 programs that uses a mix of static verification, code changes and runtime checks to ensure that the deployed P4 program is bug free. To achieve this, bf4 uses static analysis to find all possible bugs in the P4 program; for each possible bug, bf4 attempts to find predicates that, when applied to table rules inserted by the controller, make that bug unreachable. If such predicates do not exist, bf4 can change the P4 code and re-run the procedure above.We applied bf4 to a wide range of P4 programs; for all these, bf4 is able to generate controller assertions and propose fixes that guarantee no controller-induced bug is reachable. At runtime, bf4 checks that the controller does not insert faulty rules; when it does, it throws an exception which helps troubleshoot the bug.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {571–585},
numpages = {15},
keywords = {programmable networks, Network dataplane verification},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405889,
author = {Bock, Kevin and Hughey, George and Merino, Louis-Henri and Arya, Tania and Liscinsky, Daniel and Pogosian, Regina and Levin, Dave},
title = {Come as You Are: Helping Unmodified Clients Bypass Censorship with Server-Side Evasion},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405889},
doi = {10.1145/3387514.3405889},
abstract = {Decades of work on censorship evasion have resulted in myriad ways to empower clients with the ability to access censored content, but to our knowledge all of them have required some degree of client-side participation. Having to download and run anti-censorship software can put users at risk, and does not help the many users who do not even realize they are being censored in the first place.In this paper, we present the first purely server-side censorship evasion strategies---11 in total. We extend a recent tool, Geneva, to automate the discovery and implementation of server-side strategies, and we apply it to four countries (China, India, Iran, and Kazakhstan) and five protocols (DNS-over-TCP, FTP, HTTP, HTTPS, and SMTP). We also perform follow-on experiments to understand why the strategies Geneva finds work, and to glean new insights into how censors operate. Among these, we find that China runs a completely separate network stack (each with its own unique bugs) for each application-layer protocol that it censors.The server-side techniques we find are easier and safer to deploy than client-side strategies. Our code and data are publicly available.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {586–598},
numpages = {13},
keywords = {Server-side, Geneva, Censorship},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3406217,
author = {Ye, Fangdan and Yu, Da and Zhai, Ennan and Liu, Hongqiang Harry and Tian, Bingchuan and Ye, Qiaobo and Wang, Chunsheng and Wu, Xin and Guo, Tianchen and Jin, Cheng and She, Duncheng and Ma, Qing and Cheng, Biao and Xu, Hui and Zhang, Ming and Wang, Zhiliang and Fonseca, Rodrigo},
title = {Accuracy, Scalability, Coverage: A Practical Configuration Verifier on a Global WAN},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3406217},
doi = {10.1145/3387514.3406217},
abstract = {This paper presents Hoyan-- the first reported large scale deployment of configuration verification in a global-scale wide area network (WAN). Hoyan has been running in production for more than two years and is currently used for all critical configuration auditing and updates on the WAN. We highlight our innovative designs and real-life experience to make Hoyan accurate and scalable in practice. For accuracy under the inconsistencies of devices' vendor-specific behaviors (VSBs), Hoyan continuously discovers the flaws in device behavior models, thus aiding the operators in fixing the models. For scalability to verify our global WAN, Hoyan introduces a "global-simulation &amp; local formal-modeling" strategy to model uncertainties in small scales and perform aggressive pruning of possibilities during the protocol simulations. Hoyan achieves near-100% verification accuracy after it detected and fixed O(10) VSBs on our WAN. Hoyan has prevented many potential service failures resulting from misconfiguration and reduced the failure rate of updates of our WAN by more than half in 2019.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {599–614},
numpages = {16},
keywords = {Network Verification, Reliability, Network Configurations},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405891,
author = {Meng, Tong and Schiff, Neta Rozen and Godfrey, P. Brighten and Schapira, Michael},
title = {PCC Proteus: Scavenger Transport And Beyond},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405891},
doi = {10.1145/3387514.3405891},
abstract = {Many Internet applications need high bandwidth but are not time sensitive. This motivates a congestion control "scavenger" that voluntarily yields to higher-priority applications, thus improving overall user experience. However, the existing scavenger protocol, LEDBAT, often fails to yield, has performance shortcomings, and requires a codebase separate from other transport protocols.We present PCC Proteus, a new congestion controller that can behave as an effective scavenger or primary protocol. Proteus incorporates several novel ideas to ensure that it yields to primary flows while still obtaining high performance, including using latency deviation as a signal of competition, and techniques for noise tolerance in dynamic environments. By extending the existing PCC utility framework, Proteus also allows applications to specify a flexible utility function that, in addition to scavenger and primary modes, allows choice of hybrid modes between the two, better capturing application needs. Extensive emulation and real-world evaluation show that Proteus is capable of both being a much more effective scavenger than LEDBAT, and of acting as a high performance primary protocol. Application-level experiments show Proteus significantly improves page load time and DASH video delivery, and its hybrid mode significantly reduces rebuffering in a bandwidth-constrained environment.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {615–631},
numpages = {17},
keywords = {Scavenger, Congestion Control},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405892,
author = {Abbasloo, Soheil and Yen, Chen-Yu and Chao, H. Jonathan},
title = {Classic Meets Modern: A Pragmatic Learning-Based Congestion Control for the Internet},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405892},
doi = {10.1145/3387514.3405892},
abstract = {These days, taking the revolutionary approach of using clean-slate learning-based designs to completely replace the classic congestion control schemes for the Internet is gaining popularity. However, we argue that current clean-slate learning-based techniques bring practical issues and concerns such as overhead, convergence issues, and low performance over unseen network conditions to the table. To address these issues, we take a pragmatic and evolutionary approach combining classic congestion control strategies and advanced modern deep reinforcement learning (DRL) techniques and introduce a novel hybrid congestion control for the Internet named Orca1. Through extensive experiments done over global testbeds on the Internet and various locally emulated network conditions, we demonstrate that Orca is adaptive and achieves consistent high performance in different network conditions, while it can significantly alleviate the issues and problems of its clean-slate learning-based counterparts.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {632–647},
numpages = {16},
keywords = {Congestion Control, Deep Reinforcement Learning, TCP},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3406218,
author = {Ahmad, Mukhtiar and Jafri, Syed Usman and Ikram, Azam and Qasmi, Wasiq Noor Ahmad and Nawazish, Muhammad Ali and Uzmi, Zartash Afzal and Qazi, Zafar Ayyub},
title = {A Low Latency and Consistent Cellular Control Plane},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3406218},
doi = {10.1145/3387514.3406218},
abstract = {5G networks aim to provide ultra-low latency and higher reliability to support emerging and near real-time applications such as augmented and virtual reality, remote surgery, self-driving cars, and multi-player online gaming. This imposes new requirements on the design of cellular core networks. A key component of the cellular core is the control plane. Time to complete control plane operations (e.g. mobility handoff, service establishment) directly impacts the delay experienced by end-user applications. In this paper, we design Neutrino, a cellular control plane that provides users an abstraction of reliable access to cellular services while ensuring lower latency. Our testbed evaluations based on real cellular control traffic traces show that Neutrino provides an improvement in control procedure completion times by up to 3.1x without failures, and up to 5.6x under control plane failures, over existing cellular core proposals. We also show how these improvements translate into improving end-user application performance: for AR/VR applications and self-driving cars, Neutrino performs up to 2.5x and up to 2.8x better, respectively, as compared to existing EPC.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {648–661},
numpages = {14},
keywords = {Cellular Core, Consistency, Control Plane},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405894,
author = {Ben Basat, Ran and Ramanathan, Sivaramakrishnan and Li, Yuliang and Antichi, Gianni and Yu, Minian and Mitzenmacher, Michael},
title = {PINT: Probabilistic In-Band Network Telemetry},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405894},
doi = {10.1145/3387514.3405894},
abstract = {Commodity network devices support adding in-band telemetry measurements into data packets, enabling a wide range of applications, including network troubleshooting, congestion control, and path tracing. However, including such information on packets adds significant overhead that impacts both flow completion times and application-level performance.We introduce PINT, an in-band network telemetry framework that bounds the amount of information added to each packet. PINT encodes the requested data on multiple packets, allowing per-packet overhead limits that can be as low as one bit. We analyze PINT and prove performance bounds, including cases when multiple queries are running simultaneously. PINT is implemented in P4 and can be deployed on network devices.Using real topologies and traffic characteristics, we show that PINT concurrently enables applications such as congestion control, path tracing, and computing tail latencies, using only sixteen bits per packet, with performance comparable to the state of the art.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {662–680},
numpages = {19},
keywords = {Network Telemetry, Networking Protocols, Networking Algorithms},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405895,
author = {Grant, Stewart and Yelam, Anil and Bland, Maxwell and Snoeren, Alex C.},
title = {SmartNIC Performance Isolation with FairNIC: Programmable Networking for the Cloud},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405895},
doi = {10.1145/3387514.3405895},
abstract = {Multiple vendors have recently released SmartNICs that provide both special-purpose accelerators and programmable processing cores that allow increasingly sophisticated packet processing tasks to be offloaded from general-purpose CPUs. Indeed, leading data-center operators have designed and deployed SmartNICs at scale to support both network virtualization and application-specific tasks. Unfortunately, cloud providers have not yet opened up the full power of these devices to tenants, as current runtimes do not provide adequate isolation between individual applications running on the SmartNICs themselves.We introduce FairNIC, a system to provide performance isolation between tenants utilizing the full capabilities of a commodity SoC SmartNIC. We implement FairNIC on Cavium LiquidIO 2360s and show that we are able to isolate not only typical packet processing, but also prevent MIPS-core cache pollution and fairly share access to fixed-function hardware accelerators. We use FairNIC to implement NIC-accelerated OVS and key/value store applications and show that they both can cohabitate on a single NIC using the same port, where the performance of each is unimpacted by other tenants. We argue that our results demonstrate the feasibility of sharing SmartNICs among virtual tenants, and motivate the development of appropriate security isolation mechanisms.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {681–693},
numpages = {13},
keywords = {cloud hosting, Network adapters, performance isolation},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3406219,
author = {Zhao, Renjie and Wang, Purui and Ma, Yunfei and Zhang, Pengyu and Liu, Hongqiang Harry and Lin, Xianshang and Zhang, Xinyu and Xu, Chenren and Zhang, Ming},
title = {NFC+: Breaking NFC Networking Limits through Resonance Engineering},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3406219},
doi = {10.1145/3387514.3406219},
abstract = {Current UHF RFID systems suffer from two long-standing problems: 1) miss-reading non-line-of-sight or misoriented tags and 2) cross-reading undesired, distant tags due to multi-path reflections. This paper proposes a novel system, NFC+, to overcome the fundamental challenges. NFC+ is a magnetic field reader, which can inventory standard NFC tagged objects with a reasonably long range and arbitrary orientation. NFC+ achieves this by leveraging physical and algorithmic techniques based on magnetic resonance engineering. We build a prototype of NFC+ and conduct extensive evaluations in a logistic network. Comparing to UHF RFID, we find that NFC+ can reduce the miss-reading rate from 23% to 0.03%, and cross-reading rate from 42% to 0, for randomly oriented objects. NFC+ demonstrates high robustness for RFID unfriendly media (e.g., water bottles and metal cans). It can reliably read commercial NFC tags at a distance of up to 3 meters which, for the first time, enables NFC to be directly applied to practical logistics network applications.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {694–707},
numpages = {14},
keywords = {NFC, RFID, Logistics Network, Magnetic Communication, Internet of Things},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405897,
author = {Singhvi, Arjun and Akella, Aditya and Gibson, Dan and Wenisch, Thomas F. and Wong-Chan, Monica and Clark, Sean and Martin, Milo M. K. and McLaren, Moray and Chandra, Prashant and Cauble, Rob and Wassel, Hassan M. G. and Montazeri, Behnam and Sabato, Simon L. and Scherpelz, Joel and Vahdat, Amin},
title = {1RMA: Re-Envisioning Remote Memory Access for Multi-Tenant Datacenters},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405897},
doi = {10.1145/3387514.3405897},
abstract = {Remote Direct Memory Access (RDMA) plays a key role in supporting performance-hungry datacenter applications. However, existing RDMA technologies are ill-suited to multi-tenant datacenters, where applications run at massive scales, tenants require isolation and security, and the workload mix changes over time. Our experiences seeking to operationalize RDMA at scale indicate that these ills are rooted in standard RDMA's basic design attributes: connectionorientedness and complex policies baked into hardware.We describe a new approach to remote memory access -- One-Shot RMA (1RMA) -- suited to the constraints imposed by our multi-tenant datacenter settings. The 1RMA NIC is connection-free and fixed-function; it treats each RMA operation independently, assisting software by offering fine-grained delay measurements and fast failure notifications. 1RMA software provides operation pacing, congestion control, failure recovery, and inter-operation ordering, when needed. The NIC, deployed in our production datacenters, supports encryption at line rate (100Gbps and 100M ops/sec) with minimal performance/availability disruption for encryption key rotation.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {708–721},
numpages = {14},
keywords = {Remote Memory Access, Connection Free, Congestion Control},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405898,
author = {Ghaffarivardavagh, Reza and Afzal, Sayed Saad and Rodriguez, Osvy and Adib, Fadel},
title = {Ultra-Wideband Underwater Backscatter via Piezoelectric Metamaterials},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405898},
doi = {10.1145/3387514.3405898},
abstract = {We present the design, implementation, and evaluation of U2B, a technology that enables ultra-wideband backscatter in underwater environments. At the core of U2B's design is a novel metamaterialinspired transducer for underwater backscatter, and algorithms that enable self-interference cancellation and FDMA-based medium access control.We fabricated U2B nodes and tested them in a river across different weather conditions, including snow and rain. Our empirical evaluation demonstrates that U2B can achieve throughputs up to 20 kbps, an operational range up to 62 m, and can scale to networks with more than 10 nodes. In comparison to the state-of-the-art system for underwater backscatter, our design achieves 5x more throughput and 6x more communication range. Moreover, our evaluation represents the first experimental validation of underwater backscatter in the wild.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {722–734},
numpages = {13},
keywords = {Piezoelectricity, Energy Harvesting, UWB, Battery-free, Metamaterials, Wireless, Subsea IoT, Backscatter Communication},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405899,
author = {Saeed, Ahmed and Gupta, Varun and Goyal, Prateesh and Sharif, Milad and Pan, Rong and Ammar, Mostafa and Zegura, Ellen and Jang, Keon and Alizadeh, Mohammad and Kabbani, Abdul and Vahdat, Amin},
title = {Annulus: A Dual Congestion Control Loop for Datacenter and WAN Traffic Aggregates},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405899},
doi = {10.1145/3387514.3405899},
abstract = {Cloud services are deployed in datacenters connected though high-bandwidth Wide Area Networks (WANs). We find that WAN traffic negatively impacts the performance of datacenter traffic, increasing tail latency by 2.5x, despite its small bandwidth demand. This behavior is caused by the long round-trip time (RTT) for WAN traffic, combined with limited buffering in datacenter switches. The long WAN RTT forces datacenter traffic to take the full burden of reacting to congestion. Furthermore, datacenter traffic changes on a faster time-scale than the WAN RTT, making it difficult for WAN congestion control to estimate available bandwidth accurately.We present Annulus, a congestion control scheme that relies on two control loops to address these challenges. One control loop leverages existing congestion control algorithms for bottlenecks where there is only one type of traffic (i.e., WAN or datacenter). The other loop handles bottlenecks shared between WAN and datacenter traffic near the traffic source, using direct feedback from the bottleneck. We implement Annulus on a testbed and in simulation. Compared to baselines using BBR for WAN congestion control and DCTCP or DCQCN for datacenter congestion control, Annulus increases bottleneck utilization by 10% and lowers datacenter flow completion time by 1.3-3.5x.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {735–749},
numpages = {15},
keywords = {Explicit Direct Congestion Notification, Data Center Networks, Congestion Control, Wide-Area Networks},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3405900,
author = {Steffen, Samuel and Gehr, Timon and Tsankov, Petar and Vanbever, Laurent and Vechev, Martin},
title = {Probabilistic Verification of Network Configurations},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3405900},
doi = {10.1145/3387514.3405900},
abstract = {Not all important network properties need to be enforced all the time. Often, what matters instead is the fraction of time / probability these properties hold. Computing the probability of a property in a network relying on complex inter-dependent routing protocols is challenging and requires determining all failure scenarios for which the property is violated. Doing so at scale and accurately goes beyond the capabilities of current network analyzers.In this paper, we introduce NetDice, the first scalable and accurate probabilistic network configuration analyzer supporting BGP, OSPF, ECMP, and static routes. Our key contribution is an inference algorithm to efficiently explore the space of failure scenarios. More specifically, given a network configuration and a property φ, our algorithm automatically identifies a set of links whose failure is provably guaranteed not to change whether φ holds. By pruning these failure scenarios, NetDice manages to accurately approximate P(φ). NetDice supports practical properties and expressive failure models including correlated link failures.We implement NetDice and evaluate it on realistic configurations. NetDice is practical: it can precisely verify probabilistic properties in few minutes, even in large networks.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {750–764},
numpages = {15},
keywords = {Network analysis, Cold edges, Probabilistic inference, Failures},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3406220,
author = {Dukic, Vojislav and Khanna, Ginni and Gkantsidis, Christos and Karagiannis, Thomas and Parmigiani, Francesca and Singla, Ankit and Filer, Mark and Cox, Jeffrey L. and Ptasznik, Anna and Harland, Nick and Saunders, Winston and Belady, Christian},
title = {Beyond the Mega-Data Center: Networking Multi-Data Center Regions},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3406220},
doi = {10.1145/3387514.3406220},
abstract = {The difficulty of building large data centers in dense metro areas is pushing big cloud providers towards a different approach to scaling: multiple smaller data centers within tens of kilometers of each other, comprising a "region". We show that networking this small number of nearby sites with each other is a surprisingly challenging and multi-faceted problem. We draw out the operational goals and constraints of such networks, and highlight the design trade-offs involved using data from Microsoft Azure's regions.Our analysis of the design space shows that network topologies that achieve lower latency and allow greater flexibility in data center placement are, unfortunately, encumbered by their much greater cost and complexity. We thus present and demonstrate a novel optical-circuit-switched architecture, Iris, that lowers these cost and complexity barriers, making a richer topology design space more accessible to operators of regional networks. With Iris, topologies which, in comparison to a simple hub-and-spoke topology can increase the area in which a new DC can be placed by 2-5x, can be implemented at a cost within 1.1x of the simple hub-and-spoke topology, and 7x cheaper than a natural packet-switched network.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {765–781},
numpages = {17},
keywords = {optical networks, DCI, region, optical switching, cloud, data center interconnect},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

@inproceedings{10.1145/3387514.3406221,
author = {Ballani, Hitesh and Costa, Paolo and Behrendt, Raphael and Cletheroe, Daniel and Haller, Istvan and Jozwik, Krzysztof and Karinou, Fotini and Lange, Sophie and Shi, Kai and Thomsen, Benn and Williams, Hugh},
title = {Sirius: A Flat Datacenter Network with Nanosecond Optical Switching},
year = {2020},
isbn = {9781450379557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387514.3406221},
doi = {10.1145/3387514.3406221},
abstract = {The increasing gap between the growth of datacenter traffic and electrical switch capacity is expected to worsen due to the slowdown of Moore's law, motivating the need for a new switching technology for the post-Moore's law era that can meet the increasingly stringent requirements of hardware-driven cloud workloads. We propose Sirius, an optically-switched network for datacenters providing the abstraction of a single, high-radix switch that can connect thousands of nodes---racks or servers---in a datacenter while achieving nanosecond-granularity reconfiguration. At its core, Sirius uses a combination of tunable lasers and simple, passive gratings that route light based on its wavelength. Sirius' switching technology and topology is tightly codesigned with its routing and scheduling and with novel congestion-control and time-synchronization mechanisms to achieve a scalable yet flat network that can offer high bandwidth and very low end-to-end latency. Through a small-scale prototype using a custom tunable laser chip that can tune in less than 912 ps, we demonstrate 3.84 ns end-to-end reconfiguration atop 50 Gbps channels. Through large-scale simulations, we show that Sirius can approximate the performance of an ideal, electrically-switched non-blocking network with up to 74-77% lower power.},
booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
pages = {782–797},
numpages = {16},
keywords = {Scheduler-less design, Nanosecond Switching, Vertical Integration, Datacenter Networks, Fast Tunable Lasers, Optical Switches},
location = {Virtual Event, USA},
series = {SIGCOMM '20}
}

