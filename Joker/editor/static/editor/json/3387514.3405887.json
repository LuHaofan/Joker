{"authors": [{"first": "Kuntai", "last": "Du"}, {"first": "Ahsan", "last": "Pervaiz"}, {"first": "Xin", "last": "Yuan"}, {"first": "Aakanksha", "last": "Chowdhery"}, {"first": "Qizheng", "last": "Zhang"}, {"first": "Henry", "last": "Hoffmann"}, {"first": "Junchen", "last": "Jiang"}], "title": "Server-Driven Video Streaming for Deep Learning Inference", "year": "2020", "isbn": "9781450379557", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3387514.3405887", "doi": "10.1145/3387514.3405887", "abstract": "Video streaming is crucial for AI applications that gather videos from sources to servers for inference by deep neural nets (DNNs). Unlike traditional video streaming that optimizes visual quality, this new type of video streaming permits aggressive compression/pruning of pixels not relevant to achieving high DNN inference accuracy. However, much of this potential is left unrealized, because current video streaming protocols are driven by the video source (camera) where the compute is rather limited. We advocate that the video streaming protocol should be driven by real-time feedback from the server-side DNN. Our insight is two-fold: (1) server-side DNN has more context about the pixels that maximize its inference accuracy; and (2) the DNN's output contains rich information useful to guide video streaming. We present DDS (DNN-Driven Streaming), a concrete design of this approach. DDS continuously sends a low-quality video stream to the server; the server runs the DNN to determine where to re-send with higher quality to increase the inference accuracy. We find that compared to several recent baselines on multiple video genres and vision tasks, DDS maintains higher accuracy while reducing bandwidth usage by upto 59% or improves accuracy by upto 9% with no additional bandwidth usage.", "booktitle": "Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication", "numpages": "14", "keywords": ["video analytics", "feedback-driven", "deep neural networks", "video streaming"], "location": "Virtual Event, USA", "series": "SIGCOMM '20"}