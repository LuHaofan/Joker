{"authors": [{"first": "Qizhen", "last": "Zhang"}, {"first": "Kelvin K. W.", "last": "Ng"}, {"first": "Charles", "last": "Kazer"}, {"first": "Shen", "last": "Yan"}, {"first": "Jo\\~{a}o", "last": "Sedoc"}, {"first": "Vincent", "last": "Liu"}], "title": "MimicNet: Fast Performance Estimates for Data Center Networks with Machine Learning", "year": "2021", "isbn": "9781450383837", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3452296.3472926", "doi": "10.1145/3452296.3472926", "abstract": "At-scale evaluation of new data center network innovations is becoming increasingly intractable. This is true for testbeds, where few, if any, can afford a dedicated, full-scale replica of a data center. It is also true for simulations, which while originally designed for precisely this purpose, have struggled to cope with the size of today's networks. This paper presents an approach for quickly obtaining accurate performance estimates for large data center networks. Our system,MimicNet, provides users with the familiar abstraction of a packet-level simulation for a portion of the network while leveraging redundancy and recent advances in machine learning to quickly and accurately approximate portions of the network that are not directly visible. MimicNet can provide over two orders of magnitude speedup compared to regular simulation for a data center with thousands of servers. Even at this scale, MimicNet estimates of the tail FCT, throughput, and RTT are within 5% of the true results.", "booktitle": "Proceedings of the 2021 ACM SIGCOMM 2021 Conference", "numpages": "18", "keywords": ["machine learning", "network modeling", "approximation", "network simulation", "data center networks"], "location": "Virtual Event, USA", "series": "SIGCOMM '21"}