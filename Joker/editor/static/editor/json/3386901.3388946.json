{"authors": [{"first": "Fan", "last": "Mo"}, {"first": "Ali Shahin", "last": "Shamsabadi"}, {"first": "Kleomenis", "last": "Katevas"}, {"first": "Soteris", "last": "Demetriou"}, {"first": "Ilias", "last": "Leontiadis"}, {"first": "Andrea", "last": "Cavallaro"}, {"first": "Hamed", "last": "Haddadi"}], "title": "DarkneTZ: Towards Model Privacy at the Edge Using Trusted Execution Environments", "year": "2020", "isbn": "9781450379540", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3386901.3388946", "doi": "10.1145/3386901.3388946", "abstract": "We present DarkneTZ, a framework that uses an edge device's Trusted Execution Environment (TEE) in conjunction with model partitioning to limit the attack surface against Deep Neural Networks (DNNs). Increasingly, edge devices (smartphones and consumer IoT devices) are equipped with pre-trained DNNs for a variety of applications. This trend comes with privacy risks as models can leak information about their training data through effective membership inference attacks (MIAs).We evaluate the performance of DarkneTZ, including CPU execution time, memory usage, and accurate power consumption, using two small and six large image classification models. Due to the limited memory of the edge device's TEE, we partition model layers into more sensitive layers (to be executed inside the device TEE), and a set of layers to be executed in the untrusted part of the operating system. Our results show that even if a single layer is hidden, we can provide reliable model privacy and defend against state of the art MIAs, with only 3% performance overhead. When fully utilizing the TEE, DarkneTZ provides model protections with up to 10% overhead.", "booktitle": "Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services", "numpages": "14", "location": "Toronto, Ontario, Canada", "series": "MobiSys '20"}