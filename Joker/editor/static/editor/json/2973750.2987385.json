{"authors": [{"first": "Wei", "last": "Wang"}, {"first": "Alex X.", "last": "Liu"}, {"first": "Ke", "last": "Sun"}], "title": "Device-Free Gesture Tracking Using Acoustic Signals: Demo", "year": "2016", "isbn": "9781450342261", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/2973750.2987385", "doi": "10.1145/2973750.2987385", "abstract": "In this demo, we present LLAP, a hand tracking system that uses ultrasound to localize the hand of the user to enable device-free gesture inputs. LLAP utilizes speakers and microphones on Commercial-Off-The-Shelf (COTS) mobile devices to play and record sound waves that are inaudible to humans. By measuring the phase of the sound signal reflected by the hands or fingers of the user, we can accurately measure the gesture movements. With a single pair of speaker/microphone, LLAP can track hand movement with accuracy of 3.5 mm. For devices with two microphones, LLAP enables drawing-in-the air capability with tracking accuracy of 4.6 mm. Moreover, the latency for LLAP is smaller than 15 ms for both the Android and the iOS platforms so that LLAP can be used for real-time applications.", "booktitle": "Proceedings of the 22nd Annual International Conference on Mobile Computing and Networking", "numpages": "2", "location": "New York City, New York", "series": "MobiCom '16"}