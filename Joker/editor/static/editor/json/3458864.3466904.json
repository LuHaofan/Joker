{"authors": [{"first": "Hansi", "last": "Liu"}, {"first": "Abrar", "last": "Alali"}, {"first": "Mohamed", "last": "Ibrahim"}, {"first": "Hongyu", "last": "Li"}, {"first": "Marco", "last": "Gruteser"}, {"first": "Shubham", "last": "Jain"}, {"first": "Kristin", "last": "Dana"}, {"first": "Ashwin", "last": "Ashok"}, {"first": "Bin", "last": "Cheng"}, {"first": "Hongsheng", "last": "Lu"}], "title": "Lost and Found! Associating Target Persons in Camera Surveillance Footage with Smartphone Identifiers", "year": "2021", "isbn": "9781450384438", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3458864.3466904", "doi": "10.1145/3458864.3466904", "abstract": "We demonstrate an application of finding target persons on a surveillance video. Each visually detected participant is tagged with a smartphone ID and the target person with the query ID is highlighted. This work is motivated by the fact that establishing associations between subjects observed in camera images and messages transmitted from their wireless devices can enable fast and reliable tagging. This is particularly helpful when target pedestrians need to be found on public surveillance footage, without the reliance on facial recognition. The underlying system uses a multi-modal approach that leverages WiFi Fine Timing Measurements (FTM) and inertial sensor (IMU) data to associate each visually detected individual with a corresponding smartphone identifier. These smartphone measurements are combined strategically with RGB-D information from the camera, to learn affinity matrices using a multi-modal deep learning network.", "booktitle": "Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services", "numpages": "2", "keywords": ["multimodal learning", "machine learning", "wifi FTM ranging", "person identification"], "location": "Virtual Event, Wisconsin", "series": "MobiSys '21"}