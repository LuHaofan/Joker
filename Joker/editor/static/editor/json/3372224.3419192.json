{"authors": [{"first": "Juheon", "last": "Yi"}, {"first": "Youngki", "last": "Lee"}], "title": "Heimdall: Mobile GPU Coordination Platform for Augmented Reality Applications", "year": "2020", "isbn": "9781450370851", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3372224.3419192", "abstract": "We present Heimdall, a mobile GPU coordination platform for emerging Augmented Reality (AR) applications. Future AR apps impose an explored challenging workload: i) concurrent execution of multiple Deep Neural Networks (DNNs) for physical world and user behavior analysis, and ii) seamless rendering in presence of the DNN execution for immersive user experience. Existing mobile deep learning frameworks, however, fail to support such workload: multi-DNN GPU contention slows down inference latency (e.g., from 59.93 to 1181 ms), and rendering-DNN GPU contention degrades frame rate (e.g., from 30 to \u224812 fps). Multi-tasking for desktop GPUs (e.g., parallelization, preemption) cannot be applied to mobile GPUs as well due to limited architectural support and memory bandwidth. To tackle the challenge, we design a Pseudo-Preemption mechanism which i) breaks down the bulky DNN into smaller units, and ii) prioritizes and flexibly schedules concurrent GPU tasks. We prototyped Heimdall over various mobile GPUs (i.e., recent Adreno series) and multiple AR app scenarios that involve combinations of 8 state-of-the-art DNNs. Our extensive evaluation shows that Heimdall enhances the frame rate from \u224812 to \u224830 fps while reducing the worst-case DNN inference latency by up to \u224815 times compared to the baseline multi-threading approach.", "booktitle": "Proceedings of the 26th Annual International Conference on Mobile Computing and Networking", "numpages": "14"}