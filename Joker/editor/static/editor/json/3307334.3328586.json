{"authors": [{"first": "Jayeeta", "last": "Mondal"}, {"first": "Swarnava", "last": "Dey"}, {"first": "Arijit", "last": "Mukherjee"}, {"first": "Jeet", "last": "Dutta"}, {"first": "Arpan", "last": "Pal"}, {"first": "Balamurali", "last": "P"}], "title": "Edge Acceleration of Deep Neural Networks (Demo)", "year": "2019", "isbn": "9781450366618", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3307334.3328586", "doi": "10.1145/3307334.3328586", "abstract": "Running deep learning algorithms at the edge is a necessity in many industrial use-cases, especially in applications that use robots and drones in disaster recovery, surveillance, oil &amp; gas operations etc. Current state of the art deep learning algorithms are extremely efficient in analysing image, audio, video and other time-series signals. However, their performance degrades considerably on constrained edge devices. In this demo, we show how standard pretrained CNN (Convolutional Neural Network) models can be partitioned for efficient parallel execution between constrained devices and also achieve real-time response.", "booktitle": "Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services", "numpages": "2", "keywords": ["network", "acceleration", "dnn", "computing", "latency", "edge", "partitioning"], "location": "Seoul, Republic of Korea", "series": "MobiSys '19"}