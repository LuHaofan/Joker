{"authors": [{"first": "Cong", "last": "Shi"}, {"first": "Xiangyu", "last": "Xu"}, {"first": "Tianfang", "last": "Zhang"}, {"first": "Payton", "last": "Walker"}, {"first": "Yi", "last": "Wu"}, {"first": "Jian", "last": "Liu"}, {"first": "Nitesh", "last": "Saxena"}, {"first": "Yingying", "last": "Chen"}, {"first": "Jiadi", "last": "Yu"}], "title": "Face-Mic: Inferring Live Speech and Speaker Identity via Subtle Facial Dynamics Captured by AR/VR Motion Sensors", "year": "2021", "isbn": "9781450383424", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3447993.3483272", "abstract": "Augmented reality/virtual reality (AR/VR) has extended beyond 3D immersive gaming to a broader array of applications, such as shopping, tourism, education. And recently there has been a large shift from handheld-controller dominated interactions to headset-dominated interactions via voice interfaces. In this work, we show a serious privacy risk of using voice interfaces while the user is wearing the face-mounted AR/VR devices. Specifically, we design an eavesdropping attack, Face-Mic, which leverages speech-associated subtle facial dynamics captured by zero-permission motion sensors in AR/VR headsets to infer highly sensitive information from live human speech, including speaker gender, identity, and speech content. Face-Mic is grounded on a key insight that AR/VR headsets are closely mounted on the user's face, allowing a potentially malicious app on the headset to capture underlying facial dynamics as the wearer speaks, including movements of facial muscles and bone-borne vibrations, which encode private biometrics and speech characteristics. To mitigate the impacts of body movements, we develop a signal source separation technique to identify and separate the speech-associated facial dynamics from other types of body movements. We further extract representative features with respect to the two types of facial dynamics. We successfully demonstrate the privacy leakage through AR/VR headsets by deriving the user's gender/identity and extracting speech information via the development of a deep learning-based framework. Extensive experiments using four mainstream VR headsets validate the generalizability, effectiveness, and high accuracy of Face-Mic.", "booktitle": "Proceedings of the 27th Annual International Conference on Mobile Computing and Networking", "numpages": "13"}