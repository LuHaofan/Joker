{"authors": [{"first": "Dan", "last": "Wang"}, {"first": "Haibo", "last": "Lei"}, {"first": "Haozhi", "last": "Dong"}, {"first": "Yunshu", "last": "Wang"}, {"first": "Yongpan", "last": "Zou"}, {"first": "Kaishun", "last": "Wu"}], "title": "What You Wear Know How You Feel: An Emotion Inference System with Multi-Modal Wearable Devices", "year": "2020", "isbn": "9781450370851", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3372224.3418161", "abstract": "Emotions show high significance on human health. Automatic emotion recognition is helpful for monitoring psychological disorders, mental problems and exploring behavioral mechanisms. Existing approaches adopt costly and bulky specialized hardware such as EEG/ECG helmet, possess privacy risks, or with low accuracy and user experience. With the increasing popularity of wearables, people tend to equip multiple smart devices, which provides potential opportunity for emotion perception. In this paper, we present a pervasive and portable system called MW-Emotion to recognize common emotional states with multi-modal wearable devices. However, ubiquitous wearable devices perceive shallow information which is not obviously related to human emotions. MW-Emotion excavates intrinsic mapping relationship between emotions and sensing data. Our experiments show that MW-Emotion can recognize different emotion states with a relatively high accuracy of 83.1%.", "booktitle": "Proceedings of the 26th Annual International Conference on Mobile Computing and Networking", "numpages": "3"}