{"authors": [{"first": "Giovanni", "last": "Galioto"}, {"first": "Ilenia", "last": "Tinnirello"}, {"first": "Daniele", "last": "Croce"}, {"first": "Federica", "last": "Inderst"}, {"first": "Federica", "last": "Pascucci"}, {"first": "Laura", "last": "Giarr\\'{e}"}], "title": "Demo: Sensor Fusion Localization and Navigation for Visually Impaired People", "year": "2017", "isbn": "9781450349161", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3117811.3119858", "doi": "10.1145/3117811.3119858", "abstract": "We present an innovative smartphone-centric tracking system for indoor and outdoor environments, based on the joint utilization of dead-reckoning and computer vision (CV) techniques. The system is explicitly designed for visually impaired people (although it could be easily generalized to other users) and it is built under the assumption that special reference signals, such as painted lines, colored tapes or tactile pavings are deployed in the environment for guiding visually impaired users along pre-defined paths. Thanks to highly optimized software, we are able to execute the CV and sensor-fusion algorithms in run-time on low power hardware such as a normal smartphone, precisely tracking the users movements.", "booktitle": "Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking", "numpages": "3", "keywords": ["assistive technologies", "navigation", "localization", "blind"], "location": "Snowbird, Utah, USA", "series": "MobiCom '17"}