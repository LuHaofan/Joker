{"authors": [{"first": "Jiahui", "last": "Hou"}, {"first": "Xiang-Yang", "last": "Li"}, {"first": "Peide", "last": "Zhu"}, {"first": "Zefan", "last": "Wang"}, {"first": "Yu", "last": "Wang"}, {"first": "Jianwei", "last": "Qian"}, {"first": "Panlong", "last": "Yang"}], "title": "SignSpeaker: A Real-Time, High-Precision SmartWatch-Based Sign Language Translator", "year": "2019", "isbn": "9781450361699", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3300061.3300117", "doi": "10.1145/3300061.3300117", "abstract": "Sign language is a natural and fully-formed communication method for deaf or hearing-impaired people. Unfortunately, most of the state-of-the-art sign recognition technologies are limited by either high energy consumption or expensive device costs and have a difficult time providing a real-time service in a daily-life environment. Inspired by previous works on motion detection with wearable devices, we propose Sign Speaker - a real-time, robust, and user-friendly American sign language recognition (ASLR) system with affordable and portable commodity mobile devices. SignSpeaker is deployed on a smartwatch along with a smartphone; the smartwatch collects the sign signals and the smartphone outputs translation through an inbuilt loudspeaker. We implement a prototype system and run a series of experiments that demonstrate the promising performance of our system. For example, the average translation time is approximately $1.1$ seconds for a sentence with eleven words. The average detection ratio and reliability of sign recognition are 99.2% and 99.5%, respectively. The average word error rate of continuous sentence recognition is 1.04% on average.", "booktitle": "The 25th Annual International Conference on Mobile Computing and Networking", "numpages": "15", "keywords": ["mobile computing", "applications of machine learning"], "location": "Los Cabos, Mexico", "series": "MobiCom '19"}