{"authors": [{"first": "Anh", "last": "Nguyen"}, {"first": "Duy", "last": "Nguyen"}, {"first": "Nhan", "last": "Nguyen"}, {"first": "Ashwin", "last": "Ashok"}, {"first": "Binh", "last": "Nguyen"}, {"first": "Bao", "last": "Pham"}, {"first": "Tam", "last": "Vu"}], "title": "Demo: Fusing Mobile Sensors for Paper Keyboard On-the-Go", "year": "2017", "isbn": "9781450349284", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3081333.3089328", "doi": "10.1145/3081333.3089328", "abstract": "Using touchscreens has largely limited user inputs to small form-factor devices. To address this constraint, we explore a novel input mechanism, dubbed PaperKey, that enables users to interact with mobile devices by performing multi-finger typing gestures on a surface where the device is placed. Using acceleration signals on the device, PaperKey infers the user's type events and then leverages a vision based technique for detecting the exact typing locations on a paper keyboard layout. Compared to single audio, image, or vibration sensing, this work accurately localizes keystrokes with faster processing speed. Additionally, this mechanism keeps the mobility of devices by working without external sensors.", "booktitle": "Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services", "numpages": "1", "keywords": ["vision-based localization", "multi-finger typing", "touching vibration", "paper keyboard"], "location": "Niagara Falls, New York, USA", "series": "MobiSys '17"}