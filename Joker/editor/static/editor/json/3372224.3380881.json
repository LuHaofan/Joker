{"authors": [{"first": "Juheon", "last": "Yi"}, {"first": "Sunghyun", "last": "Choi"}, {"first": "Youngki", "last": "Lee"}], "title": "EagleEye: Wearable Camera-Based Person Identification in Crowded Urban Spaces", "year": "2020", "isbn": "9781450370851", "publisher": "Association for Computing Machinery", "address": "New York, NY, USA", "url": "https://doi.org/10.1145/3372224.3380881", "abstract": "We present EagleEye, an AR-based system that identifies missing person (or people) in large, crowded urban spaces. Designing EagleEye involves critical technical challenges for both accuracy and latency. Firstly, despite recent advances in Deep Neural Network (DNN)-based face identification, we observe that state-of-the-art models fail to accurately identify Low-Resolution (LR) faces. Accordingly, we design a novel Identity Clarification Network to recover missing details in the LR faces, which enhances true positives by 78% with only 14% false positives. Furthermore, designing EagleEye involves unique challenges compared to recent continuous mobile vision systems in that it requires running a series of complex DNNs multiple times on a high-resolution image. To tackle the challenge, we develop Content-Adaptive Parallel Execution to optimize complex multi-DNN face identification pipeline execution latency using heterogeneous processors on mobile and cloud. Our results show that EagleEye achieves 9.07X faster latency compared to naive execution, with only 108 KBytes of data offloaded.", "booktitle": "Proceedings of the 26th Annual International Conference on Mobile Computing and Networking", "numpages": "14"}